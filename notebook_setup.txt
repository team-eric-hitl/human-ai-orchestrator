I want a jupyter notebook for testing/experimenting with the agents - Chatbot, Quality Agent, Frustration Agent. They need to be user friendly for people with little programming experience.


I want the first one to be for the generic Chatbot/ Answer Agent.


Maybe create a directory for experiment_runs and store the input and output files there.


It loads and displays the settings from the config files. These are loaded as a list of variable assignments that can be edited. The variable names should make for easy mapping to the config files since they may later be imported to config files.


There is an option to either load an input file or to generate an input file. A cell is provided to describe what kind of inputs you want, for example: 20 chatbot questions from users contacting their insurance company about their coverage. Some users are belligerent, some are stupid, some need information immediately, etcâ€¦
There is an option to choose which model to use to generate the test questions.


The notebook provides a window to review and edit the entries after they are loaded or generated.


The notebook then allows you to run a cell that will read in the input file, process each query from the users through the agent, generate the answers, flags questions that need more input from user, and flags questions that need to go to a router, and outputs an output file. Each output entry will include the original question and the ai answer, the flag for more input, the flag for routing. The file name should be something like chatbot_output_20250717_1519. Probably in JSON format.


Create another matching file like chatbot_settings_20250717_1519 that has all the variable assignments, in JSON format and in convenient labeling to make importing to config easy if needed.


If any of the output entries are flagged for more input, these are re-run through the answer agent with previous parts of the conversation, and an additional entry is inserted with the second interaction. 


The output file is re-ran until none of the entries are flagged for more input.


The notebook provides a window to review the output file.
