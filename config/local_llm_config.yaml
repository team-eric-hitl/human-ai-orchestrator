# Local LLM Configuration
# This file contains configurations for different local LLM models

# Default provider selection
default_provider: "auto"  # auto, openai, llama, mistral, ctransformers

# OpenAI Configuration (cloud-based)
openai:
  model: "gpt-4"
  temperature: 0.7
  max_tokens: 2000

# Local Llama Models
llama:
  # Llama 2 7B
  llama-7b:
    model_path: "models/llama-7b.gguf"
    temperature: 0.7
    max_tokens: 2000
    n_ctx: 2048
    n_gpu_layers: 0  # Set to -1 for all layers on GPU, 0 for CPU only
    verbose: false
  
  # Llama 2 13B
  llama-13b:
    model_path: "models/llama-13b.gguf"
    temperature: 0.7
    max_tokens: 2000
    n_ctx: 4096
    n_gpu_layers: 0
    verbose: false

# Mistral Models
mistral:
  # Mistral 7B Instruct
  mistral-7b-instruct:
    model_path: "models/mistral-7b-instruct.gguf"
    temperature: 0.7
    max_tokens: 2000
    n_ctx: 4096
    n_gpu_layers: 0
    verbose: false

# Code Llama Models
codellama:
  # Code Llama 7B Instruct
  codellama-7b-instruct:
    model_path: "models/codellama-7b-instruct.gguf"
    temperature: 0.7
    max_tokens: 2000
    n_ctx: 2048
    n_gpu_layers: 0
    verbose: false

# CTransformers (optimized local models)
ctransformers:
  # Llama 2 7B with CTransformers
  llama-7b-ct:
    model_path: "models/llama-7b.gguf"
    model_type: "llama"
    temperature: 0.7
    max_tokens: 2000
    context_length: 2048
    gpu_layers: 0

# Model download URLs (for reference)
model_downloads:
  llama-7b: "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf"
  llama-13b: "https://huggingface.co/TheBloke/Llama-2-13B-Chat-GGUF/resolve/main/llama-2-13b-chat.Q4_K_M.gguf"
  mistral-7b: "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf"
  codellama-7b: "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q4_K_M.gguf"

# System prompts optimized for local models
system_prompts:
  llama: |
    You are a helpful AI assistant. You provide accurate, helpful, and concise responses.
    Always be respectful and professional in your interactions.
  
  mistral: |
    You are a helpful AI assistant. You provide accurate, helpful, and concise responses.
    Always be respectful and professional in your interactions.
  
  codellama: |
    You are a helpful AI coding assistant. You provide accurate, helpful, and concise responses.
    When writing code, always include comments and explanations.
    Always be respectful and professional in your interactions. 