# Global model definitions for all agents
# This file contains the master model configurations that agents can reference

# Semantic model aliases - update these when new models are released
# This allows changing model mappings in one place when newer models become available
model_aliases:
  # Anthropic models - organized by use case and performance tier
  anthropic_general_budget: "claude-3-5-haiku-20241022"
  anthropic_general_standard: "claude-3-5-sonnet-20241022"
  anthropic_reasoning_premium: "claude-3-5-sonnet-20241022"
  anthropic_coding_premium: "claude-3-5-sonnet-20241022"
  anthropic_flagship: "claude-3-5-sonnet-20241022"
  
  # OpenAI models
  openai_general_standard: "gpt-4"
  openai_general_budget: "gpt-3.5-turbo"
  openai_coding_standard: "gpt-4"
  
  # Local models
  local_general_standard: "llama-7b"
  local_general_premium: "llama-13b"
  local_coding_standard: "codellama-7b"
  local_general_budget: "mistral-7b"

models:
  # Local Llama models
  llama-7b:
    path: "models/llama-7b.gguf"
    type: "llama"
    context_length: 2048
    gpu_layers: 40
    temperature: 0.7
    max_tokens: 2000
    description: "Llama 7B model - good balance of speed and quality"
    
  llama-13b:
    path: "models/llama-13b.gguf"
    type: "llama"
    context_length: 4096
    gpu_layers: 40
    temperature: 0.7
    max_tokens: 2000
    description: "Llama 13B model - higher quality, slower inference"
    
  # Local Mistral models
  mistral-7b:
    path: "models/mistral-7b.gguf"
    type: "mistral"
    context_length: 4096
    gpu_layers: 40
    temperature: 0.7
    max_tokens: 2000
    description: "Mistral 7B Instruct - excellent instruction following"
    
  # Code-focused models
  codellama-7b:
    path: "models/codellama-7b.gguf"
    type: "llama"
    context_length: 2048
    gpu_layers: 40
    temperature: 0.2
    max_tokens: 2000
    description: "CodeLlama 7B - optimized for code generation"
    
  # OpenAI models (cloud)
  gpt-4:
    type: "openai"
    model_name: "gpt-4"
    temperature: 0.7
    max_tokens: 2000
    description: "OpenAI GPT-4 - highest quality, requires API key"
    
  gpt-3.5-turbo:
    type: "openai"
    model_name: "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 2000
    description: "OpenAI GPT-3.5 Turbo - fast and cost-effective"
    
  # Anthropic models (cloud)
  claude-3-5-sonnet-20241022:
    type: "anthropic"
    model_name: "claude-3-5-sonnet-20241022"
    temperature: 0.7
    max_tokens: 2000
    description: "Anthropic Claude 3.5 Sonnet - balanced performance and reasoning"
    
  claude-3-5-haiku-20241022:
    type: "anthropic"
    model_name: "claude-3-5-haiku-20241022"
    temperature: 0.7
    max_tokens: 2000
    description: "Anthropic Claude 3.5 Haiku - fast and efficient"

# Global model categories for different use cases
use_cases:
  general:
    recommended: "local_general_standard"
    alternatives: ["local_general_budget", "anthropic_general_standard", "openai_general_standard"]
    
  code:
    recommended: "local_coding_standard"
    alternatives: ["anthropic_coding_premium", "openai_coding_standard", "local_general_budget"]
    
  fast:
    recommended: "anthropic_general_budget"
    alternatives: ["openai_general_budget", "local_general_standard"]
    
  high_quality:
    recommended: "openai_general_standard"
    alternatives: ["anthropic_reasoning_premium", "anthropic_general_standard", "local_general_budget", "local_general_premium"]

# Global fallback strategy
fallback_strategy:
  enabled: true
  max_retries: 3
  retry_delay: 5  # seconds
  
  # Global fallback chain
  default_fallback:
    - "local_general_budget"
    - "anthropic_general_budget"  # Only if ANTHROPIC_API_KEY is set
    - "gpt-3.5-turbo"  # Only if OPENAI_API_KEY is set