model_aliases:
  anthropic_general_budget: claude-3-5-haiku-20241022
  anthropic_general_standard: claude-3-5-sonnet-20241022
  anthropic_reasoning_premium: claude-3-5-sonnet-20241022
  anthropic_coding_premium: claude-3-5-sonnet-20241022
  anthropic_flagship: claude-3-5-sonnet-20241022
  openai_general_standard: gpt-4
  openai_general_budget: gpt-3.5-turbo
  openai_coding_standard: gpt-4
  deepinfra_general_standard: gemini-2.5-flash
  deepinfra_general_budget: Llama-3.3-70B-Instruct-Turbo
  local_general_standard: llama-7b
  local_general_premium: llama-13b
  local_coding_standard: codellama-7b
  local_general_budget: mistral-7b
models:
  llama-7b:
    path: models/llama-7b.gguf
    type: llama
    context_length: 2048
    gpu_layers: -1
    n_batch: 512
    temperature: 0.7
    max_tokens: 2000
    verbose: true
    description: Llama 7B model - good balance of speed and quality
  llama-13b:
    path: models/llama-13b.gguf
    type: llama
    context_length: 4096
    gpu_layers: -1
    n_batch: 512
    temperature: 0.7
    max_tokens: 2000
    description: Llama 13B model - higher quality, slower inference
  mistral-7b:
    path: models/mistral-7b.gguf
    type: mistral
    context_length: 4096
    gpu_layers: -1
    n_batch: 512
    temperature: 0.7
    max_tokens: 2000
    description: Mistral 7B Instruct - excellent instruction following
  codellama-7b:
    path: models/codellama-7b.gguf
    type: llama
    context_length: 2048
    gpu_layers: -1
    n_batch: 512
    temperature: 0.2
    max_tokens: 2000
    description: CodeLlama 7B - optimized for code generation
  gpt-4:
    type: openai
    model_name: gpt-4
    temperature: 0.7
    max_tokens: 2000
    description: OpenAI GPT-4 - highest quality, requires API key
  gpt-3.5-turbo:
    type: openai
    model_name: gpt-3.5-turbo
    temperature: 0.7
    max_tokens: 2000
    description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  claude-3-5-sonnet-20241022:
    type: anthropic
    model_name: claude-3-5-sonnet-20241022
    temperature: 0.7
    max_tokens: 2000
    description: Anthropic Claude 3.5 Sonnet - balanced performance and reasoning
  claude-3-5-haiku-20241022:
    type: anthropic
    model_name: claude-3-5-haiku-20241022
    temperature: 0.7
    max_tokens: 2000
    description: Anthropic Claude 3.5 Haiku - fast and efficient
  qwen3-32b:
    type: deepinfra
    model_id: Qwen/Qwen3-32B
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Qwen3 32B - high-quality conversational model via DeepInfra
  qwen3-14b:
    type: deepinfra
    model_id: Qwen/Qwen3-14B
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Qwen3 14B - balanced performance model via DeepInfra
  deepseek-v3-turbo:
    type: deepinfra
    model_id: deepseek-ai/DeepSeek-V3-0324-Turbo
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: DeepSeek V3 Turbo - fast and efficient model via DeepInfra
  llama4-maverick-17b:
    type: deepinfra
    model_id: meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo
    temperature: 0.2
    max_tokens: 2000
    repetition_penalty: 1.1
    top_p: 0.9
    description: Llama 4 Maverick 17B - specialized instruction model via DeepInfra
  devstral-small:
    type: deepinfra
    model_id: mistralai/Devstral-Small-2507
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Devstral Small - developer-focused model via DeepInfra
  Llama-3.3-70B-Instruct-Turbo:
    type: deepinfra
    model_id: meta-llama/Llama-3.3-70B-Instruct-Turbo
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Llama 3.3 70B Instruct Turbo - high-performance instruction model via DeepInfra
  gemini-2.5-flash:
    type: deepinfra
    model_id: google/gemini-2.5-flash
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Google Gemini 2.5 Flash - fast multimodal model via DeepInfra
use_cases:
  general:
    recommended: local_general_standard
    alternatives:
    - deepinfra_general_standard
    - local_general_budget
    - anthropic_general_standard
    - openai_general_standard
  code:
    recommended: local_coding_standard
    alternatives:
    - deepinfra_coding_standard
    - anthropic_coding_premium
    - openai_coding_standard
    - local_general_budget
  fast:
    recommended: anthropic_general_budget
    alternatives:
    - deepinfra_general_budget
    - openai_general_budget
    - local_general_standard
  high_quality:
    recommended: openai_general_standard
    alternatives:
    - deepinfra_reasoning_premium
    - anthropic_reasoning_premium
    - anthropic_general_standard
    - local_general_budget
    - local_general_premium
fallback_strategy:
  enabled: true
  max_retries: 3
  retry_delay: 5
  default_fallback:
  - local_general_budget
  - anthropic_general_budget
  - gpt-3.5-turbo
