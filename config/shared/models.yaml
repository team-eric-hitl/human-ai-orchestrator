model_aliases:
  anthropic_general_budget: claude-3-5-haiku-20241022
  anthropic_general_standard: claude-3-5-sonnet-20241022
  anthropic_reasoning_premium: claude-3-5-sonnet-20241022
  anthropic_coding_premium: claude-3-5-sonnet-20241022
  anthropic_flagship: claude-3-5-sonnet-20241022

  deepinfra_general_budget: meta-llama-3.3-70b-instruct-turbo
  deepinfra_general_budget_2: qwen3-14b
  deepinfra_general_budget_3: meta-llama-3-8b-instruct
  deepinfra_general_standard: kimi-k2-instruct
  deepinfra_general_standard_2: qwen3-32b
  deepinfra_general_standard_3: gemini-2.5-flash 
  deepinfra_coding_standard: meta-llama-3.1-8b-instruct
  deepinfra_coding_standard_2: llama4-maverick-17b
  deepinfra_reasoning_premium: mistral-7b-instruct-v0.3
  deepinfra_reasoning_premium_2: deepseek-v3-turbo

  openai_general_standard: gpt-4
  openai_general_budget: gpt-3.5-turbo
  openai_coding_standard: gpt-4
  
  
  local_general_standard: llama-7b
  local_general_premium: llama-13b
  local_coding_standard: codellama-7b
  local_general_budget: mistral-7b
models:
  llama-7b:
    path: models/llama-7b.gguf
    type: llama
    context_length: 2048
    gpu_layers: -1
    n_batch: 512
    temperature: 0.7
    max_tokens: 2000
    verbose: true
    description: Llama 7B model - good balance of speed and quality
  llama-13b:
    path: models/llama-13b.gguf
    type: llama
    context_length: 4096
    gpu_layers: -1
    n_batch: 512
    temperature: 0.7
    max_tokens: 2000
    description: Llama 13B model - higher quality, slower inference
  mistral-7b:
    path: models/mistral-7b.gguf
    type: mistral
    context_length: 4096
    gpu_layers: -1
    n_batch: 512
    temperature: 0.7
    max_tokens: 2000
    description: Mistral 7B Instruct - excellent instruction following
  codellama-7b:
    path: models/codellama-7b.gguf
    type: llama
    context_length: 2048
    gpu_layers: -1
    n_batch: 512
    temperature: 0.2
    max_tokens: 2000
    description: CodeLlama 7B - optimized for code generation
  gpt-4:
    type: openai
    model_name: gpt-4
    temperature: 0.7
    max_tokens: 2000
    description: OpenAI GPT-4 - highest quality, requires API key
  gpt-3.5-turbo:
    type: openai
    model_name: gpt-3.5-turbo
    temperature: 0.7
    max_tokens: 2000
    description: OpenAI GPT-3.5 Turbo - fast and cost-effective
  claude-3-5-sonnet-20241022:
    type: anthropic
    model_name: claude-3-5-sonnet-20241022
    temperature: 0.7
    max_tokens: 2000
    description: Anthropic Claude 3.5 Sonnet - balanced performance and reasoning
  claude-3-5-haiku-20241022:
    type: anthropic
    model_name: claude-3-5-haiku-20241022
    temperature: 0.7
    max_tokens: 2000
    description: Anthropic Claude 3.5 Haiku - fast and efficient
  kimi-k2-instruct:
    type: deepinfra
    model_id: moonshotai/Kimi-K2-Instruct
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Kimi K2 Instruct - large-scale MoE language model via DeepInfra
  meta-llama-3-8b-instruct:
    type: deepinfra
    model_id: meta-llama/Meta-Llama-3-8B-Instruct
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Meta Llama 3 8B Instruct - balanced performance model via DeepInfra
  meta-llama-3.1-8b-instruct:
    type: deepinfra
    model_id: meta-llama/Meta-Llama-3.1-8B-Instruct
    temperature: 0.2
    max_tokens: 2000
    repetition_penalty: 1.1
    top_p: 0.9
    description: Meta Llama 3.1 8B Instruct - optimized for code and reasoning via DeepInfra
  mistral-7b-instruct-v0.3:
    type: deepinfra
    model_id: mistralai/Mistral-7B-Instruct-v0.3
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Mistral 7B Instruct v0.3 - excellent instruction following via DeepInfra
  qwen3-32b:
    type: deepinfra
    model_id: Qwen/Qwen3-32B
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Qwen3 32B - high-quality conversational model via DeepInfra
  qwen3-14b:
    type: deepinfra
    model_id: Qwen/Qwen3-14B
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Qwen3 14B - balanced performance model via DeepInfra
  deepseek-v3-turbo:
    type: deepinfra
    model_id: deepseek-ai/DeepSeek-V3-0324-Turbo
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: DeepSeek V3 Turbo - fast and efficient model via DeepInfra
  llama4-maverick-17b:
    type: deepinfra
    model_id: meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo
    temperature: 0.2
    max_tokens: 2000
    repetition_penalty: 1.1
    top_p: 0.9
    description: Llama 4 Maverick 17B - specialized instruction model via DeepInfra
  devstral-small:
    type: deepinfra
    model_id: mistralai/Devstral-Small-2507
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Devstral Small - developer-focused model via DeepInfra
  meta-llama-3.3-70b-instruct-turbo:
    type: deepinfra
    model_id: meta-llama/Llama-3.3-70B-Instruct-Turbo
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Llama 3.3 70B Instruct Turbo - high-performance instruction model via DeepInfra
  gemini-2.5-flash:
    type: deepinfra
    model_id: google/gemini-2.5-flash
    temperature: 0.7
    max_tokens: 2000
    repetition_penalty: 1.2
    top_p: 0.9
    description: Google Gemini 2.5 Flash - fast multimodal model via DeepInfra
use_cases:
  general:
    recommended: local_general_standard
    alternatives:
    - deepinfra_general_standard
    - deepinfra_general_standard_2
    - local_general_budget
    - anthropic_general_standard
    - openai_general_standard
  code:
    recommended: local_coding_standard
    alternatives:
    - deepinfra_coding_standard
    - deepinfra_coding_standard_2
    - anthropic_coding_premium
    - openai_coding_standard
    - local_general_budget
  fast:
    recommended: anthropic_general_budget
    alternatives:
    - deepinfra_general_budget
    - deepinfra_general_budget_2
    - deepinfra_budget_3
    - openai_general_budget
    - local_general_standard
  high_quality:
    recommended: openai_general_standard
    alternatives:
    - deepinfra_reasoning_premium
    - deepinfra_reasoning_premium_2
    - deepinfra_standard_3
    - anthropic_reasoning_premium
    - anthropic_general_standard
    - local_general_budget
    - local_general_premium
fallback_strategy:
  enabled: true
  max_retries: 3
  retry_delay: 5
  default_fallback:
  # Prioritize working DeepInfra models first (fast, serverless)
  - deepinfra_general_standard_2    # moonshotai/Kimi-K2-Instruct (verified working)
  - deepinfra_general_standard_3    # qwen3-32b
 
