# Provider configurations for LLM services and external integrations

llm_providers:
  openai:
    enabled: true
    api_key_env: "OPENAI_API_KEY"
    base_url: "https://api.openai.com/v1"
    timeout: 60
    max_retries: 3
    models:
      - "gpt-4"
      - "gpt-3.5-turbo"
      - "gpt-4-turbo"
    rate_limits:
      requests_per_minute: 500
      tokens_per_minute: 150000
      
  anthropic:
    enabled: true
    api_key_env: "ANTHROPIC_API_KEY"
    base_url: "https://api.anthropic.com"
    timeout: 60
    max_retries: 3
    models:
      - "claude-4-opus"
      - "claude-4-sonnet"
      - "claude-3.5-sonnet"
      - "claude-3.5-haiku"
    rate_limits:
      requests_per_minute: 100
      tokens_per_minute: 40000
      
  local:
    enabled: true
    backend: "ollama"
    base_url: "http://localhost:11434"
    timeout: 120
    max_retries: 2
    models:
      - "llama-7b"
      - "llama-13b"
      - "mistral-7b"
      - "codellama-7b"
    health_check:
      enabled: true
      interval: 30

# External service integrations
external_services:
  langsmith:
    enabled: true
    api_key_env: "LANGCHAIN_API_KEY"
    project_name: "hybrid-ai-system"
    tracing_enabled: true
    
  database:
    type: "sqlite"
    connection_string: "sqlite:///hybrid_system.db"
    pool_size: 10
    max_overflow: 20
    
  redis:
    enabled: false
    host: "localhost"
    port: 6379
    db: 0
    password_env: "REDIS_PASSWORD"
    
  webhook:
    enabled: false
    endpoints:
      escalation: "https://api.example.com/webhooks/escalation"
      completion: "https://api.example.com/webhooks/completion"

# Service discovery and load balancing
service_discovery:
  enabled: false
  consul:
    host: "localhost"
    port: 8500
    service_name: "hybrid-ai-system"
    health_check_interval: 30
    
  load_balancing:
    strategy: "round_robin"
    health_check_enabled: true
    circuit_breaker_enabled: true