primary_model: "local_general_standard"

model_overrides:
  temperature: 0.7
  max_tokens: 2000
  
  # Model-specific overrides
  per_model:
    codellama-7b:
      max_tokens: 3000
      
