primary_model: "anthropic_general_standard"

model_preferences:
  quality_assessment:
    primary: "anthropic_general_standard"
    fallback: ["openai_general_standard", "local_general_standard"]
    
  response_adjustment:
    primary: "anthropic_general_standard"
    fallback: ["openai_general_standard", "local_general_premium"]
    
  context_analysis:
    primary: "anthropic_general_budget"
    fallback: ["openai_general_budget", "local_general_standard"]

model_overrides:
  temperature: 0.3          # Lower temperature for consistent quality assessment
  max_tokens: 1000          # Sufficient for quality analysis
  
  # Task-specific overrides
  per_model:
    quality_assessment:
      temperature: 0.2      # Very low for objective assessment
      max_tokens: 500
      
    response_adjustment:
      temperature: 0.5      # Slightly higher for creative improvement
      max_tokens: 800
      
    context_analysis:
      temperature: 0.3
      max_tokens: 300