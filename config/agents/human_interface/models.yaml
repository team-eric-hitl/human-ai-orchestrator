primary_model: "claude-3-haiku"

model_preferences:
  context_summarization:
    primary: "claude-3-haiku"
    fallback: ["gpt-3.5-turbo", "mistral-7b"]
    
  handoff_formatting:
    primary: "claude-3-haiku"
    fallback: ["gpt-3.5-turbo", "mistral-7b"]
    
  complex_context:
    primary: "claude-3-sonnet"
    fallback: ["gpt-4", "claude-3-haiku"]

model_overrides:
  temperature: 0.5
  max_tokens: 1500
  
  per_model:
    claude-3-haiku:
      temperature: 0.4
      max_tokens: 1200
      
    claude-3-sonnet:
      temperature: 0.6
      max_tokens: 2000