primary_model: "claude-3-haiku"

model_preferences:
  routing_decisions:
    primary: "claude-3-haiku"
    fallback: ["gpt-3.5-turbo", "mistral-7b"]
    
  complex_routing:
    primary: "claude-3-sonnet"
    fallback: ["gpt-4", "claude-3-haiku"]
    
  priority_assessment:
    primary: "gpt-3.5-turbo"
    fallback: ["claude-3-haiku", "mistral-7b"]

model_overrides:
  temperature: 0.4
  max_tokens: 1000
  
  per_model:
    claude-3-haiku:
      temperature: 0.3
      max_tokens: 800
      
    claude-3-sonnet:
      temperature: 0.5
      max_tokens: 1200