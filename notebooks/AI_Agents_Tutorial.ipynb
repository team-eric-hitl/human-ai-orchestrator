{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents and LangGraph: A Beginner's Guide\n",
    "\n",
    "## Welcome to the World of AI Agents! ðŸ¤–\n",
    "\n",
    "This notebook will teach you about **AI Agents** and how they work in this hybrid AI-human system. Don't worry if you're new to programming or AI - we'll explain everything step by step!\n",
    "\n",
    "### What You'll Learn\n",
    "1. **What are AI Agents?** - Simple explanation with real-world analogies\n",
    "2. **How do they work together?** - Understanding the \"workflow\"\n",
    "3. **Hands-on examples** - See the actual code in action\n",
    "4. **Build your own simple agent** - Create a basic AI assistant\n",
    "\n",
    "Let's start with the basics!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are AI Agents? ðŸŽ¯\n",
    "\n",
    "Think of an AI Agent like a **specialized worker** in a company:\n",
    "\n",
    "- **Customer Service Agent**: Answers questions and helps customers\n",
    "- **Quality Inspector**: Checks if work meets standards\n",
    "- **Manager**: Decides when to escalate issues to humans\n",
    "- **Router**: Directs requests to the right department\n",
    "\n",
    "### Real-World Analogy: A Restaurant\n",
    "Imagine you're at a restaurant:\n",
    "\n",
    "1. **Host** (Answer Agent): Greets you, takes your order\n",
    "2. **Kitchen Manager** (Evaluator Agent): Checks if the food quality is good\n",
    "3. **Supervisor** (Escalation Router): Calls the chef if there's a problem\n",
    "4. **Chef** (Human Agent): Fixes complex issues\n",
    "\n",
    "Each \"agent\" has a specific job and passes information to the next one!\n",
    "\n",
    "### In This System\n",
    "Our AI agents work together to help users:\n",
    "- **Answer questions** using AI models\n",
    "- **Evaluate** if the answer is good enough\n",
    "- **Escalate** to humans when needed\n",
    "- **Learn** from interactions to improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Four Main Agents in Our System ðŸ­\n",
    "\n",
    "Let's meet our team of AI agents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up our environment first\n",
    "import sys\n",
    "sys.path.append('/workspace/src')\n",
    "\n",
    "# Import the basic components we'll use\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "import json\n",
    "\n",
    "# Let's create a simple example to show how agents work\n",
    "print(\"ðŸš€ Setting up our AI Agent demonstration...\")\n",
    "print(\"âœ… Ready to explore AI agents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 1: The Answer Agent ðŸŽ¤\n",
    "\n",
    "**Job**: Generate AI responses to user questions\n",
    "\n",
    "**What it does**:\n",
    "- Takes your question\n",
    "- Looks at conversation history for context\n",
    "- Uses an AI model (like GPT or local model) to generate an answer\n",
    "- Saves the interaction for future reference\n",
    "\n",
    "**Think of it as**: The friendly receptionist who first tries to help you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what an Answer Agent looks like in simplified form\n",
    "\n",
    "class SimpleAnswerAgent:\n",
    "    \"\"\"A simplified version of our Answer Agent for learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Answer Agent\"\n",
    "        self.responses = {\n",
    "            \"hello\": \"Hello! How can I help you today?\",\n",
    "            \"weather\": \"I'd be happy to help with weather information, but I need your location.\",\n",
    "            \"code\": \"I can help with programming questions! What language are you using?\",\n",
    "            \"default\": \"I'm here to help! Could you please provide more details?\"\n",
    "        }\n",
    "    \n",
    "    def generate_response(self, user_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate a response to the user's query\"\"\"\n",
    "        \n",
    "        # Simple keyword matching (real system uses advanced AI)\n",
    "        query_lower = user_query.lower()\n",
    "        \n",
    "        if \"hello\" in query_lower or \"hi\" in query_lower:\n",
    "            response = self.responses[\"hello\"]\n",
    "        elif \"weather\" in query_lower:\n",
    "            response = self.responses[\"weather\"]\n",
    "        elif \"code\" in query_lower or \"program\" in query_lower:\n",
    "            response = self.responses[\"code\"]\n",
    "        else:\n",
    "            response = self.responses[\"default\"]\n",
    "        \n",
    "        return {\n",
    "            \"ai_response\": response,\n",
    "            \"confidence\": 0.85,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"next_action\": \"evaluate\"  # Tell the system what to do next\n",
    "        }\n",
    "\n",
    "# Let's try it out!\n",
    "answer_agent = SimpleAnswerAgent()\n",
    "\n",
    "# Test different queries\n",
    "test_queries = [\n",
    "    \"Hello there!\",\n",
    "    \"What's the weather like?\",\n",
    "    \"I need help with Python code\",\n",
    "    \"Tell me about AI agents\"\n",
    "]\n",
    "\n",
    "print(\"ðŸŽ¤ Answer Agent in Action:\\n\")\n",
    "for query in test_queries:\n",
    "    result = answer_agent.generate_response(query)\n",
    "    print(f\"User: {query}\")\n",
    "    print(f\"Agent: {result['ai_response']}\")\n",
    "    print(f\"Confidence: {result['confidence']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 2: The Evaluator Agent ðŸ§\n",
    "\n",
    "**Job**: Check if the AI's answer is good enough\n",
    "\n",
    "**What it does**:\n",
    "- Looks at the AI's response\n",
    "- Scores it on accuracy, completeness, clarity\n",
    "- Considers user history (are they asking the same question again?)\n",
    "- Decides: \"Is this good enough, or should we get human help?\"\n",
    "\n",
    "**Think of it as**: The quality control manager who checks work before it goes to the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEvaluatorAgent:\n",
    "    \"\"\"A simplified version of our Evaluator Agent for learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Evaluator Agent\"\n",
    "        self.escalation_threshold = 6.0  # If score is below this, escalate\n",
    "    \n",
    "    def evaluate_response(self, query: str, ai_response: str, user_history: Dict = None) -> Dict[str, Any]:\n",
    "        \"\"\"Evaluate the quality of an AI response\"\"\"\n",
    "        \n",
    "        # Simple scoring based on response characteristics\n",
    "        accuracy = self._score_accuracy(ai_response)\n",
    "        completeness = self._score_completeness(query, ai_response)\n",
    "        clarity = self._score_clarity(ai_response)\n",
    "        \n",
    "        # Check user context\n",
    "        context_adjustment = self._check_user_context(user_history or {})\n",
    "        \n",
    "        # Calculate overall score\n",
    "        overall_score = (accuracy + completeness + clarity) / 3 + context_adjustment\n",
    "        \n",
    "        # Decide if escalation is needed\n",
    "        should_escalate = overall_score < self.escalation_threshold\n",
    "        \n",
    "        return {\n",
    "            \"overall_score\": round(overall_score, 1),\n",
    "            \"accuracy\": accuracy,\n",
    "            \"completeness\": completeness,\n",
    "            \"clarity\": clarity,\n",
    "            \"should_escalate\": should_escalate,\n",
    "            \"escalation_reason\": \"Low quality score\" if should_escalate else \"Good quality\",\n",
    "            \"next_action\": \"escalate\" if should_escalate else \"respond\"\n",
    "        }\n",
    "    \n",
    "    def _score_accuracy(self, response: str) -> float:\n",
    "        \"\"\"Score the accuracy of the response (simplified)\"\"\"\n",
    "        # In real system, this would use advanced AI evaluation\n",
    "        if \"I don't know\" in response or \"need more details\" in response:\n",
    "            return 7.0  # Honest uncertainty is good\n",
    "        elif len(response) > 20:\n",
    "            return 8.0  # Detailed responses tend to be more accurate\n",
    "        else:\n",
    "            return 6.0\n",
    "    \n",
    "    def _score_completeness(self, query: str, response: str) -> float:\n",
    "        \"\"\"Score how completely the response addresses the query\"\"\"\n",
    "        # Simple heuristic: longer responses for complex queries\n",
    "        if len(query) > 50 and len(response) > 30:\n",
    "            return 8.0\n",
    "        elif \"help\" in response.lower():\n",
    "            return 7.0  # Offering help is good\n",
    "        else:\n",
    "            return 6.5\n",
    "    \n",
    "    def _score_clarity(self, response: str) -> float:\n",
    "        \"\"\"Score how clear and understandable the response is\"\"\"\n",
    "        # Simple metrics: not too long, not too short\n",
    "        if 10 <= len(response) <= 100:\n",
    "            return 8.5\n",
    "        elif len(response) > 200:\n",
    "            return 6.0  # Too wordy\n",
    "        else:\n",
    "            return 7.0\n",
    "    \n",
    "    def _check_user_context(self, user_history: Dict) -> float:\n",
    "        \"\"\"Adjust score based on user context\"\"\"\n",
    "        adjustment = 0.0\n",
    "        \n",
    "        # If user has escalated before, be more careful\n",
    "        if user_history.get(\"previous_escalations\", 0) > 0:\n",
    "            adjustment -= 1.0\n",
    "        \n",
    "        # If user is asking similar questions, might need human help\n",
    "        if user_history.get(\"repeat_query\", False):\n",
    "            adjustment -= 0.5\n",
    "        \n",
    "        return adjustment\n",
    "\n",
    "# Let's test the evaluator!\n",
    "evaluator = SimpleEvaluatorAgent()\n",
    "\n",
    "# Test some responses\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"Hello there!\",\n",
    "        \"response\": \"Hello! How can I help you today?\",\n",
    "        \"user_history\": {}\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Complex technical question about quantum computing\",\n",
    "        \"response\": \"Yes.\",  # Very short response to complex question\n",
    "        \"user_history\": {}\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I need help with my account\",\n",
    "        \"response\": \"I'd be happy to help with account issues, but I need more specific details.\",\n",
    "        \"user_history\": {\"previous_escalations\": 1, \"repeat_query\": True}\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸ§ Evaluator Agent in Action:\\n\")\n",
    "for i, case in enumerate(test_cases, 1):\n",
    "    evaluation = evaluator.evaluate_response(\n",
    "        case[\"query\"], \n",
    "        case[\"response\"], \n",
    "        case[\"user_history\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"Test Case {i}:\")\n",
    "    print(f\"Query: {case['query']}\")\n",
    "    print(f\"Response: {case['response']}\")\n",
    "    print(f\"Overall Score: {evaluation['overall_score']}/10\")\n",
    "    print(f\"Should Escalate: {evaluation['should_escalate']}\")\n",
    "    print(f\"Reason: {evaluation['escalation_reason']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 3: The Escalation Router ðŸš¦\n",
    "\n",
    "**Job**: When AI isn't enough, find the right human to help\n",
    "\n",
    "**What it does**:\n",
    "- Analyzes what kind of help is needed (technical, billing, general)\n",
    "- Determines priority (urgent, normal, low)\n",
    "- Finds available human agents with the right skills\n",
    "- Routes the request to the best person\n",
    "\n",
    "**Think of it as**: The smart receptionist who knows exactly which expert to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEscalationRouter:\n",
    "    \"\"\"A simplified version of our Escalation Router for learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Escalation Router\"\n",
    "        \n",
    "        # Simulated human agents (in real system, this would be dynamic)\n",
    "        self.human_agents = {\n",
    "            \"technical\": [\n",
    "                {\"id\": \"tech_001\", \"name\": \"Alice\", \"available\": True, \"skill_level\": \"senior\"},\n",
    "                {\"id\": \"tech_002\", \"name\": \"Bob\", \"available\": False, \"skill_level\": \"junior\"}\n",
    "            ],\n",
    "            \"billing\": [\n",
    "                {\"id\": \"bill_001\", \"name\": \"Carol\", \"available\": True, \"skill_level\": \"senior\"}\n",
    "            ],\n",
    "            \"general\": [\n",
    "                {\"id\": \"gen_001\", \"name\": \"David\", \"available\": True, \"skill_level\": \"senior\"},\n",
    "                {\"id\": \"gen_002\", \"name\": \"Eve\", \"available\": True, \"skill_level\": \"junior\"}\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def route_escalation(self, query: str, evaluation_result: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Route an escalation to the appropriate human agent\"\"\"\n",
    "        \n",
    "        # 1. Determine what expertise is needed\n",
    "        expertise_needed = self._identify_expertise(query)\n",
    "        \n",
    "        # 2. Calculate priority\n",
    "        priority = self._calculate_priority(query, evaluation_result)\n",
    "        \n",
    "        # 3. Find the best available human agent\n",
    "        assigned_agent = self._find_best_agent(expertise_needed, priority)\n",
    "        \n",
    "        # 4. Create escalation data\n",
    "        return {\n",
    "            \"expertise_needed\": expertise_needed,\n",
    "            \"priority\": priority,\n",
    "            \"assigned_agent\": assigned_agent,\n",
    "            \"estimated_wait_time\": self._estimate_wait_time(priority),\n",
    "            \"escalation_summary\": self._create_summary(query, evaluation_result),\n",
    "            \"next_action\": \"await_human\" if assigned_agent else \"queue_escalation\"\n",
    "        }\n",
    "    \n",
    "    def _identify_expertise(self, query: str) -> str:\n",
    "        \"\"\"Identify what type of expertise is needed\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        technical_keywords = [\"code\", \"programming\", \"api\", \"bug\", \"error\", \"technical\"]\n",
    "        billing_keywords = [\"billing\", \"payment\", \"refund\", \"price\", \"cost\", \"charge\"]\n",
    "        \n",
    "        if any(keyword in query_lower for keyword in technical_keywords):\n",
    "            return \"technical\"\n",
    "        elif any(keyword in query_lower for keyword in billing_keywords):\n",
    "            return \"billing\"\n",
    "        else:\n",
    "            return \"general\"\n",
    "    \n",
    "    def _calculate_priority(self, query: str, evaluation_result: Dict) -> str:\n",
    "        \"\"\"Calculate the priority of the escalation\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # High priority keywords\n",
    "        if any(word in query_lower for word in [\"urgent\", \"critical\", \"broken\", \"down\"]):\n",
    "            return \"high\"\n",
    "        \n",
    "        # Low evaluation score = higher priority\n",
    "        if evaluation_result.get(\"overall_score\", 10) < 4.0:\n",
    "            return \"high\"\n",
    "        elif evaluation_result.get(\"overall_score\", 10) < 6.0:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"low\"\n",
    "    \n",
    "    def _find_best_agent(self, expertise: str, priority: str) -> Dict[str, Any] | None:\n",
    "        \"\"\"Find the best available human agent\"\"\"\n",
    "        available_agents = [\n",
    "            agent for agent in self.human_agents.get(expertise, [])\n",
    "            if agent[\"available\"]\n",
    "        ]\n",
    "        \n",
    "        if not available_agents:\n",
    "            return None\n",
    "        \n",
    "        # For high priority, prefer senior agents\n",
    "        if priority == \"high\":\n",
    "            senior_agents = [agent for agent in available_agents if agent[\"skill_level\"] == \"senior\"]\n",
    "            if senior_agents:\n",
    "                return senior_agents[0]\n",
    "        \n",
    "        # Return first available agent\n",
    "        return available_agents[0]\n",
    "    \n",
    "    def _estimate_wait_time(self, priority: str) -> str:\n",
    "        \"\"\"Estimate how long the user will wait\"\"\"\n",
    "        wait_times = {\n",
    "            \"high\": \"2-5 minutes\",\n",
    "            \"medium\": \"5-15 minutes\",\n",
    "            \"low\": \"15-30 minutes\"\n",
    "        }\n",
    "        return wait_times.get(priority, \"10-20 minutes\")\n",
    "    \n",
    "    def _create_summary(self, query: str, evaluation_result: Dict) -> str:\n",
    "        \"\"\"Create a summary for the human agent\"\"\"\n",
    "        return f\"\"\"ESCALATION SUMMARY:\n",
    "User Query: {query}\n",
    "AI Evaluation Score: {evaluation_result.get('overall_score', 'N/A')}/10\n",
    "Escalation Reason: {evaluation_result.get('escalation_reason', 'Quality threshold not met')}\n",
    "Recommended Action: Provide detailed, personalized assistance\n",
    "\"\"\"\n",
    "\n",
    "# Let's test the router!\n",
    "router = SimpleEscalationRouter()\n",
    "\n",
    "# Test different escalation scenarios\n",
    "test_escalations = [\n",
    "    {\n",
    "        \"query\": \"My Python code is throwing errors and I can't figure out why\",\n",
    "        \"evaluation\": {\"overall_score\": 4.5, \"escalation_reason\": \"Technical complexity\"}\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I was charged twice for my subscription - this is urgent!\",\n",
    "        \"evaluation\": {\"overall_score\": 3.0, \"escalation_reason\": \"Billing issue\"}\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I have a general question about your service\",\n",
    "        \"evaluation\": {\"overall_score\": 5.8, \"escalation_reason\": \"User requested human help\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"ðŸš¦ Escalation Router in Action:\\n\")\n",
    "for i, case in enumerate(test_escalations, 1):\n",
    "    routing = router.route_escalation(case[\"query\"], case[\"evaluation\"])\n",
    "    \n",
    "    print(f\"Escalation Case {i}:\")\n",
    "    print(f\"Query: {case['query']}\")\n",
    "    print(f\"Expertise Needed: {routing['expertise_needed']}\")\n",
    "    print(f\"Priority: {routing['priority']}\")\n",
    "    print(f\"Assigned Agent: {routing['assigned_agent']['name'] if routing['assigned_agent'] else 'None available'}\")\n",
    "    print(f\"Estimated Wait: {routing['estimated_wait_time']}\")\n",
    "    print(f\"Summary: {routing['escalation_summary'][:100]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent 4: The Human Agent Interface ðŸ‘¥\n",
    "\n",
    "**Job**: Facilitate smooth handoffs between AI and human agents\n",
    "\n",
    "**What it does**:\n",
    "- Presents the escalated case to human agents with full context\n",
    "- Manages the conversation while humans are involved\n",
    "- Captures the human's response and feedback\n",
    "- Helps transition back to AI if needed\n",
    "\n",
    "**Think of it as**: The assistant who briefs the expert and helps coordinate the handoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleHumanInterface:\n",
    "    \"\"\"A simplified version of our Human Interface for learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Human Agent Interface\"\n",
    "        self.active_sessions = {}  # Track active human sessions\n",
    "    \n",
    "    def handoff_to_human(self, escalation_data: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Handle the handoff from AI to human agent\"\"\"\n",
    "        \n",
    "        # Create a session for this human interaction\n",
    "        session_id = f\"human_{len(self.active_sessions) + 1}\"\n",
    "        \n",
    "        # Prepare briefing for human agent\n",
    "        briefing = self._prepare_human_briefing(escalation_data)\n",
    "        \n",
    "        # Store session info\n",
    "        self.active_sessions[session_id] = {\n",
    "            \"agent\": escalation_data.get(\"assigned_agent\", {}),\n",
    "            \"start_time\": datetime.now().isoformat(),\n",
    "            \"status\": \"active\",\n",
    "            \"escalation_data\": escalation_data\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            \"session_id\": session_id,\n",
    "            \"human_briefing\": briefing,\n",
    "            \"status\": \"handed_off\",\n",
    "            \"next_action\": \"await_human_response\"\n",
    "        }\n",
    "    \n",
    "    def simulate_human_response(self, session_id: str, user_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Simulate a human agent's response (for demonstration)\"\"\"\n",
    "        \n",
    "        if session_id not in self.active_sessions:\n",
    "            return {\"error\": \"Session not found\"}\n",
    "        \n",
    "        session = self.active_sessions[session_id]\n",
    "        agent_name = session[\"agent\"].get(\"name\", \"Human Agent\")\n",
    "        expertise = session[\"escalation_data\"].get(\"expertise_needed\", \"general\")\n",
    "        \n",
    "        # Generate appropriate human response based on expertise\n",
    "        if expertise == \"technical\":\n",
    "            response = f\"Hi! I'm {agent_name}, a technical specialist. I've reviewed your code issue and here's what I found: [Detailed technical analysis would go here]. Let me walk you through the solution step by step.\"\n",
    "        elif expertise == \"billing\":\n",
    "            response = f\"Hello! I'm {agent_name} from our billing department. I've looked into your account and I can see the duplicate charge. I'm processing a refund right now - you should see it in 1-2 business days.\"\n",
    "        else:\n",
    "            response = f\"Hi there! I'm {agent_name}. I've reviewed your question and I'm here to provide you with personalized assistance. Let me help you with that.\"\n",
    "        \n",
    "        # Update session\n",
    "        session[\"status\"] = \"completed\"\n",
    "        session[\"end_time\"] = datetime.now().isoformat()\n",
    "        \n",
    "        return {\n",
    "            \"session_id\": session_id,\n",
    "            \"human_response\": response,\n",
    "            \"agent_name\": agent_name,\n",
    "            \"resolution_status\": \"resolved\",\n",
    "            \"next_action\": \"collect_feedback\"\n",
    "        }\n",
    "    \n",
    "    def _prepare_human_briefing(self, escalation_data: Dict) -> str:\n",
    "        \"\"\"Prepare a briefing for the human agent\"\"\"\n",
    "        agent_name = escalation_data.get(\"assigned_agent\", {}).get(\"name\", \"Agent\")\n",
    "        \n",
    "        briefing = f\"\"\"ðŸŽ¯ ESCALATION BRIEFING FOR {agent_name.upper()}\n",
    "\n",
    "Priority: {escalation_data.get('priority', 'Medium').upper()}\n",
    "Expertise Required: {escalation_data.get('expertise_needed', 'General')}\n",
    "Estimated Wait Time: {escalation_data.get('estimated_wait_time', 'Unknown')}\n",
    "\n",
    "Context:\n",
    "{escalation_data.get('escalation_summary', 'No summary available')}\n",
    "\n",
    "Recommended Actions:\n",
    "1. Provide detailed, personalized assistance\n",
    "2. Address all aspects of the user's concern\n",
    "3. Explain next steps clearly\n",
    "4. Collect feedback on the resolution\n",
    "\n",
    "Remember: The user has already interacted with our AI system, so they may need more specialized help.\n",
    "\"\"\"\n",
    "        return briefing\n",
    "    \n",
    "    def get_session_info(self, session_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get information about a human session\"\"\"\n",
    "        return self.active_sessions.get(session_id, {\"error\": \"Session not found\"})\n",
    "\n",
    "# Let's test the human interface!\n",
    "human_interface = SimpleHumanInterface()\n",
    "\n",
    "# Simulate a complete handoff process\n",
    "print(\"ðŸ‘¥ Human Agent Interface in Action:\\n\")\n",
    "\n",
    "# Use the escalation from our previous example\n",
    "sample_escalation = {\n",
    "    \"expertise_needed\": \"technical\",\n",
    "    \"priority\": \"high\",\n",
    "    \"assigned_agent\": {\"name\": \"Alice\", \"skill_level\": \"senior\"},\n",
    "    \"estimated_wait_time\": \"2-5 minutes\",\n",
    "    \"escalation_summary\": \"ESCALATION SUMMARY:\\nUser Query: My Python code is throwing errors and I can't figure out why\\nAI Evaluation Score: 4.5/10\\nEscalation Reason: Technical complexity\"\n",
    "}\n",
    "\n",
    "# 1. Handoff to human\n",
    "handoff_result = human_interface.handoff_to_human(sample_escalation)\n",
    "print(\"1. HANDOFF TO HUMAN:\")\n",
    "print(f\"Session ID: {handoff_result['session_id']}\")\n",
    "print(f\"Status: {handoff_result['status']}\")\n",
    "print(\"\\nHuman Agent Briefing:\")\n",
    "print(handoff_result['human_briefing'])\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# 2. Simulate human response\n",
    "human_response = human_interface.simulate_human_response(\n",
    "    handoff_result['session_id'], \n",
    "    \"My Python code is throwing errors and I can't figure out why\"\n",
    ")\n",
    "print(\"2. HUMAN AGENT RESPONSE:\")\n",
    "print(f\"Agent: {human_response['agent_name']}\")\n",
    "print(f\"Response: {human_response['human_response']}\")\n",
    "print(f\"Resolution Status: {human_response['resolution_status']}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# 3. Check session info\n",
    "session_info = human_interface.get_session_info(handoff_result['session_id'])\n",
    "print(\"3. SESSION SUMMARY:\")\n",
    "print(f\"Status: {session_info['status']}\")\n",
    "print(f\"Duration: {session_info['start_time']} to {session_info.get('end_time', 'ongoing')}\")\n",
    "print(f\"Agent: {session_info['agent']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How They Work Together: The Complete Workflow ðŸ”„\n",
    "\n",
    "Now let's see how all these agents work together in a real scenario! This is called a \"workflow\" - like an assembly line where each worker has a specific job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleHybridWorkflow:\n",
    "    \"\"\"A simplified version of our complete workflow for learning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.answer_agent = SimpleAnswerAgent()\n",
    "        self.evaluator = SimpleEvaluatorAgent()\n",
    "        self.router = SimpleEscalationRouter()\n",
    "        self.human_interface = SimpleHumanInterface()\n",
    "    \n",
    "    def process_user_query(self, query: str, user_id: str = \"user123\") -> Dict[str, Any]:\n",
    "        \"\"\"Process a complete user query through the workflow\"\"\"\n",
    "        \n",
    "        print(f\"ðŸŽ¯ Processing query: '{query}'\\n\")\n",
    "        \n",
    "        # Step 1: Answer Agent generates response\n",
    "        print(\"ðŸ“ Step 1: AI generates initial response...\")\n",
    "        answer_result = self.answer_agent.generate_response(query)\n",
    "        print(f\"   AI Response: {answer_result['ai_response']}\")\n",
    "        print(f\"   Confidence: {answer_result['confidence']}\")\n",
    "        print()\n",
    "        \n",
    "        # Step 2: Evaluator checks quality\n",
    "        print(\"ðŸ§ Step 2: Evaluating response quality...\")\n",
    "        evaluation = self.evaluator.evaluate_response(\n",
    "            query, \n",
    "            answer_result['ai_response'],\n",
    "            {\"previous_escalations\": 0, \"repeat_query\": False}  # Sample user history\n",
    "        )\n",
    "        print(f\"   Quality Score: {evaluation['overall_score']}/10\")\n",
    "        print(f\"   Should Escalate: {evaluation['should_escalate']}\")\n",
    "        print()\n",
    "        \n",
    "        # Step 3: Decision point - escalate or respond?\n",
    "        if evaluation['should_escalate']:\n",
    "            print(\"ðŸš¦ Step 3: Escalating to human agent...\")\n",
    "            \n",
    "            # Route to human\n",
    "            routing = self.router.route_escalation(query, evaluation)\n",
    "            print(f\"   Expertise Needed: {routing['expertise_needed']}\")\n",
    "            print(f\"   Priority: {routing['priority']}\")\n",
    "            print(f\"   Assigned Agent: {routing['assigned_agent']['name'] if routing['assigned_agent'] else 'None available'}\")\n",
    "            print()\n",
    "            \n",
    "            if routing['assigned_agent']:\n",
    "                print(\"ðŸ‘¥ Step 4: Handing off to human agent...\")\n",
    "                handoff = self.human_interface.handoff_to_human(routing)\n",
    "                print(f\"   Session ID: {handoff['session_id']}\")\n",
    "                print(f\"   Status: {handoff['status']}\")\n",
    "                print()\n",
    "                \n",
    "                print(\"ðŸ¤ Step 5: Human agent responds...\")\n",
    "                human_response = self.human_interface.simulate_human_response(\n",
    "                    handoff['session_id'], query\n",
    "                )\n",
    "                print(f\"   Human Response: {human_response['human_response'][:100]}...\")\n",
    "                print(f\"   Resolution: {human_response['resolution_status']}\")\n",
    "                \n",
    "                final_response = human_response['human_response']\n",
    "                resolution_method = \"human_agent\"\n",
    "            else:\n",
    "                final_response = \"I'm sorry, all our human agents are currently busy. You've been added to the queue.\"\n",
    "                resolution_method = \"queued\"\n",
    "        else:\n",
    "            print(\"âœ… Step 3: AI response approved - sending to user\")\n",
    "            final_response = answer_result['ai_response']\n",
    "            resolution_method = \"ai_agent\"\n",
    "        \n",
    "        print()\n",
    "        print(\"=\"*60)\n",
    "        print(f\"ðŸŽ‰ FINAL RESULT:\")\n",
    "        print(f\"Response: {final_response}\")\n",
    "        print(f\"Resolved by: {resolution_method}\")\n",
    "        print(f\"Quality Score: {evaluation['overall_score']}/10\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"final_response\": final_response,\n",
    "            \"resolution_method\": resolution_method,\n",
    "            \"quality_score\": evaluation['overall_score'],\n",
    "            \"escalated\": evaluation['should_escalate']\n",
    "        }\n",
    "\n",
    "# Create our workflow\n",
    "workflow = SimpleHybridWorkflow()\n",
    "\n",
    "# Test different scenarios\n",
    "test_scenarios = [\n",
    "    \"Hello! How are you today?\",  # Simple query - should be handled by AI\n",
    "    \"My server is down and I need immediate help!\",  # Complex/urgent - should escalate\n",
    "    \"Can you help me with my account?\",  # Medium complexity\n",
    "]\n",
    "\n",
    "print(\"ðŸ”„ COMPLETE WORKFLOW DEMONSTRATION\\n\")\n",
    "print(\"Let's see how different types of queries flow through our system:\\n\")\n",
    "\n",
    "for i, scenario in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\n{'='*20} SCENARIO {i} {'='*20}\")\n",
    "    result = workflow.process_user_query(scenario)\n",
    "    print(f\"\\n{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding the Real System Architecture ðŸ—ï¸\n",
    "\n",
    "Now that you understand the basics, let's look at how this project actually implements these concepts using advanced AI technologies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the real system components\n",
    "print(\"ðŸ—ï¸ REAL SYSTEM ARCHITECTURE\\n\")\n",
    "\n",
    "# 1. State Management\n",
    "print(\"1. STATE MANAGEMENT:\")\n",
    "print(\"   - Uses TypedDict for type safety\")\n",
    "print(\"   - Tracks conversation history, user context, and metrics\")\n",
    "print(\"   - Compatible with LangChain message format\")\n",
    "print()\n",
    "\n",
    "# 2. LLM Integration\n",
    "print(\"2. LLM INTEGRATION:\")\n",
    "print(\"   - Supports multiple AI models (OpenAI, Anthropic, Local models)\")\n",
    "print(\"   - Automatic fallback between models\")\n",
    "print(\"   - Configurable through YAML files\")\n",
    "print()\n",
    "\n",
    "# 3. Advanced Features\n",
    "print(\"3. ADVANCED FEATURES:\")\n",
    "print(\"   - LangSmith tracing for monitoring\")\n",
    "print(\"   - SQLite for persistent context storage\")\n",
    "print(\"   - Comprehensive error handling and logging\")\n",
    "print(\"   - Modular design with clear interfaces\")\n",
    "print()\n",
    "\n",
    "# Let's show the actual state schema\n",
    "print(\"ðŸ“‹ EXAMPLE OF REAL SYSTEM STATE:\")\n",
    "real_state_example = {\n",
    "    \"query_id\": \"q_20240101_001\",\n",
    "    \"user_id\": \"user_123\",\n",
    "    \"session_id\": \"session_456\",\n",
    "    \"timestamp\": \"2024-01-01T10:00:00Z\",\n",
    "    \"query\": \"How do I implement a binary search tree?\",\n",
    "    \"messages\": [],  # LangChain messages\n",
    "    \"ai_response\": \"Here's how to implement a binary search tree...\",\n",
    "    \"evaluation_result\": {\n",
    "        \"overall_score\": 8.5,\n",
    "        \"accuracy\": 9.0,\n",
    "        \"completeness\": 8.0,\n",
    "        \"clarity\": 8.5,\n",
    "        \"confidence\": 0.85\n",
    "    },\n",
    "    \"escalation_decision\": False,\n",
    "    \"next_action\": \"respond\",\n",
    "    \"node_execution_times\": {\n",
    "        \"answer_agent\": 2.3,\n",
    "        \"evaluator_agent\": 0.8\n",
    "    },\n",
    "    \"total_tokens_used\": 150,\n",
    "    \"total_cost_usd\": 0.003\n",
    "}\n",
    "\n",
    "print(json.dumps(real_state_example, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configuration and Setup ðŸ› ï¸\n",
    "\n",
    "The real system uses configuration files to manage different AI models and settings. Let's see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the configuration system\n",
    "print(\"âš™ï¸ CONFIGURATION SYSTEM\\n\")\n",
    "\n",
    "# Model configuration example\n",
    "model_config_example = {\n",
    "    \"models\": {\n",
    "        \"llama-7b\": {\n",
    "            \"path\": \"models/llama-7b.gguf\",\n",
    "            \"type\": \"llama\",\n",
    "            \"context_length\": 2048,\n",
    "            \"temperature\": 0.7,\n",
    "            \"description\": \"Local Llama model for general use\"\n",
    "        },\n",
    "        \"gpt-4\": {\n",
    "            \"type\": \"openai\",\n",
    "            \"model_name\": \"gpt-4\",\n",
    "            \"temperature\": 0.7,\n",
    "            \"description\": \"OpenAI GPT-4 - highest quality\"\n",
    "        }\n",
    "    },\n",
    "    \"default_model\": \"llama-7b\",\n",
    "    \"fallback_models\": [\"gpt-4\", \"claude-3-sonnet\"]\n",
    "}\n",
    "\n",
    "print(\"ðŸ“ MODEL CONFIGURATION:\")\n",
    "print(json.dumps(model_config_example, indent=2))\n",
    "print()\n",
    "\n",
    "# Prompts configuration\n",
    "prompts_config_example = {\n",
    "    \"answer_agent\": {\n",
    "        \"system_prompt\": \"You are a helpful AI assistant...\",\n",
    "        \"context_integration\": \"Use previous conversation context...\"\n",
    "    },\n",
    "    \"evaluator_agent\": {\n",
    "        \"system_prompt\": \"You are an evaluation specialist...\",\n",
    "        \"escalation_thresholds\": {\n",
    "            \"low_score\": 4.0,\n",
    "            \"repeat_query\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ðŸ’¬ PROMPTS CONFIGURATION:\")\n",
    "print(json.dumps(prompts_config_example, indent=2))\n",
    "print()\n",
    "\n",
    "# How to use the real system\n",
    "print(\"ðŸš€ HOW TO USE THE REAL SYSTEM:\")\n",
    "print(\"1. Set up environment variables:\")\n",
    "print(\"   export OPENAI_API_KEY=your_key_here\")\n",
    "print(\"   export ANTHROPIC_API_KEY=your_key_here\")\n",
    "print()\n",
    "print(\"2. Install dependencies:\")\n",
    "print(\"   make setup\")\n",
    "print()\n",
    "print(\"3. Run the system:\")\n",
    "print(\"   make run\")\n",
    "print()\n",
    "print(\"4. Run tests:\")\n",
    "print(\"   make test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build Your Own Simple Agent ðŸ”¨\n",
    "\n",
    "Now it's your turn! Let's build a simple agent together. This will help you understand how to create your own AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple agent that helps with programming questions\n",
    "\n",
    "class SimpleProgrammingAgent:\n",
    "    \"\"\"A simple agent that helps with programming questions\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Programming Helper\"\n",
    "        self.expertise = \"programming\"\n",
    "        \n",
    "        # Simple knowledge base\n",
    "        self.knowledge_base = {\n",
    "            \"python\": {\n",
    "                \"loops\": \"Use 'for' loops to iterate over sequences, 'while' loops for conditions\",\n",
    "                \"functions\": \"Define functions with 'def function_name(parameters):'\",\n",
    "                \"variables\": \"Variables store data: name = 'value'\"\n",
    "            },\n",
    "            \"javascript\": {\n",
    "                \"variables\": \"Use let, const, or var to declare variables\",\n",
    "                \"functions\": \"Functions: function name() {} or const name = () => {}\",\n",
    "                \"loops\": \"Use for, while, or forEach for iterations\"\n",
    "            },\n",
    "            \"general\": {\n",
    "                \"debugging\": \"1. Read error messages carefully, 2. Check syntax, 3. Use print statements\",\n",
    "                \"best_practices\": \"Write clean code, use meaningful names, comment your code\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a programming question\"\"\"\n",
    "        \n",
    "        # Identify programming language\n",
    "        language = self._identify_language(query)\n",
    "        \n",
    "        # Find relevant topic\n",
    "        topic = self._identify_topic(query)\n",
    "        \n",
    "        # Generate response\n",
    "        response = self._generate_response(language, topic, query)\n",
    "        \n",
    "        # Provide additional resources\n",
    "        resources = self._suggest_resources(language, topic)\n",
    "        \n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"language\": language,\n",
    "            \"topic\": topic,\n",
    "            \"resources\": resources,\n",
    "            \"confidence\": self._calculate_confidence(language, topic)\n",
    "        }\n",
    "    \n",
    "    def _identify_language(self, query: str) -> str:\n",
    "        \"\"\"Identify the programming language from the query\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        if \"python\" in query_lower or \"py\" in query_lower:\n",
    "            return \"python\"\n",
    "        elif \"javascript\" in query_lower or \"js\" in query_lower:\n",
    "            return \"javascript\"\n",
    "        else:\n",
    "            return \"general\"\n",
    "    \n",
    "    def _identify_topic(self, query: str) -> str:\n",
    "        \"\"\"Identify the topic from the query\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        if \"loop\" in query_lower or \"for\" in query_lower or \"while\" in query_lower:\n",
    "            return \"loops\"\n",
    "        elif \"function\" in query_lower or \"def\" in query_lower:\n",
    "            return \"functions\"\n",
    "        elif \"variable\" in query_lower or \"var\" in query_lower:\n",
    "            return \"variables\"\n",
    "        elif \"debug\" in query_lower or \"error\" in query_lower:\n",
    "            return \"debugging\"\n",
    "        else:\n",
    "            return \"best_practices\"\n",
    "    \n",
    "    def _generate_response(self, language: str, topic: str, query: str) -> str:\n",
    "        \"\"\"Generate a response based on language and topic\"\"\"\n",
    "        \n",
    "        # Get base knowledge\n",
    "        knowledge = self.knowledge_base.get(language, {}).get(topic)\n",
    "        \n",
    "        if not knowledge:\n",
    "            knowledge = self.knowledge_base.get(\"general\", {}).get(topic, \n",
    "                \"I'd be happy to help with programming questions!\")\n",
    "        \n",
    "        # Create personalized response\n",
    "        response = f\"Great question about {topic}!\"\n",
    "        \n",
    "        if language != \"general\":\n",
    "            response += f\" For {language.title()}: {knowledge}\"\n",
    "        else:\n",
    "            response += f\" {knowledge}\"\n",
    "        \n",
    "        # Add encouragement\n",
    "        response += \" Feel free to ask if you need more specific help!\"\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def _suggest_resources(self, language: str, topic: str) -> List[str]:\n",
    "        \"\"\"Suggest helpful resources\"\"\"\n",
    "        resources = []\n",
    "        \n",
    "        if language == \"python\":\n",
    "            resources.extend([\n",
    "                \"Python.org official documentation\",\n",
    "                \"Python tutorial on W3Schools\",\n",
    "                \"'Automate the Boring Stuff with Python' (free online book)\"\n",
    "            ])\n",
    "        elif language == \"javascript\":\n",
    "            resources.extend([\n",
    "                \"MDN Web Docs for JavaScript\",\n",
    "                \"JavaScript.info tutorial\",\n",
    "                \"FreeCodeCamp JavaScript course\"\n",
    "            ])\n",
    "        \n",
    "        resources.extend([\n",
    "            \"Stack Overflow for specific questions\",\n",
    "            \"GitHub for code examples\",\n",
    "            \"Practice coding on LeetCode or HackerRank\"\n",
    "        ])\n",
    "        \n",
    "        return resources[:3]  # Return top 3 resources\n",
    "    \n",
    "    def _calculate_confidence(self, language: str, topic: str) -> float:\n",
    "        \"\"\"Calculate confidence in the response\"\"\"\n",
    "        if language in self.knowledge_base and topic in self.knowledge_base[language]:\n",
    "            return 0.9\n",
    "        elif language == \"general\" and topic in self.knowledge_base[\"general\"]:\n",
    "            return 0.8\n",
    "        else:\n",
    "            return 0.6\n",
    "\n",
    "# Let's test our custom agent!\n",
    "programming_agent = SimpleProgrammingAgent()\n",
    "\n",
    "# Test different programming questions\n",
    "test_questions = [\n",
    "    \"How do I create a for loop in Python?\",\n",
    "    \"What's the difference between let and var in JavaScript?\",\n",
    "    \"I'm getting an error in my code, how do I debug it?\",\n",
    "    \"How do I write better code?\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ”¨ YOUR CUSTOM PROGRAMMING AGENT IN ACTION!\\n\")\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    result = programming_agent.process_query(question)\n",
    "    \n",
    "    print(f\"Language: {result['language']}\")\n",
    "    print(f\"Topic: {result['topic']}\")\n",
    "    print(f\"Response: {result['response']}\")\n",
    "    print(f\"Confidence: {result['confidence']}\")\n",
    "    print(f\"Resources: {', '.join(result['resources'])}\")\n",
    "    print(\"-\" * 60)\n",
    "    print()\n",
    "\n",
    "print(\"ðŸŽ‰ Congratulations! You've built your own AI agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Concepts Summary ðŸ“š\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "1. **AI Agents are Specialized Workers**: Each agent has a specific job (answer questions, evaluate quality, route escalations, etc.)\n",
    "\n",
    "2. **Workflows Connect Agents**: Like an assembly line, agents pass work to each other in a specific order\n",
    "\n",
    "3. **State Management**: The system keeps track of the conversation, user context, and decisions made\n",
    "\n",
    "4. **Human-in-the-Loop**: When AI isn't enough, the system smoothly hands off to human experts\n",
    "\n",
    "5. **Configuration-Driven**: The system uses files to configure different AI models and behaviors\n",
    "\n",
    "### Key Technologies Used\n",
    "\n",
    "- **LangGraph**: Framework for building multi-agent workflows\n",
    "- **LangChain**: Library for working with language models\n",
    "- **LangSmith**: Monitoring and tracing for AI applications\n",
    "- **Multiple LLMs**: OpenAI, Anthropic, and local models\n",
    "- **SQLite**: Database for storing conversation context\n",
    "- **Python**: Programming language for the entire system\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "This type of system is used in:\n",
    "- **Customer Support**: Automated help with human escalation\n",
    "- **Technical Documentation**: AI-powered help systems\n",
    "- **Educational Platforms**: Personalized tutoring with teacher oversight\n",
    "- **Healthcare**: Initial screening with doctor consultation\n",
    "- **Legal Services**: Document review with lawyer validation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To continue learning:\n",
    "1. **Explore the Code**: Look at the actual implementation in `/workspace/src/`\n",
    "2. **Run the Tests**: Try `make test` to see how the system is tested\n",
    "3. **Modify Configuration**: Change `/workspace/config/` files to customize behavior\n",
    "4. **Build Your Own**: Create new agents following the patterns you've learned\n",
    "5. **Study LangGraph**: Learn more about building multi-agent systems\n",
    "\n",
    "Remember: AI agents are just programs that make decisions and take actions. The \"intelligence\" comes from the language models they use and how they're connected together!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
