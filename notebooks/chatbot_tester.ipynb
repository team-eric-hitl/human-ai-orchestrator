{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Chatbot Agent Testing Notebook\n\nThis notebook provides a user-friendly interface for testing and experimenting with the Chatbot Agent.\nIt's designed for users with little programming experience.\n\n## Features:\n- Load and edit agent configuration settings\n- Generate or load test questions\n- Process questions through the Chatbot Agent\n- Review and analyze results\n- Export results with timestamps\n\n## Getting Started:\n1. Run cells in order from top to bottom\n2. Edit configuration values as needed\n3. Generate or load test questions\n4. Review questions before processing\n5. Run the agent and review results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import required libraries\nimport json\nimport yaml\nimport os\nimport sys\nfrom datetime import datetime\nimport pandas as pd\nfrom pathlib import Path\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML, clear_output\n\n# Set the working directory to the root of the project\nos.chdir('/workspace')\n\n# Add workspace to path for imports (this helps with relative imports)\nsys.path.insert(0, '/workspace')\n\n# Import our system components\nfrom src.nodes.chatbot_agent import ChatbotAgentNode\nfrom src.core.config.agent_config_manager import AgentConfigManager\nfrom src.integrations.llm_providers import LLMProviderFactory\n\nprint(\"‚úÖ All libraries imported successfully!\")\nprint(\"Ready to start testing the Chatbot Agent.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Load Configuration Settings\n\nThe following cell loads the current configuration for the Chatbot Agent.\nYou can edit these values to customize the agent's behavior."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load configuration from files\nconfig_base_path = Path('/workspace/config')\nagent_config_path = config_base_path / 'agents' / 'chatbot_agent'\n\ndef load_config_files():\n    \"\"\"Load all configuration files for the Chatbot Agent\"\"\"\n    configs = {}\n    \n    # Load agent config\n    with open(agent_config_path / 'config.yaml', 'r') as f:\n        configs['agent'] = yaml.safe_load(f)\n    \n    # Load prompts\n    with open(agent_config_path / 'prompts.yaml', 'r') as f:\n        configs['prompts'] = yaml.safe_load(f)\n    \n    # Load models\n    with open(agent_config_path / 'models.yaml', 'r') as f:\n        configs['models'] = yaml.safe_load(f)\n    \n    # Load shared models for reference\n    with open(config_base_path / 'shared' / 'models.yaml', 'r') as f:\n        configs['shared_models'] = yaml.safe_load(f)\n    \n    return configs\n\n# Load configurations\nconfigs = load_config_files()\n\nprint(\"üìÅ Configuration files loaded successfully!\")\nprint(f\"Agent name: {configs['agent']['agent']['name']}\")\nprint(f\"Agent version: {configs['agent']['agent']['version']}\")\nprint(f\"Preferred model: {configs['agent']['models']['preferred']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Editable Configuration Settings\n\nEdit these settings to customize how the Chatbot Agent behaves.\nThese variables map directly to the configuration files and can be exported later."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configuration variables loaded and ready for editing!\n",
      "\n",
      "Current literal values (you can copy these to edit the variables above):\n",
      "agent_preferred_model = 'anthropic_general_budget'\n",
      "agent_fallback_models = ['local_general_budget', 'local_general_standard']\n",
      "agent_temperature = 0.7\n",
      "agent_max_tokens = 2000\n",
      "agent_timeout = 30\n",
      "agent_response_style = 'clear_and_professional'\n",
      "agent_context_integration = True\n",
      "agent_personalization = True\n",
      "agent_confidence_threshold = 0.7\n",
      "agent_auto_escalation = True\n",
      "agent_escalation_triggers = ['low_confidence', 'user_dissatisfaction', 'repeat_query']\n",
      "agent_prompt_style = 'Warm, professional customer service tone'\n",
      "agent_include_empathy = True\n",
      "agent_customer_focus = True\n",
      "\n",
      "üí° Copy any of these lines above to edit the variables, then re-run this cell to apply changes.\n",
      "üìù After editing, the new values will be used when processing questions.\n"
     ]
    }
   ],
   "source": [
    "# EDITABLE CONFIGURATION VARIABLES\n",
    "# These can be modified to customize the agent behavior\n",
    "\n",
    "# === MODEL SETTINGS ===\n",
    "agent_preferred_model = configs['agent']['models']['preferred']  # Which model to use first\n",
    "agent_fallback_models = configs['agent']['models']['fallback']  # Backup models if primary fails\n",
    "agent_temperature = configs['agent']['settings']['temperature']  # Creativity level (0.0-1.0)\n",
    "agent_max_tokens = configs['agent']['settings']['max_tokens']  # Maximum response length\n",
    "agent_timeout = configs['agent']['settings']['timeout']  # Timeout in seconds\n",
    "\n",
    "# === BEHAVIOR SETTINGS ===\n",
    "agent_response_style = configs['agent']['behavior']['response_style']  # How the agent responds\n",
    "agent_context_integration = configs['agent']['behavior']['context_integration']  # Use conversation history\n",
    "agent_personalization = configs['agent']['behavior']['personalization']  # Personalize responses\n",
    "\n",
    "# === ESCALATION SETTINGS ===\n",
    "agent_confidence_threshold = configs['agent']['escalation']['confidence_threshold']  # When to escalate (0.0-1.0)\n",
    "agent_auto_escalation = configs['agent']['escalation']['enable_auto_escalation']  # Enable automatic escalation\n",
    "agent_escalation_triggers = configs['agent']['escalation']['escalation_triggers']  # What triggers escalation\n",
    "\n",
    "# === PROMPT STYLE ===\n",
    "agent_prompt_style = configs['prompts']['response_guidelines']['style']  # Communication style\n",
    "agent_include_empathy = configs['prompts']['response_guidelines']['include_empathy']  # Show empathy\n",
    "agent_customer_focus = configs['prompts']['response_guidelines']['customer_focus']  # Focus on customer needs\n",
    "\n",
    "# Display current literal values for easy editing\n",
    "print(\"‚öôÔ∏è Configuration variables loaded and ready for editing!\")\n",
    "print(\"\\nCurrent literal values (you can copy these to edit the variables above):\")\n",
    "print(f\"agent_preferred_model = '{agent_preferred_model}'\")\n",
    "print(f\"agent_fallback_models = {agent_fallback_models}\")\n",
    "print(f\"agent_temperature = {agent_temperature}\")\n",
    "print(f\"agent_max_tokens = {agent_max_tokens}\")\n",
    "print(f\"agent_timeout = {agent_timeout}\")\n",
    "print(f\"agent_response_style = '{agent_response_style}'\")\n",
    "print(f\"agent_context_integration = {agent_context_integration}\")\n",
    "print(f\"agent_personalization = {agent_personalization}\")\n",
    "print(f\"agent_confidence_threshold = {agent_confidence_threshold}\")\n",
    "print(f\"agent_auto_escalation = {agent_auto_escalation}\")\n",
    "print(f\"agent_escalation_triggers = {agent_escalation_triggers}\")\n",
    "print(f\"agent_prompt_style = '{agent_prompt_style}'\")\n",
    "print(f\"agent_include_empathy = {agent_include_empathy}\")\n",
    "print(f\"agent_customer_focus = {agent_customer_focus}\")\n",
    "\n",
    "print(\"\\nüí° Copy any of these lines above to edit the variables, then re-run this cell to apply changes.\")\n",
    "print(\"üìù After editing, the new values will be used when processing questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Input Generation or Loading\n",
    "\n",
    "Choose whether to generate new test questions or load existing ones from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Input Configuration\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbefe2ffc5ef43198d5c7a2ac3d418a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Input source:', options=(('Generate new questions', 'generate'), ('Load from file', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For generation, describe your test scenario:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7425b48a40e14e9e89d829fef0d6d0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='20 chatbot questions from users contacting their insurance company about their coverage. Some ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384ac91862554075ae866b94bdbb2be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Generation model:', index=1, options=('anthropic_general_budget', 'anthropic_general_sta‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For file loading:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf33e312d3e444ab18122c3de6cecc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.json,.txt,.csv', description='Upload file:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create input generation interface\n",
    "input_choice = widgets.RadioButtons(\n",
    "    options=[('Generate new questions', 'generate'), ('Load from file', 'load')],\n",
    "    description='Input source:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Text area for describing what kind of inputs to generate\n",
    "generation_prompt = widgets.Textarea(\n",
    "    value=\"20 chatbot questions from users contacting their insurance company about their coverage. Some users are belligerent, some are confused and need simple explanations, some need information immediately about claims, some are asking about policy changes. Mix of simple and complex questions.\",\n",
    "    placeholder=\"Describe what kind of test questions you want...\",\n",
    "    description=\"Generation prompt:\",\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "# Model choice for generation\n",
    "available_models = list(configs['shared_models']['model_aliases'].keys())\n",
    "generation_model = widgets.Dropdown(\n",
    "    options=available_models,\n",
    "    value='anthropic_general_standard',\n",
    "    description='Generation model:',\n",
    ")\n",
    "\n",
    "# File upload widget\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='.json,.txt,.csv',\n",
    "    multiple=False,\n",
    "    description='Upload file:'\n",
    ")\n",
    "\n",
    "print(\"üìù Input Configuration\")\n",
    "display(input_choice)\n",
    "print(\"\\nFor generation, describe your test scenario:\")\n",
    "display(generation_prompt)\n",
    "display(generation_model)\n",
    "print(\"\\nFor file loading:\")\n",
    "display(file_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Generating test questions using anthropic_general_standard...\n",
      "‚úÖ Creating LLM provider: anthropic_general_standard ‚Üí claude-3-5-sonnet-20241022 (anthropic)\n",
      "‚úÖ 12:58:29.964 [INFO    ] claude-3-5-sonnet-20241022 | Initializing LLM provider | model_name=claude-3-5-sonnet-20241022\n",
      "‚úÖ 12:58:29.967 [INFO    ] claude-3-5-sonnet-20241022 | LLM provider initialized successfully | model_name=claude-3-5-sonnet-20241022\n",
      "‚úÖ 12:58:54.050 [INFO    ] claude-3-5-sonnet-20241022 | Model call: claude-3-5-sonnet-20241022 - generate_response | model_name=claude-3-5-sonnet-20241022 operation=generate_response\n",
      "üìù Raw response: [\n",
      "    {\"id\": 1, \"question\": \"I just had a car accident 10 minutes ago, what do I need to do right now??\", \"customer_type\": \"urgent\", \"complexity\": \"simple\"},\n",
      "    {\"id\": 2, \"question\": \"Why the hell di...\n",
      "‚úÖ Generated 20 test questions\n",
      "\n",
      "üìã Preview of test questions:\n",
      "  1. I just had a car accident 10 minutes ago, what do I need to do right now?? [urgent]\n",
      "  2. Why the hell did my premium go up by $200? This is ridiculous and I want answers NOW! [frustrated]\n",
      "  3. I don't understand my deductible. Can you explain what that means in simple terms? [confused]\n",
      "  ... and 17 more questions\n"
     ]
    }
   ],
   "source": [
    "# Generate or load test questions\n",
    "test_questions = []\n",
    "\n",
    "def generate_test_questions(prompt, model_name, count=20):\n",
    "    \"\"\"Generate test questions using the specified model\"\"\"\n",
    "    print(f\"ü§ñ Generating test questions using {model_name}...\")\n",
    "    \n",
    "    # Create a simple generation prompt\n",
    "    generation_system_prompt = f\"\"\"\n",
    "    Generate exactly {count} realistic customer service questions based on this scenario:\n",
    "    {prompt}\n",
    "    \n",
    "    Return the questions as a JSON array with this format:\n",
    "    [\n",
    "        {{\"id\": 1, \"question\": \"Question text here\", \"customer_type\": \"frustrated/confused/urgent/normal\", \"complexity\": \"simple/medium/complex\"}},\n",
    "        {{\"id\": 2, \"question\": \"Another question\", \"customer_type\": \"normal\", \"complexity\": \"medium\"}}\n",
    "    ]\n",
    "    \n",
    "    Make the questions diverse and realistic. Include the customer emotional state and complexity level.\n",
    "    IMPORTANT: Return ONLY the JSON array, no other text.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Initialize model provider factory\n",
    "        factory = LLMProviderFactory()\n",
    "        provider = factory.create_provider(model_name)\n",
    "        \n",
    "        # Generate questions\n",
    "        response = provider.generate_response(\n",
    "            prompt=\"Generate the test questions now.\",\n",
    "            system_prompt=generation_system_prompt\n",
    "        )\n",
    "        \n",
    "        print(f\"üìù Raw response: {response[:200]}...\")\n",
    "        \n",
    "        # Clean up the response - remove any markdown formatting\n",
    "        cleaned_response = response.strip()\n",
    "        if cleaned_response.startswith('```json'):\n",
    "            cleaned_response = cleaned_response[7:]  # Remove ```json\n",
    "        if cleaned_response.endswith('```'):\n",
    "            cleaned_response = cleaned_response[:-3]  # Remove ```\n",
    "        cleaned_response = cleaned_response.strip()\n",
    "        \n",
    "        # Parse JSON response\n",
    "        questions_data = json.loads(cleaned_response)\n",
    "        \n",
    "        # Ensure we have a list\n",
    "        if isinstance(questions_data, dict):\n",
    "            questions_data = [questions_data]\n",
    "        elif not isinstance(questions_data, list):\n",
    "            raise ValueError(f\"Expected list or dict, got {type(questions_data)}\")\n",
    "        \n",
    "        # Validate each question has required fields\n",
    "        validated_questions = []\n",
    "        for i, q in enumerate(questions_data):\n",
    "            if isinstance(q, dict):\n",
    "                # Ensure required fields exist\n",
    "                validated_q = {\n",
    "                    \"id\": q.get(\"id\", i + 1),\n",
    "                    \"question\": q.get(\"question\", f\"Question {i + 1}\"),\n",
    "                    \"customer_type\": q.get(\"customer_type\", \"normal\"),\n",
    "                    \"complexity\": q.get(\"complexity\", \"medium\")\n",
    "                }\n",
    "                validated_questions.append(validated_q)\n",
    "            else:\n",
    "                # Convert string to dict if needed\n",
    "                validated_q = {\n",
    "                    \"id\": i + 1,\n",
    "                    \"question\": str(q),\n",
    "                    \"customer_type\": \"normal\",\n",
    "                    \"complexity\": \"medium\"\n",
    "                }\n",
    "                validated_questions.append(validated_q)\n",
    "        \n",
    "        return validated_questions\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON parsing error: {e}\")\n",
    "        print(f\"üìù Raw response that failed to parse: {response}\")\n",
    "        # Return sample questions as fallback\n",
    "        return [\n",
    "            {\"id\": 1, \"question\": \"I need to file a claim for my car accident yesterday\", \"customer_type\": \"urgent\", \"complexity\": \"medium\"},\n",
    "            {\"id\": 2, \"question\": \"What does my insurance cover exactly?\", \"customer_type\": \"confused\", \"complexity\": \"simple\"},\n",
    "            {\"id\": 3, \"question\": \"Why did my premium go up this month? I haven't had any accidents!\", \"customer_type\": \"frustrated\", \"complexity\": \"medium\"}\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating questions: {e}\")\n",
    "        # Return sample questions as fallback\n",
    "        return [\n",
    "            {\"id\": 1, \"question\": \"I need to file a claim for my car accident yesterday\", \"customer_type\": \"urgent\", \"complexity\": \"medium\"},\n",
    "            {\"id\": 2, \"question\": \"What does my insurance cover exactly?\", \"customer_type\": \"confused\", \"complexity\": \"simple\"},\n",
    "            {\"id\": 3, \"question\": \"Why did my premium go up this month? I haven't had any accidents!\", \"customer_type\": \"frustrated\", \"complexity\": \"medium\"}\n",
    "        ]\n",
    "\n",
    "def load_questions_from_file(file_content, filename):\n",
    "    \"\"\"Load questions from uploaded file\"\"\"\n",
    "    try:\n",
    "        if filename.endswith('.json'):\n",
    "            data = json.loads(file_content.decode('utf-8'))\n",
    "            if isinstance(data, list):\n",
    "                return data\n",
    "            else:\n",
    "                return [data]\n",
    "        elif filename.endswith('.txt'):\n",
    "            lines = file_content.decode('utf-8').strip().split('\\n')\n",
    "            return [{\"id\": i+1, \"question\": line.strip(), \"customer_type\": \"normal\", \"complexity\": \"medium\"} \n",
    "                   for i, line in enumerate(lines) if line.strip()]\n",
    "        else:\n",
    "            return [{\"id\": 1, \"question\": \"Sample question from uploaded file\", \"customer_type\": \"normal\", \"complexity\": \"medium\"}]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading file: {e}\")\n",
    "        return []\n",
    "\n",
    "# Process based on user choice\n",
    "if input_choice.value == 'generate':\n",
    "    test_questions = generate_test_questions(\n",
    "        generation_prompt.value, \n",
    "        generation_model.value\n",
    "    )\n",
    "    print(f\"‚úÖ Generated {len(test_questions)} test questions\")\n",
    "elif input_choice.value == 'load' and file_upload.value:\n",
    "    uploaded_file = list(file_upload.value.values())[0]\n",
    "    test_questions = load_questions_from_file(\n",
    "        uploaded_file['content'], \n",
    "        uploaded_file['metadata']['name']\n",
    "    )\n",
    "    print(f\"‚úÖ Loaded {len(test_questions)} questions from file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please select an input method and configure it above, then re-run this cell.\")\n",
    "\n",
    "# Display first few questions as preview\n",
    "if test_questions:\n",
    "    print(\"\\nüìã Preview of test questions:\")\n",
    "    \n",
    "    # Ensure test_questions is a list\n",
    "    if isinstance(test_questions, list):\n",
    "        for i, q in enumerate(test_questions[:3]):\n",
    "            if isinstance(q, dict):\n",
    "                print(f\"  {i+1}. {q.get('question', 'No question text')} [{q.get('customer_type', 'unknown')}]\")\n",
    "            else:\n",
    "                print(f\"  {i+1}. {q} [type: {type(q)}]\")\n",
    "        if len(test_questions) > 3:\n",
    "            print(f\"  ... and {len(test_questions) - 3} more questions\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è Expected list but got {type(test_questions)}: {test_questions}\")\n",
    "        # Convert to list if possible\n",
    "        if hasattr(test_questions, '__iter__') and not isinstance(test_questions, (str, bytes)):\n",
    "            test_questions = list(test_questions)\n",
    "            print(f\"  ‚úÖ Converted to list with {len(test_questions)} items\")\n",
    "        else:\n",
    "            test_questions = []\n",
    "            print(f\"  ‚ùå Could not convert to list, using empty list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Review and Edit Questions\n",
    "\n",
    "Review the loaded or generated questions and make any edits before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Question Editor - You can modify questions before processing\n",
      "Edit the questions in the table below, then run the next cell to process them.\n",
      "\n",
      "Current questions (you can edit the JSON below if needed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I just had a car accident 10 minutes ago, what...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the hell did my premium go up by $200? Thi...</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I don't understand my deductible. Can you expl...</td>\n",
       "      <td>confused</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>We're adding a teenage driver to our policy. W...</td>\n",
       "      <td>normal</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My house flooded but I can't find my policy nu...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>I've been a customer for 15 years and you're r...</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Can you help me understand what 'comprehensive...</td>\n",
       "      <td>confused</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>I need to file a claim for a multi-car acciden...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>How do I add my new boat to my existing policy?</td>\n",
       "      <td>normal</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>I've been trying to get my claim processed for...</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>What's the difference between actual cash valu...</td>\n",
       "      <td>confused</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>My neighbor's tree fell on my garage during th...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>I'm moving to a new state next month. How do I...</td>\n",
       "      <td>normal</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Your website keeps crashing and I can't pay my...</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Can you explain all these different coverage o...</td>\n",
       "      <td>confused</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Someone broke into my car and stole my laptop....</td>\n",
       "      <td>confused</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>I need proof of insurance for a rental car in ...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>What happens to my rates if I file a claim for...</td>\n",
       "      <td>normal</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>I've been on hold for 45 minutes trying to get...</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>My house was damaged in a fire and I need to u...</td>\n",
       "      <td>urgent</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           question customer_type  \\\n",
       "0    1  I just had a car accident 10 minutes ago, what...        urgent   \n",
       "1    2  Why the hell did my premium go up by $200? Thi...    frustrated   \n",
       "2    3  I don't understand my deductible. Can you expl...      confused   \n",
       "3    4  We're adding a teenage driver to our policy. W...        normal   \n",
       "4    5  My house flooded but I can't find my policy nu...        urgent   \n",
       "5    6  I've been a customer for 15 years and you're r...    frustrated   \n",
       "6    7  Can you help me understand what 'comprehensive...      confused   \n",
       "7    8  I need to file a claim for a multi-car acciden...        urgent   \n",
       "8    9    How do I add my new boat to my existing policy?        normal   \n",
       "9   10  I've been trying to get my claim processed for...    frustrated   \n",
       "10  11  What's the difference between actual cash valu...      confused   \n",
       "11  12  My neighbor's tree fell on my garage during th...        urgent   \n",
       "12  13  I'm moving to a new state next month. How do I...        normal   \n",
       "13  14  Your website keeps crashing and I can't pay my...    frustrated   \n",
       "14  15  Can you explain all these different coverage o...      confused   \n",
       "15  16  Someone broke into my car and stole my laptop....      confused   \n",
       "16  17  I need proof of insurance for a rental car in ...        urgent   \n",
       "17  18  What happens to my rates if I file a claim for...        normal   \n",
       "18  19  I've been on hold for 45 minutes trying to get...    frustrated   \n",
       "19  20  My house was damaged in a fire and I need to u...        urgent   \n",
       "\n",
       "   complexity  \n",
       "0      simple  \n",
       "1      medium  \n",
       "2      simple  \n",
       "3      simple  \n",
       "4      medium  \n",
       "5      medium  \n",
       "6      medium  \n",
       "7     complex  \n",
       "8      simple  \n",
       "9     complex  \n",
       "10     medium  \n",
       "11     medium  \n",
       "12     medium  \n",
       "13     simple  \n",
       "14    complex  \n",
       "15     medium  \n",
       "16     simple  \n",
       "17     medium  \n",
       "18     simple  \n",
       "19    complex  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced: Edit questions as JSON (optional):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60515d0f15c5478a879d3c21c55dfbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='[\\n  {\\n    \"id\": 1,\\n    \"question\": \"I just had a car accident 10 minutes ago, what do I nee‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70a0f51e4d548b080e47495b6f8e183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Update from JSON', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create interactive question editor\n",
    "if test_questions:\n",
    "    print(\"üìù Question Editor - You can modify questions before processing\")\n",
    "    print(\"Edit the questions in the table below, then run the next cell to process them.\\n\")\n",
    "    \n",
    "    # Convert to DataFrame for easy editing\n",
    "    df = pd.DataFrame(test_questions)\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    if 'id' not in df.columns:\n",
    "        df['id'] = range(1, len(df) + 1)\n",
    "    if 'customer_type' not in df.columns:\n",
    "        df['customer_type'] = 'normal'\n",
    "    if 'complexity' not in df.columns:\n",
    "        df['complexity'] = 'medium'\n",
    "    \n",
    "    # Display editable table\n",
    "    print(\"Current questions (you can edit the JSON below if needed):\")\n",
    "    display(df)\n",
    "    \n",
    "    # Show JSON for manual editing if needed\n",
    "    questions_json = widgets.Textarea(\n",
    "        value=json.dumps(test_questions, indent=2),\n",
    "        description=\"Questions JSON:\",\n",
    "        layout=widgets.Layout(width='100%', height='200px')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nAdvanced: Edit questions as JSON (optional):\")\n",
    "    display(questions_json)\n",
    "    \n",
    "    def update_questions_from_json():\n",
    "        \"\"\"Update questions from the JSON editor\"\"\"\n",
    "        global test_questions\n",
    "        try:\n",
    "            test_questions = json.loads(questions_json.value)\n",
    "            print(\"‚úÖ Questions updated from JSON editor\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error parsing JSON: {e}\")\n",
    "    \n",
    "    # Button to update from JSON\n",
    "    update_btn = widgets.Button(description=\"Update from JSON\")\n",
    "    update_btn.on_click(lambda b: update_questions_from_json())\n",
    "    display(update_btn)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No questions loaded. Please run the previous cell to generate or load questions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 5: Process Questions Through Chatbot Agent\n\nRun the questions through the Chatbot Agent and collect results."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process questions through the Chatbot Agent\nif not test_questions:\n    print(\"‚ö†Ô∏è No questions to process. Please load or generate questions first.\")\nelse:\n    print(f\"ü§ñ Processing {len(test_questions)} questions through Chatbot Agent...\")\n    print(f\"Using model: {agent_preferred_model}\")\n    print(f\"Temperature: {agent_temperature}\")\n    print(\"\\n\" + \"=\"*50)\n    \n    # Initialize the Chatbot Agent\n    try:\n        # Create config manager with the correct config directory\n        config_manager = AgentConfigManager(config_dir='/workspace/config')\n        \n        # Create a simple context provider (using None for now)\n        context_provider = None\n        \n        # Initialize Chatbot Agent\n        chatbot_agent = ChatbotAgentNode(config_manager, context_provider)\n        \n        print(\"‚úÖ Chatbot Agent initialized successfully\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error initializing Chatbot Agent: {e}\")\n        print(\"Continuing with mock responses for demonstration...\")\n        chatbot_agent = None\n    \n    # Process each question\n    results = []\n    \n    for i, question_data in enumerate(test_questions):\n        question_id = question_data.get('id', i + 1)\n        question_text = question_data.get('question', '')\n        customer_type = question_data.get('customer_type', 'normal')\n        complexity = question_data.get('complexity', 'medium')\n        \n        print(f\"\\nüîÑ Processing question {question_id}: {question_text[:60]}...\")\n        \n        try:\n            if chatbot_agent:\n                # Create state for the Chatbot Agent\n                from datetime import datetime\n                state = {\n                    'query': question_text,\n                    'user_id': 'test_user',\n                    'session_id': f'test_session_{i}',\n                    'query_id': f'query_{question_id}',\n                    'timestamp': datetime.now().isoformat(),\n                    'messages': []\n                }\n                \n                # Process through agent using __call__ method\n                response_state = chatbot_agent(state)\n                \n                answer = response_state.get('ai_response', 'No response generated')\n                confidence = response_state.get('initial_assessment', {}).get('confidence', 0.8)\n                needs_escalation = confidence < agent_confidence_threshold\n                needs_more_input = 'clarification' in answer.lower() or 'more information' in answer.lower()\n                \n            else:\n                # Mock processing for demonstration\n                import random\n                answer = f\"Thank you for your question about {question_text[:30]}... I'd be happy to help you with that. [This is a mock response for demonstration]\"\n                confidence = random.uniform(0.6, 0.95)\n                needs_escalation = confidence < agent_confidence_threshold\n                needs_more_input = random.random() < 0.1  # 10% chance\n            \n            # Create result entry\n            result = {\n                'id': question_id,\n                'original_question': question_text,\n                'customer_type': customer_type,\n                'complexity': complexity,\n                'ai_answer': answer,\n                'confidence_score': confidence,\n                'needs_escalation': needs_escalation,\n                'needs_more_input': needs_more_input,\n                'processing_time': datetime.now().isoformat(),\n                'model_used': agent_preferred_model,\n                'temperature': agent_temperature\n            }\n            \n            results.append(result)\n            \n            # Show progress\n            status = \"üîÑ Needs more input\" if needs_more_input else (\"‚ö†Ô∏è Escalation needed\" if needs_escalation else \"‚úÖ Complete\")\n            print(f\"   {status} (confidence: {confidence:.2f})\")\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error processing question: {e}\")\n            # Add error result\n            result = {\n                'id': question_id,\n                'original_question': question_text,\n                'customer_type': customer_type,\n                'complexity': complexity,\n                'ai_answer': f\"Error processing question: {e}\",\n                'confidence_score': 0.0,\n                'needs_escalation': True,\n                'needs_more_input': False,\n                'processing_time': datetime.now().isoformat(),\n                'model_used': agent_preferred_model,\n                'temperature': agent_temperature,\n                'error': str(e)\n            }\n            results.append(result)\n    \n    print(\"\\n\" + \"=\"*50)\n    print(f\"‚úÖ Processing complete! Processed {len(results)} questions.\")\n    \n    # Summary statistics\n    total_questions = len(results)\n    needs_more_input_count = sum(1 for r in results if r['needs_more_input'])\n    needs_escalation_count = sum(1 for r in results if r['needs_escalation'])\n    avg_confidence = sum(r['confidence_score'] for r in results) / total_questions if total_questions > 0 else 0\n    \n    print(f\"\\nüìä Summary:\")\n    print(f\"  Total questions: {total_questions}\")\n    print(f\"  Need more input: {needs_more_input_count} ({needs_more_input_count/total_questions*100:.1f}%)\")\n    print(f\"  Need escalation: {needs_escalation_count} ({needs_escalation_count/total_questions*100:.1f}%)\")\n    print(f\"  Average confidence: {avg_confidence:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Handle Questions Needing More Input\n",
    "\n",
    "Re-process questions that were flagged as needing more input from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Handle questions that need more input\nif 'results' in locals() and results:\n    # Find questions that need more input\n    questions_needing_input = [r for r in results if r['needs_more_input']]\n    \n    if questions_needing_input:\n        print(f\"üîÑ Found {len(questions_needing_input)} questions needing more input.\")\n        print(\"Re-processing with additional context...\\n\")\n        \n        # Process questions needing more input\n        for result in questions_needing_input:\n            question_id = result['id']\n            original_question = result['original_question']\n            first_response = result['ai_answer']\n            \n            print(f\"üîÑ Re-processing question {question_id}...\")\n            \n            try:\n                if chatbot_agent:\n                    # Create follow-up state\n                    from datetime import datetime\n                    follow_up_state = {\n                        'query': 'Can you provide more specific information?',\n                        'user_id': 'test_user',\n                        'session_id': f'test_session_{question_id}',\n                        'query_id': f'query_{question_id}_followup',\n                        'timestamp': datetime.now().isoformat(),\n                        'messages': [\n                            {'role': 'user', 'content': original_question},\n                            {'role': 'assistant', 'content': first_response}\n                        ]\n                    }\n                    \n                    # Re-process through agent using __call__ method\n                    response_state = chatbot_agent(follow_up_state)\n                    \n                    follow_up_answer = response_state.get('ai_response', 'No follow-up response generated')\n                    follow_up_confidence = response_state.get('initial_assessment', {}).get('confidence', 0.8)\n                    \n                else:\n                    # Mock follow-up response\n                    follow_up_answer = f\"Thank you for asking for more details. Let me provide additional specific information about {original_question[:30]}... [Mock follow-up response]\"\n                    follow_up_confidence = 0.85\n                \n                # Add follow-up interaction to results\n                follow_up_result = {\n                    'id': f\"{question_id}_followup\",\n                    'parent_id': question_id,\n                    'original_question': 'Can you provide more specific information?',\n                    'customer_type': result['customer_type'],\n                    'complexity': result['complexity'],\n                    'ai_answer': follow_up_answer,\n                    'confidence_score': follow_up_confidence,\n                    'needs_escalation': follow_up_confidence < agent_confidence_threshold,\n                    'needs_more_input': False,  # Assume follow-up resolves the need\n                    'processing_time': datetime.now().isoformat(),\n                    'model_used': agent_preferred_model,\n                    'temperature': agent_temperature,\n                    'is_followup': True\n                }\n                \n                results.append(follow_up_result)\n                \n                # Update original result to show it no longer needs more input\n                result['needs_more_input'] = False\n                result['has_followup'] = True\n                \n                print(f\"   ‚úÖ Follow-up processed (confidence: {follow_up_confidence:.2f})\")\n                \n            except Exception as e:\n                print(f\"   ‚ùå Error processing follow-up: {e}\")\n        \n        print(f\"\\n‚úÖ Follow-up processing complete. Added {len(questions_needing_input)} follow-up interactions.\")\n        \n    else:\n        print(\"‚úÖ No questions needed additional input. All questions processed successfully.\")\n        \nelse:\n    print(\"‚ö†Ô∏è No results to process. Please run the previous cells first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Export Results and Settings\n",
    "\n",
    "Save the results and configuration settings to files with timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Export results and settings\nif 'results' in locals() and results:\n    # Create timestamp for filenames\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n    \n    # Create experiment_runs directory if it doesn't exist\n    experiment_dir = Path('/workspace/notebooks/experiment_runs')\n    experiment_dir.mkdir(exist_ok=True)\n    \n    # Export results\n    results_filename = f\"chatbot_agent_output_{timestamp}.json\"\n    results_path = experiment_dir / results_filename\n    \n    with open(results_path, 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    print(f\"üìÑ Results exported to: {results_path}\")\n    \n    # Export settings\n    settings_filename = f\"chatbot_agent_settings_{timestamp}.json\"\n    settings_path = experiment_dir / settings_filename\n    \n    settings_export = {\n        'experiment_info': {\n            'timestamp': timestamp,\n            'agent_type': 'chatbot_agent',\n            'total_questions': len([r for r in results if not r.get('is_followup', False)]),\n            'total_interactions': len(results),\n            'follow_up_count': len([r for r in results if r.get('is_followup', False)])\n        },\n        'model_settings': {\n            'preferred_model': agent_preferred_model,\n            'fallback_models': agent_fallback_models,\n            'temperature': agent_temperature,\n            'max_tokens': agent_max_tokens,\n            'timeout': agent_timeout\n        },\n        'behavior_settings': {\n            'response_style': agent_response_style,\n            'context_integration': agent_context_integration,\n            'personalization': agent_personalization,\n            'prompt_style': agent_prompt_style,\n            'include_empathy': agent_include_empathy,\n            'customer_focus': agent_customer_focus\n        },\n        'escalation_settings': {\n            'confidence_threshold': agent_confidence_threshold,\n            'auto_escalation': agent_auto_escalation,\n            'escalation_triggers': agent_escalation_triggers\n        },\n        'generation_settings': {\n            'input_method': input_choice.value if 'input_choice' in locals() else 'unknown',\n            'generation_prompt': generation_prompt.value if 'generation_prompt' in locals() else 'N/A',\n            'generation_model': generation_model.value if 'generation_model' in locals() else 'N/A'\n        }\n    }\n    \n    with open(settings_path, 'w') as f:\n        json.dump(settings_export, f, indent=2)\n    \n    print(f\"‚öôÔ∏è Settings exported to: {settings_path}\")\n    \n    # Show summary\n    print(f\"\\nüìä Export Summary:\")\n    print(f\"  Timestamp: {timestamp}\")\n    print(f\"  Results file: {results_filename}\")\n    print(f\"  Settings file: {settings_filename}\")\n    print(f\"  Total interactions: {len(results)}\")\n    print(f\"  Original questions: {len([r for r in results if not r.get('is_followup', False)])}\")\n    print(f\"  Follow-up interactions: {len([r for r in results if r.get('is_followup', False)])}\")\n    print(f\"  Files saved to: {experiment_dir.absolute()}\")\n    \nelse:\n    print(\"‚ö†Ô∏è No results to export. Please process questions first.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Review Results\n",
    "\n",
    "Display and analyze the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Results Review and Analysis\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Total original questions: 20\n",
      "Follow-up interactions: 0\n",
      "Average confidence score: 0.000\n",
      "Questions needing escalation: 20 (100.0%)\n",
      "Questions that needed more input: 0\n",
      "\n",
      "=== ANALYSIS BY CUSTOMER TYPE ===\n",
      "               confidence_score  needs_escalation  needs_more_input\n",
      "customer_type                                                      \n",
      "confused                    0.0                 5                 0\n",
      "frustrated                  0.0                 5                 0\n",
      "normal                      0.0                 4                 0\n",
      "urgent                      0.0                 6                 0\n",
      "\n",
      "=== ANALYSIS BY COMPLEXITY ===\n",
      "            confidence_score  needs_escalation  needs_more_input\n",
      "complexity                                                      \n",
      "complex                  0.0                 4                 0\n",
      "medium                   0.0                 9                 0\n",
      "simple                   0.0                 7                 0\n",
      "\n",
      "=== DETAILED RESULTS ===\n",
      "Summary table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>complexity</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>needs_escalation</th>\n",
       "      <th>needs_more_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>confused</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>normal</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>urgent</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>confused</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>urgent</td>\n",
       "      <td>complex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>normal</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>complex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>confused</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>urgent</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>normal</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>confused</td>\n",
       "      <td>complex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>confused</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>normal</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>simple</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>urgent</td>\n",
       "      <td>complex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id customer_type complexity  confidence_score  needs_escalation  \\\n",
       "0    1        urgent     simple               0.0              True   \n",
       "1    2    frustrated     medium               0.0              True   \n",
       "2    3      confused     simple               0.0              True   \n",
       "3    4        normal     simple               0.0              True   \n",
       "4    5        urgent     medium               0.0              True   \n",
       "5    6    frustrated     medium               0.0              True   \n",
       "6    7      confused     medium               0.0              True   \n",
       "7    8        urgent    complex               0.0              True   \n",
       "8    9        normal     simple               0.0              True   \n",
       "9   10    frustrated    complex               0.0              True   \n",
       "10  11      confused     medium               0.0              True   \n",
       "11  12        urgent     medium               0.0              True   \n",
       "12  13        normal     medium               0.0              True   \n",
       "13  14    frustrated     simple               0.0              True   \n",
       "14  15      confused    complex               0.0              True   \n",
       "15  16      confused     medium               0.0              True   \n",
       "16  17        urgent     simple               0.0              True   \n",
       "17  18        normal     medium               0.0              True   \n",
       "18  19    frustrated     simple               0.0              True   \n",
       "19  20        urgent    complex               0.0              True   \n",
       "\n",
       "    needs_more_input  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  \n",
       "5              False  \n",
       "6              False  \n",
       "7              False  \n",
       "8              False  \n",
       "9              False  \n",
       "10             False  \n",
       "11             False  \n",
       "12             False  \n",
       "13             False  \n",
       "14             False  \n",
       "15             False  \n",
       "16             False  \n",
       "17             False  \n",
       "18             False  \n",
       "19             False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE QUESTION & ANSWER PAIRS ===\n",
      "\n",
      "--- Question 1 (urgent, simple) ---\n",
      "Q: I just had a car accident 10 minutes ago, what do I need to do right now??\n",
      "A: Error processing question: 'NoneType' object has no attribute 'get_context_summary'\n",
      "Confidence: 0.000 | Escalation: True | More input: False\n",
      "\n",
      "--- Question 2 (frustrated, medium) ---\n",
      "Q: Why the hell did my premium go up by $200? This is ridiculous and I want answers NOW!\n",
      "A: Error processing question: 'NoneType' object has no attribute 'get_context_summary'\n",
      "Confidence: 0.000 | Escalation: True | More input: False\n",
      "\n",
      "--- Question 3 (confused, simple) ---\n",
      "Q: I don't understand my deductible. Can you explain what that means in simple terms?\n",
      "A: Error processing question: 'NoneType' object has no attribute 'get_context_summary'\n",
      "Confidence: 0.000 | Escalation: True | More input: False\n",
      "\n",
      "============================================================\n",
      "‚úÖ Review complete! Check the exported files for full details.\n"
     ]
    }
   ],
   "source": [
    "# Review and analyze results\n",
    "if 'results' in locals() and results:\n",
    "    print(\"üìã Results Review and Analysis\\n\")\n",
    "    \n",
    "    # Separate original questions and follow-ups\n",
    "    original_results = [r for r in results if not r.get('is_followup', False)]\n",
    "    followup_results = [r for r in results if r.get('is_followup', False)]\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    df_results = pd.DataFrame(original_results)\n",
    "    \n",
    "    print(\"=== SUMMARY STATISTICS ===\")\n",
    "    print(f\"Total original questions: {len(original_results)}\")\n",
    "    print(f\"Follow-up interactions: {len(followup_results)}\")\n",
    "    print(f\"Average confidence score: {df_results['confidence_score'].mean():.3f}\")\n",
    "    print(f\"Questions needing escalation: {df_results['needs_escalation'].sum()} ({df_results['needs_escalation'].sum()/len(df_results)*100:.1f}%)\")\n",
    "    print(f\"Questions that needed more input: {df_results['needs_more_input'].sum()}\")\n",
    "    \n",
    "    # Analysis by customer type\n",
    "    print(\"\\n=== ANALYSIS BY CUSTOMER TYPE ===\")\n",
    "    customer_analysis = df_results.groupby('customer_type').agg({\n",
    "        'confidence_score': 'mean',\n",
    "        'needs_escalation': 'sum',\n",
    "        'needs_more_input': 'sum'\n",
    "    }).round(3)\n",
    "    print(customer_analysis)\n",
    "    \n",
    "    # Analysis by complexity\n",
    "    print(\"\\n=== ANALYSIS BY COMPLEXITY ===\")\n",
    "    complexity_analysis = df_results.groupby('complexity').agg({\n",
    "        'confidence_score': 'mean',\n",
    "        'needs_escalation': 'sum',\n",
    "        'needs_more_input': 'sum'\n",
    "    }).round(3)\n",
    "    print(complexity_analysis)\n",
    "    \n",
    "    # Show detailed results table\n",
    "    print(\"\\n=== DETAILED RESULTS ===\")\n",
    "    \n",
    "    # Create a simplified view for display\n",
    "    display_columns = ['id', 'customer_type', 'complexity', 'confidence_score', 'needs_escalation', 'needs_more_input']\n",
    "    display_df = df_results[display_columns].copy()\n",
    "    display_df['confidence_score'] = display_df['confidence_score'].round(3)\n",
    "    \n",
    "    print(\"Summary table:\")\n",
    "    display(display_df)\n",
    "    \n",
    "    # Show a few sample Q&A pairs\n",
    "    print(\"\\n=== SAMPLE QUESTION & ANSWER PAIRS ===\")\n",
    "    for i, result in enumerate(original_results[:3]):\n",
    "        print(f\"\\n--- Question {result['id']} ({result['customer_type']}, {result['complexity']}) ---\")\n",
    "        print(f\"Q: {result['original_question']}\")\n",
    "        print(f\"A: {result['ai_answer'][:200]}{'...' if len(result['ai_answer']) > 200 else ''}\")\n",
    "        print(f\"Confidence: {result['confidence_score']:.3f} | Escalation: {result['needs_escalation']} | More input: {result['needs_more_input']}\")\n",
    "        \n",
    "        # Show follow-up if it exists\n",
    "        followup = next((f for f in followup_results if f.get('parent_id') == result['id']), None)\n",
    "        if followup:\n",
    "            print(f\"\\n  Follow-up Q: {followup['original_question']}\")\n",
    "            print(f\"  Follow-up A: {followup['ai_answer'][:200]}{'...' if len(followup['ai_answer']) > 200 else ''}\")\n",
    "            print(f\"  Follow-up Confidence: {followup['confidence_score']:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ Review complete! Check the exported files for full details.\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to review. Please process questions first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Next Steps\n\nüéâ **Congratulations!** You've successfully tested the Chatbot Agent.\n\n### What you've accomplished:\n- ‚úÖ Loaded and customized Chatbot Agent configuration\n- ‚úÖ Generated or loaded test questions\n- ‚úÖ Processed questions through the Chatbot Agent\n- ‚úÖ Handled follow-up interactions for unclear responses\n- ‚úÖ Exported results and settings with timestamps\n- ‚úÖ Analyzed performance by customer type and complexity\n\n### Your exported files contain:\n- **Results file**: All questions, answers, confidence scores, and flags\n- **Settings file**: Complete configuration used for this experiment\n\n### To import settings to config files:\nThe exported settings use variable names that map directly to the configuration structure.\nYou can use these files to:\n1. Recreate successful experiments\n2. Import optimized settings back to the main config files\n3. Compare different configuration approaches\n\n### Ready for more testing?\n- Modify the configuration variables in Step 2 and re-run\n- Try different models or temperature settings\n- Test with different types of customer questions\n- Experiment with different confidence thresholds\n\n---\n*This notebook is part of the Human-in-the-Loop AI System for customer service optimization.*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}