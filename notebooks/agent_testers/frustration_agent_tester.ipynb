{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Frustration Agent Testing Notebook\n",
    "\n",
    "This notebook provides a user-friendly interface for testing the Frustration Agent with chatbot interactions.\n",
    "It reads output from chatbot_tester.ipynb and analyzes customer frustration levels in conversations.\n",
    "\n",
    "## Features:\n",
    "- Load and edit Frustration Agent configuration settings\n",
    "- Import chatbot conversation results from chatbot_tester.ipynb\n",
    "- Process each conversation turn through the Frustration Agent\n",
    "- Generate frustration scores, sentiment analysis, and escalation recommendations\n",
    "- Track frustration patterns and escalation trends across conversations\n",
    "- Analyze employee wellbeing impact and routing recommendations\n",
    "- Export enhanced results with frustration and sentiment metrics\n",
    "\n",
    "## Getting Started:\n",
    "1. Run cells in order from top to bottom\n",
    "2. Edit configuration values as needed\n",
    "3. Load chatbot conversation results from chatbot_tester exports\n",
    "4. Review conversations before frustration analysis\n",
    "5. Run frustration detection and review detailed results\n",
    "\n",
    "## Input Requirements:\n",
    "Load conversation results exported from chatbot_tester.ipynb containing:\n",
    "- Customer queries with potential frustration indicators\n",
    "- Conversation metadata and turn-by-turn interactions\n",
    "- Customer types, complexity levels, and interaction history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "Ready to start testing the Frustration Agent.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from ruamel.yaml import YAML\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Set the working directory to the root of the project\n",
    "os.chdir('/workspace')\n",
    "\n",
    "# Add workspace to path for imports\n",
    "sys.path.insert(0, '/workspace')\n",
    "\n",
    "# Import our system components\n",
    "from src.nodes.frustration_agent import FrustrationAgentNode\n",
    "from src.core.config import ConfigManager\n",
    "from src.core.context_manager import SQLiteContextProvider\n",
    "from src.interfaces.core.state_schema import HybridSystemState\n",
    "from src.interfaces.core.context import ContextEntry\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"Ready to start testing the Frustration Agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Step 1: Load Configuration Settings\n",
    "\n",
    "The following cell loads the current configuration for the Frustration Agent.\n",
    "You can edit these values to customize the agent's frustration detection behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Configuration files loaded and temporary copies created with comments preserved!\n",
      "Agent name: frustration_agent\n",
      "Agent version: 1.0.0\n",
      "Preferred model: deepinfra_general_standard\n",
      "\n",
      "üò§ Frustration Detection Thresholds:\n",
      "  Critical: 8.0\n",
      "  High: 6.0\n",
      "  Moderate: 3.0\n",
      "  Intervention trigger: high\n",
      "\n",
      "üíæ Temporary config files created at:\n",
      "  agent_config: /tmp/frustration_agent_configs/config.yaml\n",
      "  prompts_config: /tmp/frustration_agent_configs/prompts.yaml\n",
      "  models_config: /tmp/frustration_agent_configs/models.yaml\n",
      "\n",
      "üí° These temp files retain original comments and can be edited directly in Step 2.\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from files and create temporary editable copies\n",
    "config_base_path = Path('/workspace/config')\n",
    "agent_config_path = config_base_path / 'agents' / 'frustration_agent'\n",
    "temp_config_dir = Path('/tmp/frustration_agent_configs')\n",
    "\n",
    "def load_and_create_temp_configs():\n",
    "    \"\"\"Load all configuration files and create temporary editable copies with comments preserved\"\"\"\n",
    "    configs = {}\n",
    "    \n",
    "    # Create YAML instance for comment preservation\n",
    "    yaml = YAML()\n",
    "    yaml.preserve_quotes = True\n",
    "    yaml.default_flow_style = False\n",
    "    \n",
    "    # Create temp directory\n",
    "    temp_config_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load original files for parsing (to access data)\n",
    "    with open(agent_config_path / 'config.yaml', 'r') as f:\n",
    "        configs['agent'] = yaml.load(f)\n",
    "    \n",
    "    with open(agent_config_path / 'prompts.yaml', 'r') as f:\n",
    "        configs['prompts'] = yaml.load(f)\n",
    "    \n",
    "    with open(agent_config_path / 'models.yaml', 'r') as f:\n",
    "        configs['models'] = yaml.load(f)\n",
    "    \n",
    "    # Load shared models for reference\n",
    "    with open(config_base_path / 'shared' / 'models.yaml', 'r') as f:\n",
    "        configs['shared_models'] = yaml.load(f)\n",
    "    \n",
    "    # Create temp file paths\n",
    "    temp_agent_path = temp_config_dir / 'config.yaml'\n",
    "    temp_prompts_path = temp_config_dir / 'prompts.yaml'\n",
    "    temp_models_path = temp_config_dir / 'models.yaml'\n",
    "    \n",
    "    # Copy original files to temp directory to preserve comments and formatting\n",
    "    import shutil\n",
    "    shutil.copy2(agent_config_path / 'config.yaml', temp_agent_path)\n",
    "    shutil.copy2(agent_config_path / 'prompts.yaml', temp_prompts_path)  \n",
    "    shutil.copy2(agent_config_path / 'models.yaml', temp_models_path)\n",
    "    \n",
    "    return configs, {\n",
    "        'agent_config': temp_agent_path,\n",
    "        'prompts_config': temp_prompts_path,\n",
    "        'models_config': temp_models_path\n",
    "    }\n",
    "\n",
    "# Load configurations and create temp files\n",
    "configs, temp_file_paths = load_and_create_temp_configs()\n",
    "\n",
    "print(\"üìÅ Configuration files loaded and temporary copies created with comments preserved!\")\n",
    "print(f\"Agent name: {configs['agent']['agent']['name']}\")\n",
    "print(f\"Agent version: {configs['agent']['agent']['version']}\")\n",
    "\n",
    "# Get preferred model from models config\n",
    "preferred_model = \"Unknown\"\n",
    "if 'primary_model' in configs['models']:\n",
    "    preferred_model = configs['models']['primary_model']\n",
    "elif 'preferred' in configs['models']:\n",
    "    preferred_model = configs['models']['preferred']\n",
    "\n",
    "print(f\"Preferred model: {preferred_model}\")\n",
    "\n",
    "# Display key frustration thresholds\n",
    "frustration_thresholds = configs['agent']['settings']['frustration_thresholds']\n",
    "print(f\"\\nüò§ Frustration Detection Thresholds:\")\n",
    "print(f\"  Critical: {frustration_thresholds['critical']}\")\n",
    "print(f\"  High: {frustration_thresholds['high']}\")\n",
    "print(f\"  Moderate: {frustration_thresholds['moderate']}\")\n",
    "\n",
    "# Display intervention threshold\n",
    "intervention_threshold = configs['agent']['settings']['intervention_threshold']\n",
    "print(f\"  Intervention trigger: {intervention_threshold}\")\n",
    "\n",
    "print(f\"\\nüíæ Temporary config files created at:\")\n",
    "for config_type, path in temp_file_paths.items():\n",
    "    print(f\"  {config_type}: {path}\")\n",
    "print(f\"\\nüí° These temp files retain original comments and can be edited directly in Step 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Step 2: Editable Configuration Settings\n",
    "\n",
    "Edit these settings to customize how the Frustration Agent detects and analyzes customer frustration.\n",
    "These variables map directly to the configuration files and can be exported later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Frustration Agent Configuration File Editor\n",
      "Edit the YAML configuration files below and use the Save buttons to apply changes.\n",
      "Changes are saved to temporary files and will be used in frustration detection.\n",
      "\n",
      "üìÑ 1. Frustration Agent Configuration (config.yaml)\n",
      "Contains: frustration thresholds, intervention settings, pattern detection rules\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3a54e3b00748edbf2baad749b44f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='# Frustration Agent Configuration\\n# Responsibility: Analyze customer comments to detect frust‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826d4e2c51e64be3b56dce907d0d33d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Agent Config', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ 2. Frustration Detection Prompts Configuration (prompts.yaml)\n",
      "Contains: system prompts, frustration analysis criteria, pattern detection templates\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5742a924b2dd4245bbb58803091a6e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='# Frustration Agent Prompts\\n\\nsystem: |\\n  You are a Frustration Detection Agent responsible ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c55d28b26b4cb2bcb9a608a2e0157d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Prompts Config', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ 3. Frustration Analysis Models Configuration (models.yaml)\n",
      "Contains: preferred models for frustration detection, pattern analysis\n",
      "\n",
      "üîç Available Model Aliases for Frustration Detection:\n",
      "Use these aliases in your models configuration below:\n",
      "\n",
      "üì° ANTHROPIC Provider:\n",
      "  ‚Ä¢ anthropic_general_budget ‚Üí claude-3-5-haiku-20241022 - Anthropic Claude 3.5 Haiku - fast and efficient\n",
      "  ‚Ä¢ anthropic_general_standard ‚Üí claude-3-5-sonnet-20241022 - Anthropic Claude 3.5 Sonnet - balanced performance and reasoning\n",
      "  ‚Ä¢ anthropic_reasoning_premium ‚Üí claude-3-5-sonnet-20241022 - Anthropic Claude 3.5 Sonnet - balanced performance and reasoning\n",
      "  ‚Ä¢ anthropic_coding_premium ‚Üí claude-3-5-sonnet-20241022 - Anthropic Claude 3.5 Sonnet - balanced performance and reasoning\n",
      "  ‚Ä¢ anthropic_flagship ‚Üí claude-3-5-sonnet-20241022 - Anthropic Claude 3.5 Sonnet - balanced performance and reasoning\n",
      "\n",
      "üì° OPENAI Provider:\n",
      "  ‚Ä¢ openai_general_standard ‚Üí gpt-4 - OpenAI GPT-4 - highest quality, requires API key\n",
      "  ‚Ä¢ openai_general_budget ‚Üí gpt-3.5-turbo - OpenAI GPT-3.5 Turbo - fast and cost-effective\n",
      "  ‚Ä¢ openai_coding_standard ‚Üí gpt-4 - OpenAI GPT-4 - highest quality, requires API key\n",
      "\n",
      "üì° DEEPINFRA Provider:\n",
      "  ‚Ä¢ deepinfra_general_standard ‚Üí kimi-k2-instruct - Kimi K2 Instruct - large-scale MoE language model via DeepInfra\n",
      "  ‚Ä¢ deepinfra_general_budget ‚Üí meta-llama-3-8b-instruct - Meta Llama 3 8B Instruct - balanced performance model via DeepInfra\n",
      "  ‚Ä¢ deepinfra_coding_standard ‚Üí meta-llama-3.1-8b-instruct - Meta Llama 3.1 8B Instruct - optimized for code and reasoning via DeepInfra\n",
      "  ‚Ä¢ deepinfra_reasoning_premium ‚Üí mistral-7b-instruct-v0.3 - Mistral 7B Instruct v0.3 - excellent instruction following via DeepInfra\n",
      "  ‚Ä¢ deepinfra_general_standard_2 ‚Üí qwen3-32b - Qwen3 32B - high-quality conversational model via DeepInfra\n",
      "  ‚Ä¢ deepinfra_general_budget_2 ‚Üí qwen3-14b - Qwen3 14B - balanced performance model via DeepInfra\n",
      "  ‚Ä¢ deepinfra_coding_standard_2 ‚Üí llama4-maverick-17b - Llama 4 Maverick 17B - specialized instruction model via DeepInfra\n",
      "  ‚Ä¢ deepinfra_reasoning_premium_2 ‚Üí deepseek-v3-turbo - DeepSeek V3 Turbo - fast and efficient model via DeepInfra\n",
      "  ‚Ä¢ deepinfra_budget_3 ‚Üí Llama-3.3-70B-Instruct-Turbo - Llama 3.3 70B Instruct Turbo - high-performance instruction model via DeepInfra\n",
      "  ‚Ä¢ deepinfra_standard_3 ‚Üí gemini-2.5-flash - Google Gemini 2.5 Flash - fast multimodal model via DeepInfra\n",
      "\n",
      "üì° LLAMA Provider:\n",
      "  ‚Ä¢ local_general_standard ‚Üí llama-7b - Llama 7B model - good balance of speed and quality\n",
      "  ‚Ä¢ local_general_premium ‚Üí llama-13b - Llama 13B model - higher quality, slower inference\n",
      "  ‚Ä¢ local_coding_standard ‚Üí codellama-7b - CodeLlama 7B - optimized for code generation\n",
      "\n",
      "üì° MISTRAL Provider:\n",
      "  ‚Ä¢ local_general_budget ‚Üí mistral-7b - Mistral 7B Instruct - excellent instruction following\n",
      "\n",
      "üìã Current Models Configuration:\n",
      "  Primary model: deepinfra_general_standard\n",
      "\n",
      "üí° Frustration Detection Model Recommendations:\n",
      "  ‚Ä¢ Very low temperature models (0.1-0.2) for consistent sentiment analysis\n",
      "  ‚Ä¢ Standard models sufficient for basic frustration detection\n",
      "  ‚Ä¢ Budget models acceptable for rule-based pattern matching\n",
      "  ‚Ä¢ Reasoning models beneficial for complex emotional analysis\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1a5b45753147f8875f8410e6808219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='primary_model: \"deepinfra_general_standard\"\\n\\nmodel_overrides:\\n  temperature: 0.2          #‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c3fd89b4ae41aca91c9f557992c4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Save Models Config', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Save All Changes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abf4816587e4fc084113b8812792f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Save All Configs', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Temp config files location:\n",
      "  agent_config: /tmp/frustration_agent_configs/config.yaml\n",
      "  prompts_config: /tmp/frustration_agent_configs/prompts.yaml\n",
      "  models_config: /tmp/frustration_agent_configs/models.yaml\n",
      "\n",
      "üí° Frustration Detection Tips:\n",
      "  ‚Ä¢ Lower critical/high thresholds = more sensitive frustration detection\n",
      "  ‚Ä¢ intervention_threshold controls when to escalate to humans\n",
      "  ‚Ä¢ Lower temperature = more consistent frustration scoring\n",
      "  ‚Ä¢ Edit frustration_indicators to customize keyword detection\n",
      "  ‚Ä¢ Employee protection settings help manage agent workload\n"
     ]
    }
   ],
   "source": [
    "# Display and edit configuration files in separate windows\n",
    "\n",
    "def load_config_file_contents():\n",
    "    \"\"\"Load current config file contents from temp files\"\"\"\n",
    "    with open(temp_file_paths['agent_config'], 'r') as f:\n",
    "        agent_config_content = f.read()\n",
    "    with open(temp_file_paths['prompts_config'], 'r') as f:\n",
    "        prompts_config_content = f.read()\n",
    "    with open(temp_file_paths['models_config'], 'r') as f:\n",
    "        models_config_content = f.read()\n",
    "    \n",
    "    return agent_config_content, prompts_config_content, models_config_content\n",
    "\n",
    "# Load current config file contents\n",
    "agent_config_content, prompts_config_content, models_config_content = load_config_file_contents()\n",
    "\n",
    "print(\"‚öôÔ∏è Frustration Agent Configuration File Editor\")\n",
    "print(\"Edit the YAML configuration files below and use the Save buttons to apply changes.\")\n",
    "print(\"Changes are saved to temporary files and will be used in frustration detection.\\n\")\n",
    "\n",
    "# Create text areas for each config file\n",
    "print(\"üìÑ 1. Frustration Agent Configuration (config.yaml)\")\n",
    "print(\"Contains: frustration thresholds, intervention settings, pattern detection rules\")\n",
    "\n",
    "agent_config_editor = widgets.Textarea(\n",
    "    value=agent_config_content,\n",
    "    description=\"\",\n",
    "    layout=widgets.Layout(width='100%', height='350px'),\n",
    "    style={'description_width': '0px'}\n",
    ")\n",
    "\n",
    "def save_agent_config(button):\n",
    "    \"\"\"Save agent config changes with comments preserved\"\"\"\n",
    "    try:\n",
    "        yaml = YAML()\n",
    "        yaml.preserve_quotes = True\n",
    "        yaml.default_flow_style = False\n",
    "        \n",
    "        # Validate YAML syntax\n",
    "        yaml.load(agent_config_editor.value)\n",
    "        \n",
    "        # Save to temp file (preserves comments in the editor content)\n",
    "        with open(temp_file_paths['agent_config'], 'w') as f:\n",
    "            f.write(agent_config_editor.value)\n",
    "        \n",
    "        print(\"‚úÖ Frustration Agent config saved successfully with comments preserved!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå YAML syntax error in agent config: {e}\")\n",
    "\n",
    "agent_save_btn = widgets.Button(description=\"Save Agent Config\", button_style='success')\n",
    "agent_save_btn.on_click(save_agent_config)\n",
    "\n",
    "display(agent_config_editor)\n",
    "display(agent_save_btn)\n",
    "\n",
    "print(\"\\nüìÑ 2. Frustration Detection Prompts Configuration (prompts.yaml)\")\n",
    "print(\"Contains: system prompts, frustration analysis criteria, pattern detection templates\")\n",
    "\n",
    "prompts_config_editor = widgets.Textarea(\n",
    "    value=prompts_config_content,\n",
    "    description=\"\",\n",
    "    layout=widgets.Layout(width='100%', height='300px'),\n",
    "    style={'description_width': '0px'}\n",
    ")\n",
    "\n",
    "def save_prompts_config(button):\n",
    "    \"\"\"Save prompts config changes with comments preserved\"\"\"\n",
    "    try:\n",
    "        yaml = YAML()\n",
    "        yaml.preserve_quotes = True\n",
    "        yaml.default_flow_style = False\n",
    "        \n",
    "        # Validate YAML syntax\n",
    "        yaml.load(prompts_config_editor.value)\n",
    "        \n",
    "        # Save to temp file (preserves comments in the editor content)\n",
    "        with open(temp_file_paths['prompts_config'], 'w') as f:\n",
    "            f.write(prompts_config_editor.value)\n",
    "        \n",
    "        print(\"‚úÖ Prompts config saved successfully with comments preserved!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå YAML syntax error in prompts config: {e}\")\n",
    "\n",
    "prompts_save_btn = widgets.Button(description=\"Save Prompts Config\", button_style='success')\n",
    "prompts_save_btn.on_click(save_prompts_config)\n",
    "\n",
    "display(prompts_config_editor)\n",
    "display(prompts_save_btn)\n",
    "\n",
    "print(\"\\nüìÑ 3. Frustration Analysis Models Configuration (models.yaml)\")\n",
    "print(\"Contains: preferred models for frustration detection, pattern analysis\")\n",
    "\n",
    "# Show available model aliases from shared models config\n",
    "def display_available_models():\n",
    "    \"\"\"Display available model aliases and their actual models\"\"\"\n",
    "    try:\n",
    "        shared_models = configs['shared_models']\n",
    "        \n",
    "        # Extract model aliases and models sections\n",
    "        model_aliases = shared_models.get('model_aliases', {})\n",
    "        models = shared_models.get('models', {})\n",
    "        \n",
    "        if not model_aliases:\n",
    "            print(\"‚ùå No model aliases found in shared configuration\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nüîç Available Model Aliases for Frustration Detection:\")\n",
    "        print(\"Use these aliases in your models configuration below:\\n\")\n",
    "        \n",
    "        # Group by provider for better organization\n",
    "        providers = {}\n",
    "        for alias, actual_model_name in model_aliases.items():\n",
    "            # Get model details from models section\n",
    "            model_details = models.get(actual_model_name, {})\n",
    "            provider = model_details.get('type', 'unknown')\n",
    "            description = model_details.get('description', '')\n",
    "            \n",
    "            if provider not in providers:\n",
    "                providers[provider] = []\n",
    "            providers[provider].append({\n",
    "                'alias': alias,\n",
    "                'model_name': actual_model_name,\n",
    "                'description': description\n",
    "            })\n",
    "        \n",
    "        # Display by provider with frustration detection recommendations\n",
    "        for provider, provider_models in providers.items():\n",
    "            print(f\"üì° {provider.upper()} Provider:\")\n",
    "            for model in provider_models:\n",
    "                desc = f\" - {model['description']}\" if model['description'] else \"\"\n",
    "                print(f\"  ‚Ä¢ {model['alias']} ‚Üí {model['model_name']}{desc}\")\n",
    "            print()\n",
    "        \n",
    "        # Show current configuration\n",
    "        try:\n",
    "            yaml = YAML()\n",
    "            yaml.preserve_quotes = True\n",
    "            current_models_config = yaml.load(models_config_content)\n",
    "            current_preferred = current_models_config.get('primary_model', current_models_config.get('preferred', 'unknown'))\n",
    "            \n",
    "            # Show model preferences for different tasks\n",
    "            model_preferences = current_models_config.get('model_preferences', {})\n",
    "        except:\n",
    "            current_preferred = 'unknown'\n",
    "            model_preferences = {}\n",
    "        \n",
    "        print(f\"üìã Current Models Configuration:\")\n",
    "        print(f\"  Primary model: {current_preferred}\")\n",
    "        if model_preferences:\n",
    "            print(f\"  Task-specific preferences:\")\n",
    "            for task, prefs in model_preferences.items():\n",
    "                print(f\"    {task}: {prefs.get('primary', 'unknown')}\")\n",
    "        print()\n",
    "        \n",
    "        print(\"üí° Frustration Detection Model Recommendations:\")\n",
    "        print(\"  ‚Ä¢ Very low temperature models (0.1-0.2) for consistent sentiment analysis\")\n",
    "        print(\"  ‚Ä¢ Standard models sufficient for basic frustration detection\")\n",
    "        print(\"  ‚Ä¢ Budget models acceptable for rule-based pattern matching\")\n",
    "        print(\"  ‚Ä¢ Reasoning models beneficial for complex emotional analysis\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading available models: {e}\")\n",
    "        print(\"Continuing with models configuration editor...\\n\")\n",
    "\n",
    "# Display available models before showing the editor\n",
    "display_available_models()\n",
    "\n",
    "models_config_editor = widgets.Textarea(\n",
    "    value=models_config_content,\n",
    "    description=\"\",\n",
    "    layout=widgets.Layout(width='100%', height='200px'),\n",
    "    style={'description_width': '0px'}\n",
    ")\n",
    "\n",
    "def save_models_config(button):\n",
    "    \"\"\"Save models config changes with comments preserved\"\"\"\n",
    "    try:\n",
    "        yaml = YAML()\n",
    "        yaml.preserve_quotes = True\n",
    "        yaml.default_flow_style = False\n",
    "        \n",
    "        # Validate YAML syntax\n",
    "        parsed_config = yaml.load(models_config_editor.value)\n",
    "        \n",
    "        # Additional validation for model aliases\n",
    "        if isinstance(parsed_config, dict):\n",
    "            preferred = parsed_config.get('primary_model') or parsed_config.get('preferred')\n",
    "            \n",
    "            # Get available aliases\n",
    "            model_aliases = configs['shared_models'].get('model_aliases', {})\n",
    "            \n",
    "            # Check if preferred model exists\n",
    "            if preferred and preferred not in model_aliases:\n",
    "                print(f\"‚ö†Ô∏è Warning: Preferred model '{preferred}' not found in available model aliases\")\n",
    "            \n",
    "            # Check model preferences\n",
    "            model_preferences = parsed_config.get('model_preferences', {})\n",
    "            for task, prefs in model_preferences.items():\n",
    "                task_primary = prefs.get('primary')\n",
    "                if task_primary and task_primary not in model_aliases:\n",
    "                    print(f\"‚ö†Ô∏è Warning: {task} primary model '{task_primary}' not found in available model aliases\")\n",
    "        \n",
    "        # Save to temp file (preserves comments in the editor content)\n",
    "        with open(temp_file_paths['models_config'], 'w') as f:\n",
    "            f.write(models_config_editor.value)\n",
    "        \n",
    "        print(\"‚úÖ Models config saved successfully with comments preserved!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå YAML syntax error in models config: {e}\")\n",
    "\n",
    "models_save_btn = widgets.Button(description=\"Save Models Config\", button_style='success')\n",
    "models_save_btn.on_click(save_models_config)\n",
    "\n",
    "display(models_config_editor)\n",
    "display(models_save_btn)\n",
    "\n",
    "# Save All button for convenience\n",
    "def save_all_configs(button):\n",
    "    \"\"\"Save all config changes at once\"\"\"\n",
    "    save_agent_config(None)\n",
    "    save_prompts_config(None)\n",
    "    save_models_config(None)\n",
    "\n",
    "print(\"\\nüíæ Save All Changes\")\n",
    "save_all_btn = widgets.Button(description=\"Save All Configs\", button_style='info')\n",
    "save_all_btn.on_click(save_all_configs)\n",
    "display(save_all_btn)\n",
    "\n",
    "print(f\"\\nüíæ Temp config files location:\")\n",
    "for config_type, path in temp_file_paths.items():\n",
    "    print(f\"  {config_type}: {path}\")\n",
    "\n",
    "print(\"\\nüí° Frustration Detection Tips:\")\n",
    "print(\"  ‚Ä¢ Lower critical/high thresholds = more sensitive frustration detection\")\n",
    "print(\"  ‚Ä¢ intervention_threshold controls when to escalate to humans\")\n",
    "print(\"  ‚Ä¢ Lower temperature = more consistent frustration scoring\")\n",
    "print(\"  ‚Ä¢ Edit frustration_indicators to customize keyword detection\")\n",
    "print(\"  ‚Ä¢ Employee protection settings help manage agent workload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.5: How Frustration Detection Works\n",
    "\n",
    "The Frustration Agent uses a sophisticated LLM-based approach to detect customer frustration, with conversation pattern tracking and intelligent scoring that prioritizes accuracy and consistency. Understanding this process helps optimize the detection parameters for accurate frustration assessment and appropriate human intervention timing.\n",
    "\n",
    "### Frustration Detection Architecture\n",
    "\n",
    "The frustration detection process follows these key steps:\n",
    "\n",
    "1. **LLM-Based Sentiment Analysis**: Uses configured LLM with specialized prompts for comprehensive emotional assessment\n",
    "2. **Conversation Pattern Analysis**: Tracks frustration progression across multiple interactions using LLM analysis\n",
    "3. **Unified Scoring System**: Combines current query and historical patterns for balanced assessment\n",
    "4. **Intervention Decision Making**: Compares scores against configurable thresholds to determine escalation\n",
    "5. **Employee Wellbeing Protection**: Considers agent workload and stress levels in routing decisions\n",
    "\n",
    "### YAML Configuration Components\n",
    "\n",
    "#### 1. Agent Configuration (`config.yaml`)\n",
    "\n",
    "**Frustration Thresholds** (`src/nodes/frustration_agent.py:384-398`):\n",
    "```yaml\n",
    "frustration_thresholds:\n",
    "  critical: 8.0    # Immediate human intervention required\n",
    "  high: 6.0        # Priority human routing  \n",
    "  moderate: 3.0    # Monitor and prepare for escalation\n",
    "  # Below 3.0 = low frustration\n",
    "```\n",
    "\n",
    "**Intervention Threshold** (`src/nodes/frustration_agent.py:457-477`):\n",
    "```yaml\n",
    "intervention_threshold: \"high\"  # Options: critical, high, moderate\n",
    "```\n",
    "\n",
    "**Analysis Configuration** (`src/nodes/frustration_agent.py:26-33`):\n",
    "```yaml\n",
    "analysis:\n",
    "  use_llm_analysis: true                    # Primary LLM-based sentiment analysis\n",
    "  track_frustration_progression: true       # Monitor escalation patterns using LLM\n",
    "  consider_interaction_history: true        # Factor in conversation history\n",
    "  weight_recent_interactions: 0.7           # Weight of current query vs pattern\n",
    "  weight_historical_pattern: 0.3            # Weight of pattern analysis\n",
    "```\n",
    "\n",
    "**Employee Protection Settings** (`src/nodes/frustration_agent.py:40-44`):\n",
    "```yaml\n",
    "employee_protection:\n",
    "  max_consecutive_frustrated_customers: 3   # Rotation threshold\n",
    "  cooldown_period_hours: 2                 # Break between difficult cases\n",
    "  high_frustration_rotation: true          # Distribute high-stress cases\n",
    "```\n",
    "\n",
    "#### 2. Prompts Configuration (`prompts.yaml`)\n",
    "\n",
    "**System Prompt** (`src/nodes/frustration_agent.py:183`):\n",
    "- Establishes agent role as frustration detection specialist\n",
    "- Defines focus areas: emotional tone, escalation patterns, urgency signals\n",
    "- Emphasizes cultural sensitivity and customer wellbeing\n",
    "\n",
    "**Frustration Analysis Prompt** (`src/nodes/frustration_agent.py:183-247`):\n",
    "- Structures 1-10 scale assessment with specific criteria per level\n",
    "- Defines output format: Score, Confidence, Reasoning\n",
    "- Guides LLM to identify specific frustration indicators and emotional context\n",
    "\n",
    "**Pattern Analysis Prompt** (lines 44-63):\n",
    "- Analyzes interaction history for escalation trends using LLM evaluation\n",
    "- Identifies rapid-fire communication patterns\n",
    "- Assesses repetition and unresolved issues\n",
    "\n",
    "#### 3. Models Configuration (`models.yaml`)\n",
    "\n",
    "**Temperature Settings** (`src/nodes/frustration_agent.py:242-247`):\n",
    "```yaml\n",
    "model_overrides:\n",
    "  temperature: 0.2          # Base temperature for consistent detection\n",
    "  per_model:\n",
    "    frustration_analysis:\n",
    "      temperature: 0.1      # Very low for objective sentiment analysis\n",
    "    pattern_detection:\n",
    "      temperature: 0.2      # Consistent pattern recognition\n",
    "    trend_analysis:\n",
    "      temperature: 0.3      # Slight creativity for trend interpretation\n",
    "```\n",
    "\n",
    "### Detection Logic Flow\n",
    "\n",
    "#### Step 1: LLM-Based Sentiment Analysis (`src/nodes/frustration_agent.py:142-179`)\n",
    "\n",
    "1. **Prompt Formation**: Combines system prompt with frustration analysis template\n",
    "2. **Structured Evaluation**: LLM assesses emotional tone, language patterns, and escalation intent\n",
    "3. **Score Extraction**: Parses numerical score (1-10), confidence (0.1-1.0), and detailed reasoning\n",
    "4. **Fallback Handling**: Uses conservative moderate score (2.0) if LLM analysis fails\n",
    "\n",
    "#### Step 2: Pattern Analysis (`src/nodes/frustration_agent.py:305-317`)\n",
    "\n",
    "The system tracks frustration patterns across conversation history using LLM analysis:\n",
    "\n",
    "**Historical Query Analysis**:\n",
    "- Each previous query analyzed using LLM frustration detection\n",
    "- Scores compiled for trend calculation\n",
    "- Fallback to moderate score (2.0) on analysis errors\n",
    "\n",
    "**First Turn Handling** (`src/nodes/frustration_agent.py:294-302`):\n",
    "- For conversations with < 2 queries, pattern_score = current_llm_score\n",
    "- Eliminates artificial dampening on initial interactions\n",
    "- Ensures consistent scoring between overall and individual query analysis\n",
    "\n",
    "**Trend Calculation** (`src/nodes/frustration_agent.py:319-333`):\n",
    "```python\n",
    "if recent_avg > earlier_avg + 1.0:\n",
    "    trend = \"escalating\"    # Frustration increasing\n",
    "elif recent_avg < earlier_avg - 1.0:\n",
    "    trend = \"decreasing\"    # Frustration improving  \n",
    "else:\n",
    "    trend = \"stable\"        # Consistent level\n",
    "```\n",
    "\n",
    "#### Step 3: Combined Assessment (`src/nodes/frustration_agent.py:408-425`)\n",
    "\n",
    "**Score Combination** (`src/nodes/frustration_agent.py:417-420`):\n",
    "```python\n",
    "combined_score = (\n",
    "    current_analysis[\"current_query_score\"] * 0.7 +  # Current query weight\n",
    "    history_analysis[\"pattern_score\"] * 0.3           # Pattern weight\n",
    ")\n",
    "```\n",
    "\n",
    "**First Turn Advantage**: On first turns, both current and pattern scores use the same LLM analysis, preventing score dampening and ensuring accurate initial assessments.\n",
    "\n",
    "**Frustration Level Mapping** (`src/nodes/frustration_agent.py:381-397`):\n",
    "```python\n",
    "if score >= 8.0:    # Critical\n",
    "if score >= 6.0:    # High  \n",
    "if score >= 3.0:    # Moderate\n",
    "else:               # Low\n",
    "```\n",
    "\n",
    "#### Step 4: Intervention Decision (`src/nodes/frustration_agent.py:457-477`)\n",
    "\n",
    "**Threshold-Based Escalation**:\n",
    "```python\n",
    "if intervention_threshold == \"moderate\":\n",
    "    escalate_on = [\"critical\", \"high\", \"moderate\"]\n",
    "elif intervention_threshold == \"high\":  # Default\n",
    "    escalate_on = [\"critical\", \"high\"]\n",
    "elif intervention_threshold == \"critical\":\n",
    "    escalate_on = [\"critical\"]\n",
    "```\n",
    "\n",
    "### Key Improvements in LLM-Only Approach\n",
    "\n",
    "**Enhanced Accuracy**:\n",
    "- No keyword-based false positives from rule-based detection\n",
    "- Context-aware emotional assessment through LLM reasoning\n",
    "- Cultural and linguistic nuance recognition\n",
    "\n",
    "**Consistent Scoring**:\n",
    "- First turn pattern_score = current_llm_score prevents artificial dampening\n",
    "- Pure LLM analysis eliminates rule-based/LLM scoring conflicts\n",
    "- Temperature control ensures reproducible results\n",
    "\n",
    "**Better Pattern Recognition**:\n",
    "- Historical queries analyzed using same LLM approach as current queries\n",
    "- Coherent trend analysis across conversation history\n",
    "- Intelligent fallback handling maintains service continuity\n",
    "\n",
    "### Configuration Best Practices\n",
    "\n",
    "**For Sensitive Detection**:\n",
    "- Lower thresholds: critical: 6.0, high: 4.0, moderate: 2.0\n",
    "- Set intervention_threshold to \"moderate\"\n",
    "- Use temperature 0.1 for maximum consistency\n",
    "\n",
    "**For Conservative Detection**:\n",
    "- Higher thresholds: critical: 9.0, high: 7.0, moderate: 4.0  \n",
    "- Set intervention_threshold to \"critical\"\n",
    "- Use temperature 0.2 for balanced analysis\n",
    "\n",
    "**For Employee Protection Focus**:\n",
    "- Enable high_frustration_rotation: true\n",
    "- Set max_consecutive_frustrated_customers: 2\n",
    "- Lower cooldown_period_hours: 1\n",
    "\n",
    "**For Pattern Analysis Enhancement**:\n",
    "- Enable track_frustration_progression: true\n",
    "- Lower escalation_trend_threshold: 2\n",
    "- Reduce rapid_fire_threshold_minutes: 1\n",
    "\n",
    "### Contributing Factors Analysis\n",
    "\n",
    "**LLM-Based Factor Identification** (`src/nodes/frustration_agent.py:456-463`):\n",
    "The system identifies specific contributors using LLM reasoning analysis:\n",
    "\n",
    "```python\n",
    "if current.get(\"llm_analysis\"):\n",
    "    llm_reasoning = current[\"llm_analysis\"].lower()\n",
    "    if \"escalat\" in llm_reasoning or \"urgent\" in llm_reasoning:\n",
    "        factors.append(\"escalation_language\")\n",
    "    if \"frustrat\" in llm_reasoning or \"anger\" in llm_reasoning:\n",
    "        factors.append(\"strong_negative_sentiment\")\n",
    "```\n",
    "\n",
    "### Employee Wellbeing Integration\n",
    "\n",
    "**Workload Balancing** (prompts.yaml lines 117-136):\n",
    "- Tracks recent frustration assignments per agent\n",
    "- Identifies agents with high frustration tolerance\n",
    "- Provides cooldown recommendations\n",
    "- Suggests post-interaction support needs\n",
    "\n",
    "**Monitoring and Alerts** (config.yaml lines 123-128):\n",
    "```yaml\n",
    "monitoring:\n",
    "  track_frustration_trends: true\n",
    "  alert_on_critical_frustration: true  \n",
    "  generate_frustration_reports: true\n",
    "  monitor_agent_frustration_load: true\n",
    "```\n",
    "\n",
    "### Assessment Output Structure\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"overall_score\": 7.2,\n",
    "  \"overall_level\": \"high\", \n",
    "  \"confidence\": 0.85,\n",
    "  \"current_analysis\": {\n",
    "    \"current_query_score\": 8.0,\n",
    "    \"rule_based_indicators\": [],  // No longer used\n",
    "    \"llm_analysis\": \"Detailed LLM reasoning...\"\n",
    "  },\n",
    "  \"history_analysis\": {\n",
    "    \"pattern_score\": 5.5,  // Same as current_query_score on first turn\n",
    "    \"escalation_trend\": \"escalating\",\n",
    "    \"interaction_count\": 4\n",
    "  },\n",
    "  \"contributing_factors\": [\n",
    "    \"high_frustration_language\",\n",
    "    \"strong_negative_sentiment\", \n",
    "    \"escalation_language\"\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "This comprehensive LLM-based system ensures accurate frustration detection with improved consistency, especially on first-turn interactions, while prioritizing both customer experience and employee wellbeing through configurable thresholds and protection mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Step 3: Load Chatbot Conversation Results\n",
    "\n",
    "Load conversation results from chatbot_tester.ipynb exports for frustration analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Load Chatbot Conversation Results for Frustration Analysis\n",
      "\n",
      "üí° How to get conversation data:\n",
      "1. Run chatbot_tester.ipynb and export conversation results\n",
      "2. Upload the exported JSON file below\n",
      "3. The file should contain conversation turns with customer queries\n",
      "\n",
      "üìÑ Expected JSON format:\n",
      "- Array of conversations with conversation_history containing:\n",
      "- Each turn: {'customer_query': '...', 'chatbot_response': '...', 'turn_number': N}\n",
      "- Customer queries will be analyzed for frustration indicators\n",
      "- Conversation patterns will be tracked for escalation trends\n",
      "\n",
      "üìÅ Upload your conversation results file:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4c44eb33454632a885e16e20e47773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.json', description='Upload conversation results:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File upload widget for loading conversation results\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='.json',\n",
    "    multiple=False,\n",
    "    description='Upload conversation results:'\n",
    ")\n",
    "\n",
    "# Instructions for file format\n",
    "print(\"üìù Load Chatbot Conversation Results for Frustration Analysis\")\n",
    "print(\"\\nüí° How to get conversation data:\")\n",
    "print(\"1. Run chatbot_tester.ipynb and export conversation results\")\n",
    "print(\"2. Upload the exported JSON file below\")\n",
    "print(\"3. The file should contain conversation turns with customer queries\")\n",
    "print(\"\\nüìÑ Expected JSON format:\")\n",
    "print(\"- Array of conversations with conversation_history containing:\")\n",
    "print(\"- Each turn: {'customer_query': '...', 'chatbot_response': '...', 'turn_number': N}\")\n",
    "print(\"- Customer queries will be analyzed for frustration indicators\")\n",
    "print(\"- Conversation patterns will be tracked for escalation trends\")\n",
    "print(\"\\nüìÅ Upload your conversation results file:\")\n",
    "display(file_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading conversations from: chatbot_agent_output.json\n",
      "‚úÖ Successfully loaded 20 valid conversations from 20 total entries\n",
      "‚úÖ Loaded 60 conversation turns from 20 conversations\n",
      "\n",
      "üìä Conversation Turn Distribution:\n",
      "  Total turns: 60\n",
      "  Unique conversations: 20\n",
      "  Customer types: {'confused': np.int64(24), 'urgent': np.int64(17), 'frustrated': np.int64(12), 'normal': np.int64(7)}\n",
      "  Complexity levels: {'complex': np.int64(26), 'simple': np.int64(20), 'medium': np.int64(14)}\n",
      "\n",
      "üîç Preliminary Frustration Indicator Analysis:\n",
      "  Potential high frustration turns: 2 (3.3%)\n",
      "  Potential moderate frustration turns: 2 (3.3%)\n",
      "  Potential escalation requests: 3 (5.0%)\n",
      "\n",
      "üìã Sample Conversation Turns for Frustration Analysis:\n",
      "  Turn 1.1 [frustrated]:\n",
      "    Query: Why did my premium increase by $200? This is ridiculous - I haven't had any clai...\n",
      "    Context: 0 previous turns in conversation\n",
      "  Turn 1.2 [frustrated]:\n",
      "    Query: ARE YOU KIDDING ME?! I ALREADY TOLD YOU I HAVEN'T MADE ANY CLAIMS, SO IT'S NOT L...\n",
      "    Context: 1 previous turns in conversation\n",
      "  Turn 2.1 [urgent]:\n",
      "    Query: I just had a car accident. What do I need to do right now?\n",
      "    Context: 0 previous turns in conversation\n",
      "  ... and 57 more turns\n"
     ]
    }
   ],
   "source": [
    "# Load conversation results from uploaded file and prepare context data\n",
    "conversation_data = []\n",
    "\n",
    "def load_conversations_from_file(file_content, filename):\n",
    "    \"\"\"Load conversations from uploaded JSON file with enhanced format detection\"\"\"\n",
    "    try:\n",
    "        # Handle different content types\n",
    "        if isinstance(file_content, memoryview):\n",
    "            content_bytes = file_content.tobytes()\n",
    "        elif hasattr(file_content, 'decode'):\n",
    "            content_bytes = file_content\n",
    "        else:\n",
    "            content_bytes = str(file_content).encode('utf-8')\n",
    "        \n",
    "        # Decode to string and parse JSON\n",
    "        data = json.loads(content_bytes.decode('utf-8'))\n",
    "        \n",
    "        # Handle different JSON formats with enhanced detection\n",
    "        conversations = []\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            # Check for different export formats from chatbot_tester\n",
    "            if 'conversation_results' in data:\n",
    "                # New chatbot_tester export format\n",
    "                conversations = data['conversation_results']\n",
    "            elif 'conversations' in data:\n",
    "                # Standard conversations format\n",
    "                conversations = data['conversations']\n",
    "            elif 'results' in data:\n",
    "                # Results array format\n",
    "                conversations = data['results']\n",
    "            elif 'metadata' in data and 'conversations' in data:\n",
    "                # Metadata + conversations format\n",
    "                conversations = data['conversations']\n",
    "            elif any(key in data for key in ['conversation_history', 'customer_type', 'original_question']):\n",
    "                # Single conversation object\n",
    "                conversations = [data]\n",
    "            else:\n",
    "                # Try to extract any array-like data\n",
    "                array_fields = [v for v in data.values() if isinstance(v, list)]\n",
    "                if array_fields:\n",
    "                    conversations = array_fields[0]\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Unknown dictionary format. Keys found: {list(data.keys())}\")\n",
    "                    return []\n",
    "        elif isinstance(data, list):\n",
    "            # Direct list of conversations\n",
    "            conversations = data\n",
    "        else:\n",
    "            print(f\"‚ùå Unexpected data format: {type(data)}\")\n",
    "            return []\n",
    "        \n",
    "        # Validate that we have actual conversation data\n",
    "        if not conversations:\n",
    "            print(\"‚ùå No conversations found in the uploaded file\")\n",
    "            return []\n",
    "        \n",
    "        # Validate conversation structure\n",
    "        valid_conversations = []\n",
    "        for i, conv in enumerate(conversations):\n",
    "            if not isinstance(conv, dict):\n",
    "                print(f\"‚ö†Ô∏è Skipping invalid conversation {i+1}: not a dictionary\")\n",
    "                continue\n",
    "            \n",
    "            # Check for required fields or conversation history\n",
    "            has_history = 'conversation_history' in conv and conv['conversation_history']\n",
    "            has_single_turn = any(field in conv for field in ['query', 'customer_query', 'original_question'])\n",
    "            \n",
    "            if not (has_history or has_single_turn):\n",
    "                print(f\"‚ö†Ô∏è Skipping conversation {i+1}: no conversation history or query found\")\n",
    "                continue\n",
    "                \n",
    "            valid_conversations.append(conv)\n",
    "        \n",
    "        if not valid_conversations:\n",
    "            print(\"‚ùå No valid conversations found after validation\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"‚úÖ Successfully loaded {len(valid_conversations)} valid conversations from {len(conversations)} total entries\")\n",
    "        return valid_conversations\n",
    "            \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"‚ùå JSON parsing error: {e}\")\n",
    "        print(\"Please ensure the file is valid JSON format\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading file '{filename}': {e}\")\n",
    "        print(\"Please check the file format and try again\")\n",
    "        return []\n",
    "\n",
    "def extract_conversation_turns_with_context(conversations):\n",
    "    \"\"\"Extract individual turns from conversations and build context for frustration analysis\"\"\"\n",
    "    turns = []\n",
    "    \n",
    "    for conv_idx, conversation in enumerate(conversations):\n",
    "        conv_id = conversation.get('id', conversation.get('conversation_id', conv_idx + 1))\n",
    "        customer_type = conversation.get('customer_type', 'unknown')\n",
    "        complexity = conversation.get('complexity', 'medium')\n",
    "        \n",
    "        # Get conversation history with multiple format support\n",
    "        history = conversation.get('conversation_history', [])\n",
    "        \n",
    "        # If no conversation_history, try to extract from other fields\n",
    "        if not history:\n",
    "            # Check for single turn conversation\n",
    "            query = (conversation.get('query') or \n",
    "                    conversation.get('customer_query') or \n",
    "                    conversation.get('original_question'))\n",
    "            response = (conversation.get('ai_response') or \n",
    "                       conversation.get('chatbot_response') or \n",
    "                       conversation.get('response'))\n",
    "            \n",
    "            if query and response:\n",
    "                history = [{\n",
    "                    'turn_number': 1,\n",
    "                    'customer_query': query,\n",
    "                    'chatbot_response': response\n",
    "                }]\n",
    "        \n",
    "        # Skip conversations with no extractable history\n",
    "        if not history:\n",
    "            print(f\"‚ö†Ô∏è Skipping conversation {conv_id}: no turns found\")\n",
    "            continue\n",
    "        \n",
    "        # Extract turns from conversation history and build context\n",
    "        for turn_idx, turn in enumerate(history):\n",
    "            # Skip invalid turns\n",
    "            if not isinstance(turn, dict):\n",
    "                continue\n",
    "                \n",
    "            customer_query = turn.get('customer_query', turn.get('query', ''))\n",
    "            chatbot_response = turn.get('chatbot_response', turn.get('response', ''))\n",
    "            \n",
    "            if not customer_query:\n",
    "                continue\n",
    "            \n",
    "            # Create simulated timestamps for frustration pattern analysis\n",
    "            base_timestamp = datetime.now() - timedelta(hours=1) + timedelta(minutes=turn_idx * 5)\n",
    "            \n",
    "            turn_data = {\n",
    "                'conversation_id': conv_id,\n",
    "                'user_id': f'user_{conv_id}',\n",
    "                'session_id': f'session_{conv_id}',\n",
    "                'turn_number': turn.get('turn_number', turn_idx + 1),\n",
    "                'timestamp': base_timestamp,\n",
    "                'customer_type': customer_type,\n",
    "                'complexity': complexity,\n",
    "                'customer_query': customer_query,\n",
    "                'chatbot_response': chatbot_response,\n",
    "                'original_customer_satisfaction': turn.get('customer_satisfaction'),\n",
    "                'conversation_metadata': {\n",
    "                    'total_turns': len(history),\n",
    "                    'final_outcome': conversation.get('final_outcome'),\n",
    "                    'original_question': conversation.get('original_question', ''),\n",
    "                    'turn_index': turn_idx,  # Position in conversation\n",
    "                    'is_first_turn': turn_idx == 0,\n",
    "                    'is_last_turn': turn_idx == len(history) - 1,\n",
    "                },\n",
    "                # Previous turns in conversation for pattern analysis\n",
    "                'previous_turns': history[:turn_idx] if turn_idx > 0 else []\n",
    "            }\n",
    "            turns.append(turn_data)\n",
    "    \n",
    "    return turns\n",
    "\n",
    "def simulate_context_history(turn_data, context_provider):\n",
    "    \"\"\"Simulate conversation history in context provider for pattern analysis\"\"\"\n",
    "    try:\n",
    "        # Add previous turns to context for pattern analysis\n",
    "        for prev_turn_idx, prev_turn in enumerate(turn_data['previous_turns']):\n",
    "            # Create context entries for previous queries\n",
    "            prev_timestamp = turn_data['timestamp'] - timedelta(minutes=(len(turn_data['previous_turns']) - prev_turn_idx) * 5)\n",
    "            \n",
    "            query_entry = ContextEntry(\n",
    "                entry_id=f\"{turn_data['conversation_id']}_{prev_turn_idx + 1}_query\",\n",
    "                user_id=turn_data['user_id'],\n",
    "                session_id=turn_data['session_id'],\n",
    "                timestamp=prev_timestamp,\n",
    "                entry_type=\"query\",\n",
    "                content=prev_turn.get('customer_query', ''),\n",
    "                metadata={\n",
    "                    'turn_number': prev_turn_idx + 1,\n",
    "                    'conversation_id': turn_data['conversation_id']\n",
    "                }\n",
    "            )\n",
    "            context_provider.save_context_entry(query_entry)\n",
    "            \n",
    "            # Create context entries for previous responses\n",
    "            response_entry = ContextEntry(\n",
    "                entry_id=f\"{turn_data['conversation_id']}_{prev_turn_idx + 1}_response\",\n",
    "                user_id=turn_data['user_id'],\n",
    "                session_id=turn_data['session_id'],\n",
    "                timestamp=prev_timestamp + timedelta(seconds=30),\n",
    "                entry_type=\"response\",\n",
    "                content=prev_turn.get('chatbot_response', ''),\n",
    "                metadata={\n",
    "                    'turn_number': prev_turn_idx + 1,\n",
    "                    'conversation_id': turn_data['conversation_id']\n",
    "                }\n",
    "            )\n",
    "            context_provider.save_context_entry(response_entry)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not simulate context history: {e}\")\n",
    "\n",
    "# Process uploaded file with enhanced error handling\n",
    "if file_upload.value:\n",
    "    uploaded_file = None\n",
    "    filename = None\n",
    "    file_content = None\n",
    "    \n",
    "    # Handle different file upload widget formats\n",
    "    try:\n",
    "        if isinstance(file_upload.value, tuple) and len(file_upload.value) > 0:\n",
    "            uploaded_file = file_upload.value[0]\n",
    "            filename = uploaded_file['name']\n",
    "            file_content = uploaded_file['content']\n",
    "        elif isinstance(file_upload.value, dict) and len(file_upload.value) > 0:\n",
    "            uploaded_file = list(file_upload.value.values())[0]\n",
    "            filename = uploaded_file['metadata']['name']\n",
    "            file_content = uploaded_file['content']\n",
    "        else:\n",
    "            print(f\"‚ùå Unable to read uploaded file format: {type(file_upload.value)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing uploaded file: {e}\")\n",
    "    \n",
    "    if uploaded_file and filename and file_content is not None:\n",
    "        print(f\"üìÅ Loading conversations from: {filename}\")\n",
    "        \n",
    "        raw_conversations = load_conversations_from_file(file_content, filename)\n",
    "        \n",
    "        if raw_conversations:\n",
    "            conversation_data = extract_conversation_turns_with_context(raw_conversations)\n",
    "            \n",
    "            if conversation_data:\n",
    "                print(f\"‚úÖ Loaded {len(conversation_data)} conversation turns from {len(raw_conversations)} conversations\")\n",
    "                \n",
    "                # Display conversation statistics\n",
    "                df_preview = pd.DataFrame(conversation_data)\n",
    "                print(f\"\\nüìä Conversation Turn Distribution:\")\n",
    "                print(f\"  Total turns: {len(conversation_data)}\")\n",
    "                print(f\"  Unique conversations: {df_preview['conversation_id'].nunique()}\")\n",
    "                print(f\"  Customer types: {dict(df_preview['customer_type'].value_counts())}\")\n",
    "                print(f\"  Complexity levels: {dict(df_preview['complexity'].value_counts())}\")\n",
    "                \n",
    "                # Analyze frustration indicators in queries\n",
    "                print(f\"\\nüîç Preliminary Frustration Indicator Analysis:\")\n",
    "                high_frustration_keywords = ['angry', 'frustrated', 'terrible', 'awful', 'ridiculous', 'unacceptable', 'furious', 'livid', 'outraged']\n",
    "                moderate_frustration_keywords = ['annoyed', 'disappointed', 'upset', 'confused', 'stuck', 'concerned', 'worried', 'bothered']\n",
    "                escalation_keywords = ['manager', 'supervisor', 'complaint', 'cancel', 'refund', 'speak to someone', 'escalate', 'higher up']\n",
    "                \n",
    "                high_frustration_turns = 0\n",
    "                moderate_frustration_turns = 0\n",
    "                escalation_turns = 0\n",
    "                \n",
    "                for turn in conversation_data:\n",
    "                    query_lower = turn['customer_query'].lower()\n",
    "                    if any(keyword in query_lower for keyword in high_frustration_keywords):\n",
    "                        high_frustration_turns += 1\n",
    "                    if any(keyword in query_lower for keyword in moderate_frustration_keywords):\n",
    "                        moderate_frustration_turns += 1\n",
    "                    if any(keyword in query_lower for keyword in escalation_keywords):\n",
    "                        escalation_turns += 1\n",
    "                \n",
    "                print(f\"  Potential high frustration turns: {high_frustration_turns} ({high_frustration_turns/len(conversation_data)*100:.1f}%)\")\n",
    "                print(f\"  Potential moderate frustration turns: {moderate_frustration_turns} ({moderate_frustration_turns/len(conversation_data)*100:.1f}%)\")\n",
    "                print(f\"  Potential escalation requests: {escalation_turns} ({escalation_turns/len(conversation_data)*100:.1f}%)\")\n",
    "                \n",
    "                # Show sample turns\n",
    "                print(f\"\\nüìã Sample Conversation Turns for Frustration Analysis:\")\n",
    "                for i, turn in enumerate(conversation_data[:3]):\n",
    "                    query_preview = turn['customer_query'][:80] + \"...\" if len(turn['customer_query']) > 80 else turn['customer_query']\n",
    "                    print(f\"  Turn {turn['conversation_id']}.{turn['turn_number']} [{turn['customer_type']}]:\")\n",
    "                    print(f\"    Query: {query_preview}\")\n",
    "                    print(f\"    Context: {len(turn['previous_turns'])} previous turns in conversation\")\n",
    "                if len(conversation_data) > 3:\n",
    "                    print(f\"  ... and {len(conversation_data) - 3} more turns\")\n",
    "            else:\n",
    "                print(\"‚ùå No valid conversation turns extracted from the loaded data\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to load conversations from file\")\n",
    "    else:\n",
    "        print(\"‚ùå Error accessing uploaded file data\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please upload a JSON file with conversation results from chatbot_tester.ipynb.\")\n",
    "    print(\"\\nüí° Supported file formats:\")\n",
    "    print(\"  ‚Ä¢ chatbot_tester.ipynb export files (conversation_results format)\")\n",
    "    print(\"  ‚Ä¢ Standard conversation JSON files\")\n",
    "    print(\"  ‚Ä¢ Any JSON file with conversation history or query/response pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Frustration Agent\n",
    "\n",
    "Create the Frustration Agent instance with the configured settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing Frustration Agent with configured settings...\n",
      "‚úÖ 16:56:09.073 [INFO    ] context_manager | SQLite context provider initialized | operation=__init__\n",
      "‚úÖ 16:56:09.114 [INFO    ] factory         | Attempting to create provider: deepinfra_general_standard\n",
      "‚úÖ Creating LLM provider: deepinfra_general_standard ‚Üí kimi-k2-instruct (deepinfra)\n",
      "‚úÖ 16:56:09.117 [INFO    ] kimi-k2-instruct | Initializing LLM provider | model_name=kimi-k2-instruct\n",
      "‚úÖ 16:56:09.122 [INFO    ] kimi-k2-instruct | LLM provider initialized successfully | model_name=kimi-k2-instruct\n",
      "‚úÖ 16:56:09.123 [INFO    ] factory         | Successfully created provider: deepinfra_general_standard\n",
      "‚úÖ 16:56:09.124 [INFO    ] frustration_agent | Frustration Agent LLM provider initialized | operation=initialize_llm_provider model_name=kimi-k2-instruct\n",
      "‚úÖ Frustration Agent initialized successfully!\n",
      "  Agent config: frustration_agent\n",
      "  LLM provider: kimi-k2-instruct\n",
      "\n",
      "üìã Frustration Agent Configuration:\n",
      "  Frustration thresholds:\n",
      "    critical: 8.0\n",
      "    high: 6.0\n",
      "    moderate: 3.0\n",
      "  Intervention threshold: high\n",
      "  Analysis settings:\n",
      "    Use LLM analysis: True\n",
      "    Track frustration progression: True\n",
      "    Consider interaction history: True\n",
      "\n",
      "üöÄ Frustration Agent is ready for conversation analysis!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Frustration Agent with temporary configuration\n",
    "def initialize_frustration_agent():\n",
    "    \"\"\"Initialize Frustration Agent using temporary configuration files\"\"\"\n",
    "    try:\n",
    "        # Create a complete temporary config structure that ConfigManager expects\n",
    "        temp_base_config_dir = temp_config_dir.parent / 'temp_frustration_config'\n",
    "        temp_base_config_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Create the expected directory structure\n",
    "        temp_agents_dir = temp_base_config_dir / 'agents' / 'frustration_agent'\n",
    "        temp_shared_dir = temp_base_config_dir / 'shared'\n",
    "        temp_agents_dir.mkdir(parents=True, exist_ok=True)\n",
    "        temp_shared_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy agent-specific configs to the expected location\n",
    "        import shutil\n",
    "        shutil.copy2(temp_file_paths['agent_config'], temp_agents_dir / 'config.yaml')\n",
    "        shutil.copy2(temp_file_paths['prompts_config'], temp_agents_dir / 'prompts.yaml')\n",
    "        shutil.copy2(temp_file_paths['models_config'], temp_agents_dir / 'models.yaml')\n",
    "        \n",
    "        # Copy shared configs that agents might need\n",
    "        original_shared_dir = config_base_path / 'shared'\n",
    "        for shared_file in ['models.yaml', 'system.yaml', 'providers.yaml']:\n",
    "            if (original_shared_dir / shared_file).exists():\n",
    "                shutil.copy2(original_shared_dir / shared_file, temp_shared_dir / shared_file)\n",
    "        \n",
    "        # Copy main config.yaml if needed\n",
    "        if (config_base_path / 'config.yaml').exists():\n",
    "            shutil.copy2(config_base_path / 'config.yaml', temp_base_config_dir / 'config.yaml')\n",
    "        \n",
    "        # Create ConfigManager with the complete structure\n",
    "        config_manager = ConfigManager(config_dir=str(temp_base_config_dir))\n",
    "        \n",
    "        # Initialize context provider (using in-memory for testing)\n",
    "        context_provider = SQLiteContextProvider(db_path=\":memory:\")\n",
    "        \n",
    "        # Create Frustration Agent\n",
    "        frustration_agent = FrustrationAgentNode(\n",
    "            config_manager=config_manager,\n",
    "            context_provider=context_provider\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Frustration Agent initialized successfully!\")\n",
    "        print(f\"  Agent config: {frustration_agent.agent_config.name if frustration_agent.agent_config else 'Unknown'}\")\n",
    "        print(f\"  LLM provider: {frustration_agent.llm_provider.model_name if frustration_agent.llm_provider else 'None'}\")\n",
    "        \n",
    "        return frustration_agent, context_provider\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error initializing Frustration Agent: {e}\")\n",
    "        import traceback\n",
    "        print(\"Full traceback:\")\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "frustration_agent = None\n",
    "context_provider = None\n",
    "\n",
    "print(\"üîß Initializing Frustration Agent with configured settings...\")\n",
    "\n",
    "# Initialize the frustration agent\n",
    "frustration_agent, context_provider = initialize_frustration_agent()\n",
    "\n",
    "if frustration_agent:\n",
    "    # Display agent configuration\n",
    "    if frustration_agent.agent_config:\n",
    "        settings = frustration_agent.agent_config.settings\n",
    "        print(f\"\\nüìã Frustration Agent Configuration:\")\n",
    "        print(f\"  Frustration thresholds:\")\n",
    "        frustration_thresholds = settings.get('frustration_thresholds', {})\n",
    "        for threshold_name, threshold_value in frustration_thresholds.items():\n",
    "            print(f\"    {threshold_name}: {threshold_value}\")\n",
    "        \n",
    "        print(f\"  Intervention threshold: {settings.get('intervention_threshold', 'high')}\")\n",
    "        \n",
    "        analysis_settings = settings.get('analysis', {})\n",
    "        print(f\"  Analysis settings:\")\n",
    "        print(f\"    Use LLM analysis: {analysis_settings.get('use_llm_analysis', True)}\")\n",
    "        print(f\"    Track frustration progression: {analysis_settings.get('track_frustration_progression', True)}\")\n",
    "        print(f\"    Consider interaction history: {analysis_settings.get('consider_interaction_history', True)}\")\n",
    "    \n",
    "    # Show frustration indicators\n",
    "    if hasattr(frustration_agent, 'frustration_indicators'):\n",
    "        indicators = frustration_agent.frustration_indicators\n",
    "        print(f\"\\nüîç Frustration Detection Indicators:\")\n",
    "        print(f\"  High frustration keywords: {len(indicators.get('high_frustration', []))}\")\n",
    "        print(f\"  Moderate frustration keywords: {len(indicators.get('moderate_frustration', []))}\")\n",
    "        print(f\"  Escalation phrases: {len(indicators.get('escalation_phrases', []))}\")\n",
    "        print(f\"  Urgency indicators: {len(indicators.get('urgency_indicators', []))}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Frustration Agent is ready for conversation analysis!\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Frustration Agent initialization failed. Please check configuration and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 5: Run Frustration Analysis\n",
    "\n",
    "Process each conversation turn through the Frustration Agent to generate frustration scores and intervention recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting frustration analysis process...\n",
      "üò§ Running frustration analysis on 60 conversation turns...\n",
      "\\rProcessing turn 1/60 (Conv 1.1)...‚úÖ 16:56:21.499 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:21.500 [ERROR   ] context_manager | Failed to get recent context | user_id=user_1 session_id=session_1 operation=get_recent_context\n",
      "‚ùå 16:56:21.501 [ERROR   ] context_manager | Failed to save context entry | user_id=user_1 session_id=session_1 operation=save_context_entry\n",
      "‚úÖ 16:56:21.502 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_1_1 user_id=user_1 session_id=session_1\n",
      "‚ùå 16:56:21.503 [ERROR   ] context_manager | Failed to save context entry | user_id=user_1 session_id=session_1 operation=save_context_entry\n",
      "‚ùå 16:56:21.504 [ERROR   ] context_manager | Failed to save context entry | user_id=user_1 session_id=session_1 operation=save_context_entry\n",
      "\\rProcessing turn 2/60 (Conv 1.2)...‚úÖ 16:56:25.218 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:25.219 [ERROR   ] context_manager | Failed to get recent context | user_id=user_1 session_id=session_1 operation=get_recent_context\n",
      "‚ùå 16:56:25.220 [ERROR   ] context_manager | Failed to save context entry | user_id=user_1 session_id=session_1 operation=save_context_entry\n",
      "‚úÖ 16:56:25.221 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_1_2 user_id=user_1 session_id=session_1\n",
      "\\rProcessing turn 3/60 (Conv 2.1)...‚úÖ 16:56:28.793 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:28.794 [ERROR   ] context_manager | Failed to get recent context | user_id=user_2 session_id=session_2 operation=get_recent_context\n",
      "‚ùå 16:56:28.795 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚úÖ 16:56:28.796 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_2_1 user_id=user_2 session_id=session_2\n",
      "‚ùå 16:56:28.796 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:28.798 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "\\rProcessing turn 4/60 (Conv 2.2)...‚úÖ 16:56:32.853 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:32.854 [ERROR   ] context_manager | Failed to get recent context | user_id=user_2 session_id=session_2 operation=get_recent_context\n",
      "‚ùå 16:56:32.855 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚úÖ 16:56:32.856 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_2_2 user_id=user_2 session_id=session_2\n",
      "‚ùå 16:56:32.857 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:32.858 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:32.859 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:32.860 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "\\rProcessing turn 5/60 (Conv 2.3)...‚úÖ 16:56:35.446 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:35.447 [ERROR   ] context_manager | Failed to get recent context | user_id=user_2 session_id=session_2 operation=get_recent_context\n",
      "‚ùå 16:56:35.448 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚úÖ 16:56:35.449 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_2_3 user_id=user_2 session_id=session_2\n",
      "‚ùå 16:56:35.450 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:35.451 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:35.453 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:35.454 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:35.455 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚ùå 16:56:35.456 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "\\rProcessing turn 6/60 (Conv 2.4)...‚úÖ 16:56:37.879 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:37.880 [ERROR   ] context_manager | Failed to get recent context | user_id=user_2 session_id=session_2 operation=get_recent_context\n",
      "‚ùå 16:56:37.881 [ERROR   ] context_manager | Failed to save context entry | user_id=user_2 session_id=session_2 operation=save_context_entry\n",
      "‚úÖ 16:56:37.882 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_2_4 user_id=user_2 session_id=session_2\n",
      "\\rProcessing turn 7/60 (Conv 3.1)...‚úÖ 16:56:40.409 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:40.411 [ERROR   ] context_manager | Failed to get recent context | user_id=user_3 session_id=session_3 operation=get_recent_context\n",
      "‚ùå 16:56:40.412 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚úÖ 16:56:40.412 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_3_1 user_id=user_3 session_id=session_3\n",
      "‚ùå 16:56:40.414 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:40.415 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "\\rProcessing turn 8/60 (Conv 3.2)...‚úÖ 16:56:43.532 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:43.533 [ERROR   ] context_manager | Failed to get recent context | user_id=user_3 session_id=session_3 operation=get_recent_context\n",
      "‚ùå 16:56:43.534 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚úÖ 16:56:43.535 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_3_2 user_id=user_3 session_id=session_3\n",
      "‚ùå 16:56:43.536 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:43.537 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:43.539 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:43.541 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "\\rProcessing turn 9/60 (Conv 3.3)...‚úÖ 16:56:49.052 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:49.053 [ERROR   ] context_manager | Failed to get recent context | user_id=user_3 session_id=session_3 operation=get_recent_context\n",
      "‚ùå 16:56:49.054 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚úÖ 16:56:49.055 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_3_3 user_id=user_3 session_id=session_3\n",
      "‚ùå 16:56:49.056 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:49.057 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:49.059 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:49.060 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:49.062 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:49.063 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "\\rProcessing turn 10/60 (Conv 3.4)...‚úÖ 16:56:51.737 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:51.738 [ERROR   ] context_manager | Failed to get recent context | user_id=user_3 session_id=session_3 operation=get_recent_context\n",
      "‚ùå 16:56:51.739 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚úÖ 16:56:51.740 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_3_4 user_id=user_3 session_id=session_3\n",
      "‚ùå 16:56:51.741 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:51.742 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:51.743 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:51.744 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:51.745 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:51.746 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:51.747 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:51.748 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "\\rProcessing turn 11/60 (Conv 3.5)...‚úÖ 16:56:54.267 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:54.268 [ERROR   ] context_manager | Failed to get recent context | user_id=user_3 session_id=session_3 operation=get_recent_context\n",
      "‚ùå 16:56:54.269 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚úÖ 16:56:54.270 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_3_5 user_id=user_3 session_id=session_3\n",
      "‚ùå 16:56:54.271 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.272 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.273 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.274 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.275 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.276 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.277 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.278 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.279 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:54.280 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "\\rProcessing turn 12/60 (Conv 3.6)...‚úÖ 16:56:58.016 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:56:58.018 [ERROR   ] context_manager | Failed to get recent context | user_id=user_3 session_id=session_3 operation=get_recent_context\n",
      "‚ùå 16:56:58.019 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚úÖ 16:56:58.022 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_3_6 user_id=user_3 session_id=session_3\n",
      "‚ùå 16:56:58.023 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.024 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.025 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.026 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.027 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.029 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.030 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.032 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.034 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.035 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.037 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚ùå 16:56:58.037 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "\\rProcessing turn 13/60 (Conv 3.7)...‚úÖ 16:57:00.221 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:00.222 [ERROR   ] context_manager | Failed to get recent context | user_id=user_3 session_id=session_3 operation=get_recent_context\n",
      "‚ùå 16:57:00.223 [ERROR   ] context_manager | Failed to save context entry | user_id=user_3 session_id=session_3 operation=save_context_entry\n",
      "‚úÖ 16:57:00.224 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_3_7 user_id=user_3 session_id=session_3\n",
      "\\rProcessing turn 14/60 (Conv 4.1)...‚úÖ 16:57:02.764 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:02.766 [ERROR   ] context_manager | Failed to get recent context | user_id=user_4 session_id=session_4 operation=get_recent_context\n",
      "‚ùå 16:57:02.767 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "‚úÖ 16:57:02.768 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_4_1 user_id=user_4 session_id=session_4\n",
      "‚ùå 16:57:02.770 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "‚ùå 16:57:02.771 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "\\rProcessing turn 15/60 (Conv 4.2)...‚úÖ 16:57:05.112 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:05.113 [ERROR   ] context_manager | Failed to get recent context | user_id=user_4 session_id=session_4 operation=get_recent_context\n",
      "‚ùå 16:57:05.114 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "‚úÖ 16:57:05.115 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_4_2 user_id=user_4 session_id=session_4\n",
      "‚ùå 16:57:05.116 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "‚ùå 16:57:05.117 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "‚ùå 16:57:05.118 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "‚ùå 16:57:05.119 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "\\rProcessing turn 16/60 (Conv 4.3)...‚úÖ 16:57:06.948 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:06.950 [ERROR   ] context_manager | Failed to get recent context | user_id=user_4 session_id=session_4 operation=get_recent_context\n",
      "‚ùå 16:57:06.951 [ERROR   ] context_manager | Failed to save context entry | user_id=user_4 session_id=session_4 operation=save_context_entry\n",
      "‚úÖ 16:57:06.952 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_4_3 user_id=user_4 session_id=session_4\n",
      "\\rProcessing turn 17/60 (Conv 5.1)...‚úÖ 16:57:10.882 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:10.883 [ERROR   ] context_manager | Failed to get recent context | user_id=user_5 session_id=session_5 operation=get_recent_context\n",
      "‚ùå 16:57:10.884 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "‚úÖ 16:57:10.885 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_5_1 user_id=user_5 session_id=session_5\n",
      "‚ùå 16:57:10.886 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "‚ùå 16:57:10.887 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "\\rProcessing turn 18/60 (Conv 5.2)...‚úÖ 16:57:14.286 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:14.287 [ERROR   ] context_manager | Failed to get recent context | user_id=user_5 session_id=session_5 operation=get_recent_context\n",
      "‚ùå 16:57:14.288 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "‚úÖ 16:57:14.289 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_5_2 user_id=user_5 session_id=session_5\n",
      "‚ùå 16:57:14.291 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "‚ùå 16:57:14.292 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "‚ùå 16:57:14.293 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "‚ùå 16:57:14.294 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "\\rProcessing turn 19/60 (Conv 5.3)...‚úÖ 16:57:16.527 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:16.528 [ERROR   ] context_manager | Failed to get recent context | user_id=user_5 session_id=session_5 operation=get_recent_context\n",
      "‚ùå 16:57:16.529 [ERROR   ] context_manager | Failed to save context entry | user_id=user_5 session_id=session_5 operation=save_context_entry\n",
      "‚úÖ 16:57:16.530 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_5_3 user_id=user_5 session_id=session_5\n",
      "\\rProcessing turn 20/60 (Conv 6.1)...‚úÖ 16:57:20.925 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:20.926 [ERROR   ] context_manager | Failed to get recent context | user_id=user_6 session_id=session_6 operation=get_recent_context\n",
      "‚ùå 16:57:20.927 [ERROR   ] context_manager | Failed to save context entry | user_id=user_6 session_id=session_6 operation=save_context_entry\n",
      "‚úÖ 16:57:20.928 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_6_1 user_id=user_6 session_id=session_6\n",
      "‚ùå 16:57:20.929 [ERROR   ] context_manager | Failed to save context entry | user_id=user_6 session_id=session_6 operation=save_context_entry\n",
      "‚ùå 16:57:20.930 [ERROR   ] context_manager | Failed to save context entry | user_id=user_6 session_id=session_6 operation=save_context_entry\n",
      "\\rProcessing turn 21/60 (Conv 6.2)...‚úÖ 16:57:24.624 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:24.625 [ERROR   ] context_manager | Failed to get recent context | user_id=user_6 session_id=session_6 operation=get_recent_context\n",
      "‚ùå 16:57:24.626 [ERROR   ] context_manager | Failed to save context entry | user_id=user_6 session_id=session_6 operation=save_context_entry\n",
      "‚úÖ 16:57:24.627 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_6_2 user_id=user_6 session_id=session_6\n",
      "\\rProcessing turn 22/60 (Conv 7.1)...‚úÖ 16:57:28.604 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:28.606 [ERROR   ] context_manager | Failed to get recent context | user_id=user_7 session_id=session_7 operation=get_recent_context\n",
      "‚ùå 16:57:28.607 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚úÖ 16:57:28.608 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_7_1 user_id=user_7 session_id=session_7\n",
      "‚ùå 16:57:28.610 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:28.611 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "\\rProcessing turn 23/60 (Conv 7.2)...‚úÖ 16:57:30.280 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:30.282 [ERROR   ] context_manager | Failed to get recent context | user_id=user_7 session_id=session_7 operation=get_recent_context\n",
      "‚ùå 16:57:30.282 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚úÖ 16:57:30.283 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_7_2 user_id=user_7 session_id=session_7\n",
      "‚ùå 16:57:30.284 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:30.285 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:30.286 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:30.287 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "\\rProcessing turn 24/60 (Conv 7.3)...‚úÖ 16:57:33.671 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:33.672 [ERROR   ] context_manager | Failed to get recent context | user_id=user_7 session_id=session_7 operation=get_recent_context\n",
      "‚ùå 16:57:33.673 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚úÖ 16:57:33.674 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_7_3 user_id=user_7 session_id=session_7\n",
      "‚ùå 16:57:33.675 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:33.676 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:33.677 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:33.679 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:33.680 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚ùå 16:57:33.682 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "\\rProcessing turn 25/60 (Conv 7.4)...‚úÖ 16:57:36.643 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:36.644 [ERROR   ] context_manager | Failed to get recent context | user_id=user_7 session_id=session_7 operation=get_recent_context\n",
      "‚ùå 16:57:36.645 [ERROR   ] context_manager | Failed to save context entry | user_id=user_7 session_id=session_7 operation=save_context_entry\n",
      "‚úÖ 16:57:36.646 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_7_4 user_id=user_7 session_id=session_7\n",
      "\\rProcessing turn 26/60 (Conv 8.1)...‚úÖ 16:57:38.809 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:38.810 [ERROR   ] context_manager | Failed to get recent context | user_id=user_8 session_id=session_8 operation=get_recent_context\n",
      "‚ùå 16:57:38.811 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "‚úÖ 16:57:38.812 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_8_1 user_id=user_8 session_id=session_8\n",
      "‚ùå 16:57:38.813 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "‚ùå 16:57:38.814 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "\\rProcessing turn 27/60 (Conv 8.2)...‚úÖ 16:57:41.690 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:41.691 [ERROR   ] context_manager | Failed to get recent context | user_id=user_8 session_id=session_8 operation=get_recent_context\n",
      "‚ùå 16:57:41.692 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "‚úÖ 16:57:41.693 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_8_2 user_id=user_8 session_id=session_8\n",
      "‚ùå 16:57:41.694 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "‚ùå 16:57:41.695 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "‚ùå 16:57:41.696 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "‚ùå 16:57:41.698 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "\\rProcessing turn 28/60 (Conv 8.3)...‚úÖ 16:57:44.652 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:44.654 [ERROR   ] context_manager | Failed to get recent context | user_id=user_8 session_id=session_8 operation=get_recent_context\n",
      "‚ùå 16:57:44.655 [ERROR   ] context_manager | Failed to save context entry | user_id=user_8 session_id=session_8 operation=save_context_entry\n",
      "‚úÖ 16:57:44.656 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_8_3 user_id=user_8 session_id=session_8\n",
      "\\rProcessing turn 29/60 (Conv 9.1)...‚úÖ 16:57:47.180 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:47.181 [ERROR   ] context_manager | Failed to get recent context | user_id=user_9 session_id=session_9 operation=get_recent_context\n",
      "‚ùå 16:57:47.182 [ERROR   ] context_manager | Failed to save context entry | user_id=user_9 session_id=session_9 operation=save_context_entry\n",
      "‚úÖ 16:57:47.183 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_9_1 user_id=user_9 session_id=session_9\n",
      "\\rProcessing turn 30/60 (Conv 10.1)...‚úÖ 16:57:52.008 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:52.009 [ERROR   ] context_manager | Failed to get recent context | user_id=user_10 session_id=session_10 operation=get_recent_context\n",
      "‚ùå 16:57:52.010 [ERROR   ] context_manager | Failed to save context entry | user_id=user_10 session_id=session_10 operation=save_context_entry\n",
      "‚úÖ 16:57:52.011 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_10_1 user_id=user_10 session_id=session_10\n",
      "\\rProcessing turn 31/60 (Conv 11.1)...‚úÖ 16:57:55.915 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:57:55.916 [ERROR   ] context_manager | Failed to get recent context | user_id=user_11 session_id=session_11 operation=get_recent_context\n",
      "‚ùå 16:57:55.917 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "‚úÖ 16:57:55.918 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_11_1 user_id=user_11 session_id=session_11\n",
      "‚ùå 16:57:55.919 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "‚ùå 16:57:55.920 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "\\rProcessing turn 32/60 (Conv 11.2)...‚úÖ 16:58:00.700 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:00.701 [ERROR   ] context_manager | Failed to get recent context | user_id=user_11 session_id=session_11 operation=get_recent_context\n",
      "‚ùå 16:58:00.702 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "‚úÖ 16:58:00.703 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_11_2 user_id=user_11 session_id=session_11\n",
      "‚ùå 16:58:00.705 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "‚ùå 16:58:00.706 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "‚ùå 16:58:00.707 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "‚ùå 16:58:00.708 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "\\rProcessing turn 33/60 (Conv 11.3)...‚úÖ 16:58:04.903 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:04.904 [ERROR   ] context_manager | Failed to get recent context | user_id=user_11 session_id=session_11 operation=get_recent_context\n",
      "‚ùå 16:58:04.906 [ERROR   ] context_manager | Failed to save context entry | user_id=user_11 session_id=session_11 operation=save_context_entry\n",
      "‚úÖ 16:58:04.907 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_11_3 user_id=user_11 session_id=session_11\n",
      "\\rProcessing turn 34/60 (Conv 12.1)...‚úÖ 16:58:07.444 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:07.446 [ERROR   ] context_manager | Failed to get recent context | user_id=user_12 session_id=session_12 operation=get_recent_context\n",
      "‚ùå 16:58:07.447 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚úÖ 16:58:07.448 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_12_1 user_id=user_12 session_id=session_12\n",
      "‚ùå 16:58:07.449 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:07.450 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "\\rProcessing turn 35/60 (Conv 12.2)...‚úÖ 16:58:10.587 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:10.588 [ERROR   ] context_manager | Failed to get recent context | user_id=user_12 session_id=session_12 operation=get_recent_context\n",
      "‚ùå 16:58:10.589 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚úÖ 16:58:10.590 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_12_2 user_id=user_12 session_id=session_12\n",
      "‚ùå 16:58:10.591 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:10.592 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:10.593 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:10.595 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "\\rProcessing turn 36/60 (Conv 12.3)...‚úÖ 16:58:14.891 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:14.893 [ERROR   ] context_manager | Failed to get recent context | user_id=user_12 session_id=session_12 operation=get_recent_context\n",
      "‚ùå 16:58:14.894 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚úÖ 16:58:14.895 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_12_3 user_id=user_12 session_id=session_12\n",
      "‚ùå 16:58:14.896 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:14.897 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:14.898 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:14.899 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:14.901 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:14.902 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "\\rProcessing turn 37/60 (Conv 12.4)...‚úÖ 16:58:18.165 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:18.166 [ERROR   ] context_manager | Failed to get recent context | user_id=user_12 session_id=session_12 operation=get_recent_context\n",
      "‚ùå 16:58:18.167 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚úÖ 16:58:18.169 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_12_4 user_id=user_12 session_id=session_12\n",
      "‚ùå 16:58:18.171 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:18.173 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:18.176 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:18.178 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:18.179 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:18.180 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:18.181 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:18.182 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "\\rProcessing turn 38/60 (Conv 12.5)...‚úÖ 16:58:20.206 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:20.208 [ERROR   ] context_manager | Failed to get recent context | user_id=user_12 session_id=session_12 operation=get_recent_context\n",
      "‚ùå 16:58:20.209 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚úÖ 16:58:20.210 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_12_5 user_id=user_12 session_id=session_12\n",
      "‚ùå 16:58:20.211 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.213 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.214 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.215 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.216 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.217 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.218 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.219 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.220 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:20.221 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "\\rProcessing turn 39/60 (Conv 12.6)...‚úÖ 16:58:25.225 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:25.226 [ERROR   ] context_manager | Failed to get recent context | user_id=user_12 session_id=session_12 operation=get_recent_context\n",
      "‚ùå 16:58:25.227 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚úÖ 16:58:25.228 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_12_6 user_id=user_12 session_id=session_12\n",
      "‚ùå 16:58:25.229 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.230 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.231 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.232 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.233 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.235 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.236 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.237 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.238 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.240 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.241 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚ùå 16:58:25.242 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "\\rProcessing turn 40/60 (Conv 12.7)...‚úÖ 16:58:27.447 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:27.449 [ERROR   ] context_manager | Failed to get recent context | user_id=user_12 session_id=session_12 operation=get_recent_context\n",
      "‚ùå 16:58:27.450 [ERROR   ] context_manager | Failed to save context entry | user_id=user_12 session_id=session_12 operation=save_context_entry\n",
      "‚úÖ 16:58:27.451 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_12_7 user_id=user_12 session_id=session_12\n",
      "\\rProcessing turn 41/60 (Conv 13.1)...‚úÖ 16:58:30.031 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:30.032 [ERROR   ] context_manager | Failed to get recent context | user_id=user_13 session_id=session_13 operation=get_recent_context\n",
      "‚ùå 16:58:30.033 [ERROR   ] context_manager | Failed to save context entry | user_id=user_13 session_id=session_13 operation=save_context_entry\n",
      "‚úÖ 16:58:30.034 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_13_1 user_id=user_13 session_id=session_13\n",
      "\\rProcessing turn 42/60 (Conv 14.1)...‚úÖ 16:58:32.645 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:32.646 [ERROR   ] context_manager | Failed to get recent context | user_id=user_14 session_id=session_14 operation=get_recent_context\n",
      "‚ùå 16:58:32.647 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "‚úÖ 16:58:32.648 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_14_1 user_id=user_14 session_id=session_14\n",
      "‚ùå 16:58:32.649 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "‚ùå 16:58:32.650 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "\\rProcessing turn 43/60 (Conv 14.2)...‚úÖ 16:58:37.837 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:37.838 [ERROR   ] context_manager | Failed to get recent context | user_id=user_14 session_id=session_14 operation=get_recent_context\n",
      "‚ùå 16:58:37.840 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "‚úÖ 16:58:37.841 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_14_2 user_id=user_14 session_id=session_14\n",
      "‚ùå 16:58:37.842 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "‚ùå 16:58:37.843 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "‚ùå 16:58:37.844 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "‚ùå 16:58:37.846 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "\\rProcessing turn 44/60 (Conv 14.3)...‚úÖ 16:58:40.357 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:40.358 [ERROR   ] context_manager | Failed to get recent context | user_id=user_14 session_id=session_14 operation=get_recent_context\n",
      "‚ùå 16:58:40.360 [ERROR   ] context_manager | Failed to save context entry | user_id=user_14 session_id=session_14 operation=save_context_entry\n",
      "‚úÖ 16:58:40.361 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_14_3 user_id=user_14 session_id=session_14\n",
      "\\rProcessing turn 45/60 (Conv 15.1)...‚úÖ 16:58:43.681 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:43.682 [ERROR   ] context_manager | Failed to get recent context | user_id=user_15 session_id=session_15 operation=get_recent_context\n",
      "‚ùå 16:58:43.683 [ERROR   ] context_manager | Failed to save context entry | user_id=user_15 session_id=session_15 operation=save_context_entry\n",
      "‚úÖ 16:58:43.684 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_15_1 user_id=user_15 session_id=session_15\n",
      "‚ùå 16:58:43.685 [ERROR   ] context_manager | Failed to save context entry | user_id=user_15 session_id=session_15 operation=save_context_entry\n",
      "‚ùå 16:58:43.686 [ERROR   ] context_manager | Failed to save context entry | user_id=user_15 session_id=session_15 operation=save_context_entry\n",
      "\\rProcessing turn 46/60 (Conv 15.2)...‚úÖ 16:58:47.127 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:47.128 [ERROR   ] context_manager | Failed to get recent context | user_id=user_15 session_id=session_15 operation=get_recent_context\n",
      "‚ùå 16:58:47.129 [ERROR   ] context_manager | Failed to save context entry | user_id=user_15 session_id=session_15 operation=save_context_entry\n",
      "‚úÖ 16:58:47.130 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_15_2 user_id=user_15 session_id=session_15\n",
      "\\rProcessing turn 47/60 (Conv 16.1)...‚úÖ 16:58:49.440 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:49.442 [ERROR   ] context_manager | Failed to get recent context | user_id=user_16 session_id=session_16 operation=get_recent_context\n",
      "‚ùå 16:58:49.443 [ERROR   ] context_manager | Failed to save context entry | user_id=user_16 session_id=session_16 operation=save_context_entry\n",
      "‚úÖ 16:58:49.444 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_16_1 user_id=user_16 session_id=session_16\n",
      "\\rProcessing turn 48/60 (Conv 17.1)...‚úÖ 16:58:51.487 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:51.488 [ERROR   ] context_manager | Failed to get recent context | user_id=user_17 session_id=session_17 operation=get_recent_context\n",
      "‚ùå 16:58:51.489 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚úÖ 16:58:51.491 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_17_1 user_id=user_17 session_id=session_17\n",
      "‚ùå 16:58:51.492 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:51.493 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "\\rProcessing turn 49/60 (Conv 17.2)...‚úÖ 16:58:56.578 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:56.579 [ERROR   ] context_manager | Failed to get recent context | user_id=user_17 session_id=session_17 operation=get_recent_context\n",
      "‚ùå 16:58:56.580 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚úÖ 16:58:56.581 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_17_2 user_id=user_17 session_id=session_17\n",
      "‚ùå 16:58:56.582 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:56.583 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:56.585 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:56.586 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "\\rProcessing turn 50/60 (Conv 17.3)...‚úÖ 16:58:59.552 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:58:59.553 [ERROR   ] context_manager | Failed to get recent context | user_id=user_17 session_id=session_17 operation=get_recent_context\n",
      "‚ùå 16:58:59.554 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚úÖ 16:58:59.556 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_17_3 user_id=user_17 session_id=session_17\n",
      "‚ùå 16:58:59.557 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:59.558 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:59.559 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:59.560 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:59.562 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:58:59.563 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "\\rProcessing turn 51/60 (Conv 17.4)...‚úÖ 16:59:01.525 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:01.527 [ERROR   ] context_manager | Failed to get recent context | user_id=user_17 session_id=session_17 operation=get_recent_context\n",
      "‚ùå 16:59:01.528 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚úÖ 16:59:01.529 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_17_4 user_id=user_17 session_id=session_17\n",
      "‚ùå 16:59:01.530 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:01.533 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:01.535 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:01.536 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:01.538 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:01.540 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:01.542 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:01.543 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "\\rProcessing turn 52/60 (Conv 17.5)...‚úÖ 16:59:04.984 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:04.985 [ERROR   ] context_manager | Failed to get recent context | user_id=user_17 session_id=session_17 operation=get_recent_context\n",
      "‚ùå 16:59:04.986 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚úÖ 16:59:04.987 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_17_5 user_id=user_17 session_id=session_17\n",
      "‚ùå 16:59:04.988 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.989 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.990 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.992 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.993 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.994 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.995 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.996 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.998 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:04.999 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "\\rProcessing turn 53/60 (Conv 17.6)...‚úÖ 16:59:07.281 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:07.282 [ERROR   ] context_manager | Failed to get recent context | user_id=user_17 session_id=session_17 operation=get_recent_context\n",
      "‚ùå 16:59:07.283 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚úÖ 16:59:07.284 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_17_6 user_id=user_17 session_id=session_17\n",
      "‚ùå 16:59:07.285 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.286 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.288 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.289 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.290 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.292 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.293 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.294 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.295 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.297 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.298 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚ùå 16:59:07.300 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "\\rProcessing turn 54/60 (Conv 17.7)...‚úÖ 16:59:09.807 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:09.808 [ERROR   ] context_manager | Failed to get recent context | user_id=user_17 session_id=session_17 operation=get_recent_context\n",
      "‚ùå 16:59:09.809 [ERROR   ] context_manager | Failed to save context entry | user_id=user_17 session_id=session_17 operation=save_context_entry\n",
      "‚úÖ 16:59:09.810 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_17_7 user_id=user_17 session_id=session_17\n",
      "\\rProcessing turn 55/60 (Conv 18.1)...‚úÖ 16:59:12.224 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:12.226 [ERROR   ] context_manager | Failed to get recent context | user_id=user_18 session_id=session_18 operation=get_recent_context\n",
      "‚ùå 16:59:12.227 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "‚úÖ 16:59:12.228 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_18_1 user_id=user_18 session_id=session_18\n",
      "‚ùå 16:59:12.229 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "‚ùå 16:59:12.230 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "\\rProcessing turn 56/60 (Conv 18.2)...‚úÖ 16:59:16.016 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:16.017 [ERROR   ] context_manager | Failed to get recent context | user_id=user_18 session_id=session_18 operation=get_recent_context\n",
      "‚ùå 16:59:16.019 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "‚úÖ 16:59:16.020 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_18_2 user_id=user_18 session_id=session_18\n",
      "‚ùå 16:59:16.021 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "‚ùå 16:59:16.022 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "‚ùå 16:59:16.024 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "‚ùå 16:59:16.025 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "\\rProcessing turn 57/60 (Conv 18.3)...‚úÖ 16:59:19.041 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:19.042 [ERROR   ] context_manager | Failed to get recent context | user_id=user_18 session_id=session_18 operation=get_recent_context\n",
      "‚ùå 16:59:19.043 [ERROR   ] context_manager | Failed to save context entry | user_id=user_18 session_id=session_18 operation=save_context_entry\n",
      "‚úÖ 16:59:19.045 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_18_3 user_id=user_18 session_id=session_18\n",
      "\\rProcessing turn 58/60 (Conv 19.1)...‚úÖ 16:59:21.425 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:21.426 [ERROR   ] context_manager | Failed to get recent context | user_id=user_19 session_id=session_19 operation=get_recent_context\n",
      "‚ùå 16:59:21.427 [ERROR   ] context_manager | Failed to save context entry | user_id=user_19 session_id=session_19 operation=save_context_entry\n",
      "‚úÖ 16:59:21.428 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_19_1 user_id=user_19 session_id=session_19\n",
      "‚ùå 16:59:21.429 [ERROR   ] context_manager | Failed to save context entry | user_id=user_19 session_id=session_19 operation=save_context_entry\n",
      "‚ùå 16:59:21.430 [ERROR   ] context_manager | Failed to save context entry | user_id=user_19 session_id=session_19 operation=save_context_entry\n",
      "\\rProcessing turn 59/60 (Conv 19.2)...‚úÖ 16:59:24.852 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:24.854 [ERROR   ] context_manager | Failed to get recent context | user_id=user_19 session_id=session_19 operation=get_recent_context\n",
      "‚ùå 16:59:24.855 [ERROR   ] context_manager | Failed to save context entry | user_id=user_19 session_id=session_19 operation=save_context_entry\n",
      "‚úÖ 16:59:24.856 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_19_2 user_id=user_19 session_id=session_19\n",
      "\\rProcessing turn 60/60 (Conv 20.1)...‚úÖ 16:59:30.103 [INFO    ] kimi-k2-instruct | Model call: kimi-k2-instruct - generate_response | model_name=kimi-k2-instruct operation=generate_response\n",
      "‚ùå 16:59:30.104 [ERROR   ] context_manager | Failed to get recent context | user_id=user_20 session_id=session_20 operation=get_recent_context\n",
      "‚ùå 16:59:30.105 [ERROR   ] context_manager | Failed to save context entry | user_id=user_20 session_id=session_20 operation=save_context_entry\n",
      "‚úÖ 16:59:30.107 [INFO    ] frustration_agent | Frustration analysis completed | operation=frustration_analysis query_id=frustration_test_20_1 user_id=user_20 session_id=session_20\n",
      "\\n‚úÖ Frustration analysis completed for 60 turns!\n",
      "\\nüìä Frustration Analysis Summary:\n",
      "  Total turns analyzed: 60\n",
      "  Average frustration score: 3.43\n",
      "  Frustration score range: 1.00 - 9.00\n",
      "\\nüò§ Frustration Levels:\n",
      "  Low: 37 (61.7%)\n",
      "  Moderate: 10 (16.7%)\n",
      "  High: 7 (11.7%)\n",
      "  Critical: 6 (10.0%)\n",
      "\\nüö® Intervention Recommendations:\n",
      "  Human intervention needed: 13 (21.7%)\n",
      "\\nüìà Escalation Trends:\n",
      "  None: 60 (100.0%)\n",
      "\\nüìù Sample Frustration Analyses:\n",
      "\\n  Turn 1.1 [frustrated]:\n",
      "    Frustration Score: 7.00/10.0\n",
      "    Frustration Level: high\n",
      "    Confidence: 0.85\n",
      "    Intervention Needed: True\n",
      "    Contributing Factors: high_frustration_language, escalation_language, strong_negative_sentiment\n",
      "    Query Score: 7.00, Pattern Score: 7.00\n",
      "    Escalation Trend: none\n",
      "\\n  Turn 1.2 [frustrated]:\n",
      "    Frustration Score: 8.00/10.0\n",
      "    Frustration Level: critical\n",
      "    Confidence: 0.95\n",
      "    Intervention Needed: True\n",
      "    Contributing Factors: high_frustration_language, escalation_language, strong_negative_sentiment\n",
      "    Query Score: 8.00, Pattern Score: 8.00\n",
      "    Escalation Trend: none\n",
      "\\n  Turn 2.1 [urgent]:\n",
      "    Frustration Score: 7.00/10.0\n",
      "    Frustration Level: high\n",
      "    Confidence: 0.85\n",
      "    Intervention Needed: True\n",
      "    Contributing Factors: high_frustration_language, strong_negative_sentiment\n",
      "    Query Score: 7.00, Pattern Score: 7.00\n",
      "    Escalation Trend: none\n",
      "  ... and 57 more analyses\n",
      "\\n‚úÖ Frustration analysis data ready for detailed review and export!\n"
     ]
    }
   ],
   "source": [
    "# Run frustration analysis on all conversation turns\n",
    "frustration_results = []\n",
    "\n",
    "def create_state_for_turn(turn_data):\n",
    "    \"\"\"Create HybridSystemState for a conversation turn\"\"\"\n",
    "    return HybridSystemState({\n",
    "        \"query_id\": f\"frustration_test_{turn_data['conversation_id']}_{turn_data['turn_number']}\",\n",
    "        \"user_id\": turn_data['user_id'],\n",
    "        \"session_id\": turn_data['session_id'],\n",
    "        \"timestamp\": turn_data['timestamp'],\n",
    "        \"query\": turn_data['customer_query'],\n",
    "        \"customer_type\": turn_data['customer_type'],\n",
    "        \"complexity\": turn_data['complexity'],\n",
    "        \"conversation_metadata\": turn_data['conversation_metadata']\n",
    "    })\n",
    "\n",
    "def analyze_conversation_frustration(conversation_turns):\n",
    "    \"\"\"Run frustration analysis on conversation turns\"\"\"\n",
    "    if not frustration_agent:\n",
    "        print(\"‚ùå Frustration Agent not initialized. Please run the previous step.\")\n",
    "        return []\n",
    "    \n",
    "    if not conversation_turns:\n",
    "        print(\"‚ùå No conversation turns to analyze. Please load conversation data first.\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"üò§ Running frustration analysis on {len(conversation_turns)} conversation turns...\")\n",
    "    \n",
    "    analyzed_turns = []\n",
    "    \n",
    "    for i, turn in enumerate(conversation_turns):\n",
    "        try:\n",
    "            # Simulate context history for pattern analysis\n",
    "            simulate_context_history(turn, context_provider)\n",
    "            \n",
    "            # Create state for this turn\n",
    "            state = create_state_for_turn(turn)\n",
    "            \n",
    "            print(f\"\\\\rProcessing turn {i+1}/{len(conversation_turns)} (Conv {turn['conversation_id']}.{turn['turn_number']})...\", end='', flush=True)\n",
    "            \n",
    "            # Run frustration analysis\n",
    "            result_state = frustration_agent(state)\n",
    "            \n",
    "            # Extract frustration analysis results\n",
    "            frustration_analysis = result_state.get('frustration_analysis', {})\n",
    "            frustration_intervention_needed = result_state.get('frustration_intervention_needed', False)\n",
    "            next_action = result_state.get('next_action', 'continue')\n",
    "            \n",
    "            # Create enhanced turn data with frustration metrics\n",
    "            enhanced_turn = {\n",
    "                **turn,  # Original turn data\n",
    "                'frustration_analysis': frustration_analysis,\n",
    "                'frustration_intervention_needed': frustration_intervention_needed,\n",
    "                'next_action': next_action,\n",
    "                'frustration_score': frustration_analysis.get('overall_score', 0.0),\n",
    "                'frustration_level': frustration_analysis.get('overall_level', 'low'),\n",
    "                'frustration_confidence': frustration_analysis.get('confidence', 0.0),\n",
    "                'contributing_factors': frustration_analysis.get('contributing_factors', []),\n",
    "                'current_query_score': frustration_analysis.get('current_analysis', {}).get('current_query_score', 0.0),\n",
    "                'pattern_score': frustration_analysis.get('history_analysis', {}).get('pattern_score', 0.0),\n",
    "                'escalation_trend': frustration_analysis.get('history_analysis', {}).get('escalation_trend', 'stable'),\n",
    "                'analysis_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            analyzed_turns.append(enhanced_turn)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n‚ùå Error analyzing turn {turn['conversation_id']}.{turn['turn_number']}: {e}\")\n",
    "            # Add turn with error information\n",
    "            error_turn = {\n",
    "                **turn,\n",
    "                'frustration_analysis': {'error': str(e)},\n",
    "                'frustration_score': 0.0,\n",
    "                'frustration_level': 'error',\n",
    "                'frustration_confidence': 0.0,\n",
    "                'contributing_factors': [f'Analysis error: {str(e)}'],\n",
    "                'frustration_intervention_needed': False,\n",
    "                'analysis_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            analyzed_turns.append(error_turn)\n",
    "    \n",
    "    print(f\"\\\\n‚úÖ Frustration analysis completed for {len(analyzed_turns)} turns!\")\n",
    "    return analyzed_turns\n",
    "\n",
    "# Run analysis if we have data and agent\n",
    "if conversation_data and frustration_agent:\n",
    "    print(\"üöÄ Starting frustration analysis process...\")\n",
    "    frustration_results = analyze_conversation_frustration(conversation_data)\n",
    "    \n",
    "    if frustration_results:\n",
    "        # Display summary statistics\n",
    "        df_results = pd.DataFrame(frustration_results)\n",
    "        \n",
    "        print(f\"\\\\nüìä Frustration Analysis Summary:\")\n",
    "        print(f\"  Total turns analyzed: {len(frustration_results)}\")\n",
    "        print(f\"  Average frustration score: {df_results['frustration_score'].mean():.2f}\")\n",
    "        print(f\"  Frustration score range: {df_results['frustration_score'].min():.2f} - {df_results['frustration_score'].max():.2f}\")\n",
    "        \n",
    "        # Frustration level distribution\n",
    "        level_counts = df_results['frustration_level'].value_counts()\n",
    "        print(f\"\\\\nüò§ Frustration Levels:\")\n",
    "        for level, count in level_counts.items():\n",
    "            percentage = count / len(frustration_results) * 100\n",
    "            print(f\"  {level.title()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Intervention recommendations\n",
    "        intervention_needed = df_results['frustration_intervention_needed'].sum()\n",
    "        print(f\"\\\\nüö® Intervention Recommendations:\")\n",
    "        print(f\"  Human intervention needed: {intervention_needed} ({intervention_needed/len(frustration_results)*100:.1f}%)\")\n",
    "        \n",
    "        # Escalation trends\n",
    "        escalation_trends = df_results['escalation_trend'].value_counts()\n",
    "        print(f\"\\\\nüìà Escalation Trends:\")\n",
    "        for trend, count in escalation_trends.items():\n",
    "            percentage = count / len(frustration_results) * 100\n",
    "            print(f\"  {trend.title()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Show sample analyses\n",
    "        print(f\"\\\\nüìù Sample Frustration Analyses:\")\n",
    "        for i, result in enumerate(frustration_results[:3]):\n",
    "            print(f\"\\\\n  Turn {result['conversation_id']}.{result['turn_number']} [{result['customer_type']}]:\")\n",
    "            print(f\"    Frustration Score: {result['frustration_score']:.2f}/10.0\")\n",
    "            print(f\"    Frustration Level: {result['frustration_level']}\")\n",
    "            print(f\"    Confidence: {result['frustration_confidence']:.2f}\")\n",
    "            print(f\"    Intervention Needed: {result['frustration_intervention_needed']}\")\n",
    "            factors = result['contributing_factors'][:3]\n",
    "            if factors:\n",
    "                print(f\"    Contributing Factors: {', '.join(factors)}\")\n",
    "            print(f\"    Query Score: {result['current_query_score']:.2f}, Pattern Score: {result['pattern_score']:.2f}\")\n",
    "            print(f\"    Escalation Trend: {result['escalation_trend']}\")\n",
    "        \n",
    "        if len(frustration_results) > 3:\n",
    "            print(f\"  ... and {len(frustration_results) - 3} more analyses\")\n",
    "            \n",
    "        print(f\"\\\\n‚úÖ Frustration analysis data ready for detailed review and export!\")\n",
    "    \n",
    "elif not conversation_data:\n",
    "    print(\"‚ö†Ô∏è No conversation data loaded. Please upload conversation results in Step 3.\")\n",
    "elif not frustration_agent:\n",
    "    print(\"‚ö†Ô∏è Frustration Agent not initialized. Please run Step 4 first.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Unable to start frustration analysis. Please check previous steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Frustration Patterns and Results\n",
    "\n",
    "Detailed analysis of frustration patterns, escalation trends, and employee wellbeing recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üò§ Frustration Analysis Dashboard\n",
      "============================================================\n",
      "\n",
      "üéØ OVERALL FRUSTRATION STATISTICS\n",
      "Total turns analyzed: 60\n",
      "Mean frustration score: 3.43/10.0\n",
      "Median frustration score: 2.00/10.0\n",
      "Standard deviation: 2.58\n",
      "Score range: 1.00 - 9.00\n",
      "\n",
      "üò§ FRUSTRATION LEVEL BREAKDOWN\n",
      "  Low: 37 (61.7%)\n",
      "  Moderate: 10 (16.7%)\n",
      "  High: 7 (11.7%)\n",
      "  Critical: 6 (10.0%)\n",
      "\n",
      "üö® INTERVENTION ANALYSIS\n",
      "  Human intervention recommended: 13 (21.7%)\n",
      "  Customers continuing with AI: 47 (78.3%)\n",
      "\n",
      "üë• FRUSTRATION BY CUSTOMER TYPE\n",
      "  Frustrated:\n",
      "    Average frustration: 7.50/10.0\n",
      "    Average confidence: 0.90\n",
      "    Intervention rate: 91.7%\n",
      "    High/Critical frustration rate: 91.7%\n",
      "    Sample size: 12\n",
      "  Urgent:\n",
      "    Average frustration: 3.35/10.0\n",
      "    Average confidence: 0.88\n",
      "    Intervention rate: 11.8%\n",
      "    High/Critical frustration rate: 11.8%\n",
      "    Sample size: 17\n",
      "  Confused:\n",
      "    Average frustration: 2.04/10.0\n",
      "    Average confidence: 0.90\n",
      "    Intervention rate: 0.0%\n",
      "    High/Critical frustration rate: 0.0%\n",
      "    Sample size: 24\n",
      "  Normal:\n",
      "    Average frustration: 1.43/10.0\n",
      "    Average confidence: 0.94\n",
      "    Intervention rate: 0.0%\n",
      "    High/Critical frustration rate: 0.0%\n",
      "    Sample size: 7\n",
      "\n",
      "üî¢ FRUSTRATION BY COMPLEXITY LEVEL\n",
      "  Medium Complexity:\n",
      "    Average frustration: 5.07/10.0\n",
      "    Average confidence: 0.89\n",
      "    Intervention rate: 42.9%\n",
      "    Sample size: 14\n",
      "  Simple Complexity:\n",
      "    Average frustration: 2.65/10.0\n",
      "    Average confidence: 0.89\n",
      "    Intervention rate: 5.0%\n",
      "    Sample size: 20\n",
      "  Complex Complexity:\n",
      "    Average frustration: 3.15/10.0\n",
      "    Average confidence: 0.90\n",
      "    Intervention rate: 23.1%\n",
      "    Sample size: 26\n",
      "\n",
      "üìà ESCALATION TREND ANALYSIS\n",
      "  None: 60 (100.0%)\n",
      "\n",
      "üìä FRUSTRATION SCORE DISTRIBUTION\n",
      "  üö® Critical (8.0-10.0): 6 (10.0%)\n",
      "  üò† High (6.0-7.99): 7 (11.7%)\n",
      "  üò§ Moderate (4.0-5.99): 9 (15.0%)\n",
      "  üòê Low (2.0-3.99): 19 (31.7%)\n",
      "  üòä Minimal (0.0-1.99): 18 (30.0%)\n",
      "\n",
      "üîç CONTRIBUTING FACTORS ANALYSIS\n",
      "  Top contributing factors:\n",
      "    ‚Ä¢ Escalation Language: 55 (91.7%)\n",
      "    ‚Ä¢ Strong Negative Sentiment: 49 (81.7%)\n",
      "    ‚Ä¢ High Frustration Language: 13 (21.7%)\n",
      "\n",
      "üîÑ PATTERN vs CURRENT QUERY ANALYSIS\n",
      "  High pattern frustration (‚â•6.0): 14 (23.3%)\n",
      "  High current query frustration (‚â•6.0): 14 (23.3%)\n",
      "  Both pattern and current high: 14 (23.3%)\n",
      "\n",
      "üéØ CONFIDENCE vs FRUSTRATION CORRELATION\n",
      "High confidence + High frustration: 13 (21.7%)\n",
      "Low confidence + Low frustration: 0 (0.0%)\n",
      "\n",
      "üìù DETAILED EXAMPLES BY FRUSTRATION LEVEL\n",
      "\n",
      "üö® CRITICAL FRUSTRATION:\n",
      "  Example 1.2 (Score: 8.0):\n",
      "    Query: ARE YOU KIDDING ME?! I ALREADY TOLD YOU I HAVEN'T MADE ANY CLAIMS, SO IT'S NOT LIKE MY RISK PROFILE ...\n",
      "    Factors: high_frustration_language, escalation_language, strong_negative_sentiment\n",
      "    Trend: none, Intervention: True\n",
      "    Confidence: 0.95\n",
      "  Example 5.2 (Score: 9.0):\n",
      "    Query: ARE YOU KIDDING ME?! YOU'RE TELLING ME TO WAIT EVEN LONGER AFTER ALREADY DENYING MY CLAIM?! I SPECIF...\n",
      "    Factors: high_frustration_language, escalation_language, strong_negative_sentiment\n",
      "    Trend: none, Intervention: True\n",
      "    Confidence: 0.95\n",
      "\n",
      "üò† HIGH FRUSTRATION:\n",
      "  Example 1.1 (Score: 7.0):\n",
      "    Query: Why did my premium increase by $200? This is ridiculous - I haven't had any claims!...\n",
      "    Factors: high_frustration_language, escalation_language, strong_negative_sentiment\n",
      "    Trend: none, Intervention: True\n",
      "    Confidence: 0.85\n",
      "  Example 2.1 (Score: 7.0):\n",
      "    Query: I just had a car accident. What do I need to do right now?...\n",
      "    Factors: high_frustration_language, strong_negative_sentiment\n",
      "    Trend: none, Intervention: True\n",
      "    Confidence: 0.85\n",
      "\n",
      "üò§ MODERATE FRUSTRATION:\n",
      "  Example 2.4 (Score: 6.0):\n",
      "    Query: This is urgent - please connect me with someone who can resolve this now....\n",
      "    Factors: escalation_language, strong_negative_sentiment\n",
      "    Trend: none, Intervention: False\n",
      "    Confidence: 0.85\n",
      "  Example 3.4 (Score: 4.0):\n",
      "    Query: I'm still not clear on this. I think I need to talk to someone in person....\n",
      "    Factors: escalation_language, strong_negative_sentiment\n",
      "    Trend: none, Intervention: False\n",
      "    Confidence: 0.75\n",
      "\n",
      "üòä LOW/MINIMAL FRUSTRATION:\n",
      "  Example 2.2 (Score: 1.0):\n",
      "    Query: That helps, thank you. I have already exchanged information with the other party and taken some phot...\n",
      "    Level: low, Confidence: 0.95\n",
      "  Example 2.3 (Score: 2.0):\n",
      "    Query: That sounds good. Can you tell me how long it typically takes for them to review the claim after sub...\n",
      "    Level: low, Confidence: 0.90\n",
      "\n",
      "üë• EMPLOYEE WELLBEING IMPACT ANALYSIS\n",
      "  High-stress customer interactions: 13 (21.7%)\n",
      "  Escalating frustration patterns: 0 (0.0%)\n",
      "  Recommended for experienced agents: 13\n",
      "\n",
      "üí° Employee Protection Recommendations:\n",
      "  ‚Ä¢ Rotate high-frustration customers among multiple agents\n",
      "  ‚Ä¢ Provide emotional support for agents handling 13 difficult cases\n",
      "  ‚Ä¢ Consider priority routing for 0 escalating situations\n",
      "  ‚Ä¢ Monitor agent stress levels during peak frustration periods\n",
      "  ‚Ä¢ Implement cooldown periods after handling critical frustration cases\n",
      "  ‚Ä¢ Provide specialized training for 13 intervention-required cases\n",
      "\n",
      "üìä FRUSTRATION PROGRESSION ANALYSIS\n",
      "  Multi-turn conversations: 15\n",
      "  Escalating patterns: 0 (0.0%)\n",
      "  Stable patterns: 0 (0.0%)\n",
      "  Improving patterns: 0 (0.0%)\n",
      "\n",
      "üìä FRUSTRATION ANALYSIS SUMMARY TABLE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_number</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>complexity</th>\n",
       "      <th>frustration_score</th>\n",
       "      <th>frustration_level</th>\n",
       "      <th>frustration_confidence</th>\n",
       "      <th>frustration_intervention_needed</th>\n",
       "      <th>escalation_trend</th>\n",
       "      <th>current_query_score</th>\n",
       "      <th>pattern_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>high</td>\n",
       "      <td>0.85</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>frustrated</td>\n",
       "      <td>medium</td>\n",
       "      <td>8.0</td>\n",
       "      <td>critical</td>\n",
       "      <td>0.95</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "      <td>7.0</td>\n",
       "      <td>high</td>\n",
       "      <td>0.85</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "      <td>1.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.90</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>urgent</td>\n",
       "      <td>simple</td>\n",
       "      <td>6.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>0.85</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>confused</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>confused</td>\n",
       "      <td>simple</td>\n",
       "      <td>1.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>confused</td>\n",
       "      <td>simple</td>\n",
       "      <td>2.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.95</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>confused</td>\n",
       "      <td>simple</td>\n",
       "      <td>4.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id  turn_number customer_type complexity  frustration_score  \\\n",
       "0                1            1    frustrated     medium                7.0   \n",
       "1                1            2    frustrated     medium                8.0   \n",
       "2                2            1        urgent     simple                7.0   \n",
       "3                2            2        urgent     simple                1.0   \n",
       "4                2            3        urgent     simple                2.0   \n",
       "5                2            4        urgent     simple                6.0   \n",
       "6                3            1      confused     simple                2.0   \n",
       "7                3            2      confused     simple                1.0   \n",
       "8                3            3      confused     simple                2.0   \n",
       "9                3            4      confused     simple                4.0   \n",
       "\n",
       "  frustration_level  frustration_confidence  frustration_intervention_needed  \\\n",
       "0              high                    0.85                             True   \n",
       "1          critical                    0.95                             True   \n",
       "2              high                    0.85                             True   \n",
       "3               low                    0.95                            False   \n",
       "4               low                    0.90                            False   \n",
       "5          moderate                    0.85                            False   \n",
       "6               low                    0.95                            False   \n",
       "7               low                    0.95                            False   \n",
       "8               low                    0.95                            False   \n",
       "9          moderate                    0.75                            False   \n",
       "\n",
       "  escalation_trend  current_query_score  pattern_score  \n",
       "0             none                  7.0            7.0  \n",
       "1             none                  8.0            8.0  \n",
       "2             none                  7.0            7.0  \n",
       "3             none                  1.0            1.0  \n",
       "4             none                  2.0            2.0  \n",
       "5             none                  6.0            6.0  \n",
       "6             none                  2.0            2.0  \n",
       "7             none                  1.0            1.0  \n",
       "8             none                  2.0            2.0  \n",
       "9             none                  4.0            4.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... showing first 10 of 60 analyzed turns\n",
      "\n",
      "üìà ADVANCED ANALYTICS SUMMARY\n",
      "  Average confidence: 0.90\n",
      "  High confidence detections (‚â•0.8): 95.0%\n",
      "  Consistent pattern-query analysis (‚â§2.0 difference): 100.0%\n",
      "\n",
      "============================================================\n",
      "‚úÖ Comprehensive frustration analysis complete! Use Step 7 to export detailed results.\n"
     ]
    }
   ],
   "source": [
    "# Detailed analysis of frustration detection results\n",
    "if frustration_results:\n",
    "    print(\"üò§ Frustration Analysis Dashboard\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    df_frustration = pd.DataFrame(frustration_results)\n",
    "    \n",
    "    # Overall Frustration Statistics\n",
    "    print(f\"\\nüéØ OVERALL FRUSTRATION STATISTICS\")\n",
    "    print(f\"Total turns analyzed: {len(df_frustration)}\")\n",
    "    print(f\"Mean frustration score: {df_frustration['frustration_score'].mean():.2f}/10.0\")\n",
    "    print(f\"Median frustration score: {df_frustration['frustration_score'].median():.2f}/10.0\")\n",
    "    print(f\"Standard deviation: {df_frustration['frustration_score'].std():.2f}\")\n",
    "    print(f\"Score range: {df_frustration['frustration_score'].min():.2f} - {df_frustration['frustration_score'].max():.2f}\")\n",
    "    \n",
    "    # Frustration Level Breakdown\n",
    "    print(f\"\\nüò§ FRUSTRATION LEVEL BREAKDOWN\")\n",
    "    level_analysis = df_frustration['frustration_level'].value_counts()\n",
    "    for level, count in level_analysis.items():\n",
    "        percentage = count / len(df_frustration) * 100\n",
    "        print(f\"  {level.replace('_', ' ').title()}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Intervention Analysis\n",
    "    print(f\"\\nüö® INTERVENTION ANALYSIS\")\n",
    "    intervention_needed = df_frustration['frustration_intervention_needed'].sum()\n",
    "    intervention_rate = intervention_needed / len(df_frustration) * 100\n",
    "    print(f\"  Human intervention recommended: {intervention_needed} ({intervention_rate:.1f}%)\")\n",
    "    print(f\"  Customers continuing with AI: {len(df_frustration) - intervention_needed} ({100-intervention_rate:.1f}%)\")\n",
    "    \n",
    "    # Frustration by Customer Type\n",
    "    print(f\"\\nüë• FRUSTRATION BY CUSTOMER TYPE\")\n",
    "    for customer_type in df_frustration['customer_type'].unique():\n",
    "        type_data = df_frustration[df_frustration['customer_type'] == customer_type]\n",
    "        avg_score = type_data['frustration_score'].mean()\n",
    "        avg_confidence = type_data['frustration_confidence'].mean()\n",
    "        intervention_rate = type_data['frustration_intervention_needed'].sum() / len(type_data) * 100\n",
    "        high_frustration_rate = len(type_data[type_data['frustration_level'].isin(['high', 'critical'])]) / len(type_data) * 100\n",
    "        print(f\"  {customer_type.title()}:\")\n",
    "        print(f\"    Average frustration: {avg_score:.2f}/10.0\")\n",
    "        print(f\"    Average confidence: {avg_confidence:.2f}\")\n",
    "        print(f\"    Intervention rate: {intervention_rate:.1f}%\")\n",
    "        print(f\"    High/Critical frustration rate: {high_frustration_rate:.1f}%\")\n",
    "        print(f\"    Sample size: {len(type_data)}\")\n",
    "    \n",
    "    # Frustration by Complexity\n",
    "    print(f\"\\nüî¢ FRUSTRATION BY COMPLEXITY LEVEL\")\n",
    "    for complexity in df_frustration['complexity'].unique():\n",
    "        complexity_data = df_frustration[df_frustration['complexity'] == complexity]\n",
    "        avg_score = complexity_data['frustration_score'].mean()\n",
    "        avg_confidence = complexity_data['frustration_confidence'].mean()\n",
    "        intervention_rate = complexity_data['frustration_intervention_needed'].sum() / len(complexity_data) * 100\n",
    "        print(f\"  {complexity.title()} Complexity:\")\n",
    "        print(f\"    Average frustration: {avg_score:.2f}/10.0\")\n",
    "        print(f\"    Average confidence: {avg_confidence:.2f}\")\n",
    "        print(f\"    Intervention rate: {intervention_rate:.1f}%\")\n",
    "        print(f\"    Sample size: {len(complexity_data)}\")\n",
    "    \n",
    "    # Escalation Trend Analysis\n",
    "    print(f\"\\nüìà ESCALATION TREND ANALYSIS\")\n",
    "    escalation_analysis = df_frustration['escalation_trend'].value_counts()\n",
    "    for trend, count in escalation_analysis.items():\n",
    "        percentage = count / len(df_frustration) * 100\n",
    "        print(f\"  {trend.replace('_', ' ').title()}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Show frustration distribution with enhanced ranges\n",
    "    print(f\"\\nüìä FRUSTRATION SCORE DISTRIBUTION\")\n",
    "    frustration_ranges = [\n",
    "        (8.0, 10.0, \"Critical\", \"üö®\"),\n",
    "        (6.0, 7.99, \"High\", \"üò†\"),\n",
    "        (4.0, 5.99, \"Moderate\", \"üò§\"),\n",
    "        (2.0, 3.99, \"Low\", \"üòê\"),\n",
    "        (0.0, 1.99, \"Minimal\", \"üòä\")\n",
    "    ]\n",
    "    \n",
    "    for min_score, max_score, label, emoji in frustration_ranges:\n",
    "        count = len(df_frustration[(df_frustration['frustration_score'] >= min_score) & (df_frustration['frustration_score'] <= max_score)])\n",
    "        percentage = count / len(df_frustration) * 100\n",
    "        print(f\"  {emoji} {label} ({min_score}-{max_score}): {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Contributing Factors Analysis\n",
    "    print(f\"\\nüîç CONTRIBUTING FACTORS ANALYSIS\")\n",
    "    all_factors = []\n",
    "    for result in frustration_results:\n",
    "        all_factors.extend(result.get('contributing_factors', []))\n",
    "    \n",
    "    if all_factors:\n",
    "        factor_counts = pd.Series(all_factors).value_counts()\n",
    "        print(f\"  Top contributing factors:\")\n",
    "        for factor, count in factor_counts.head(8).items():\n",
    "            percentage = count / len(frustration_results) * 100\n",
    "            print(f\"    ‚Ä¢ {factor.replace('_', ' ').title()}: {count} ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  No contributing factors data available\")\n",
    "    \n",
    "    # Pattern vs Current Query Analysis\n",
    "    print(f\"\\nüîÑ PATTERN vs CURRENT QUERY ANALYSIS\")\n",
    "    high_pattern = len(df_frustration[df_frustration['pattern_score'] >= 6.0])\n",
    "    high_current = len(df_frustration[df_frustration['current_query_score'] >= 6.0])\n",
    "    both_high = len(df_frustration[(df_frustration['pattern_score'] >= 6.0) & (df_frustration['current_query_score'] >= 6.0)])\n",
    "    \n",
    "    print(f\"  High pattern frustration (‚â•6.0): {high_pattern} ({high_pattern/len(df_frustration)*100:.1f}%)\")\n",
    "    print(f\"  High current query frustration (‚â•6.0): {high_current} ({high_current/len(df_frustration)*100:.1f}%)\")\n",
    "    print(f\"  Both pattern and current high: {both_high} ({both_high/len(df_frustration)*100:.1f}%)\")\n",
    "    \n",
    "    # Confidence vs Score Analysis\n",
    "    print(f\"\\nüéØ CONFIDENCE vs FRUSTRATION CORRELATION\")\n",
    "    high_conf_high_frust = len(df_frustration[(df_frustration['frustration_confidence'] >= 0.8) & (df_frustration['frustration_score'] >= 6.0)])\n",
    "    low_conf_low_frust = len(df_frustration[(df_frustration['frustration_confidence'] <= 0.5) & (df_frustration['frustration_score'] <= 3.0)])\n",
    "    print(f\"High confidence + High frustration: {high_conf_high_frust} ({high_conf_high_frust/len(df_frustration)*100:.1f}%)\")\n",
    "    print(f\"Low confidence + Low frustration: {low_conf_low_frust} ({low_conf_low_frust/len(df_frustration)*100:.1f}%)\")\n",
    "    \n",
    "    # Show detailed examples by frustration level\n",
    "    print(f\"\\nüìù DETAILED EXAMPLES BY FRUSTRATION LEVEL\")\n",
    "    \n",
    "    # Critical frustration examples\n",
    "    critical_examples = df_frustration[df_frustration['frustration_level'] == 'critical'].head(2)\n",
    "    if len(critical_examples) > 0:\n",
    "        print(f\"\\nüö® CRITICAL FRUSTRATION:\")\n",
    "        for idx, row in critical_examples.iterrows():\n",
    "            print(f\"  Example {row['conversation_id']}.{row['turn_number']} (Score: {row['frustration_score']:.1f}):\")\n",
    "            print(f\"    Query: {row['customer_query'][:100]}...\")\n",
    "            if row['contributing_factors']:\n",
    "                factors_str = ', '.join(row['contributing_factors'][:3])\n",
    "                print(f\"    Factors: {factors_str}\")\n",
    "            print(f\"    Trend: {row['escalation_trend']}, Intervention: {row['frustration_intervention_needed']}\")\n",
    "            print(f\"    Confidence: {row['frustration_confidence']:.2f}\")\n",
    "    \n",
    "    # High frustration examples\n",
    "    high_examples = df_frustration[df_frustration['frustration_level'] == 'high'].head(2)\n",
    "    if len(high_examples) > 0:\n",
    "        print(f\"\\nüò† HIGH FRUSTRATION:\")\n",
    "        for idx, row in high_examples.iterrows():\n",
    "            print(f\"  Example {row['conversation_id']}.{row['turn_number']} (Score: {row['frustration_score']:.1f}):\")\n",
    "            print(f\"    Query: {row['customer_query'][:100]}...\")\n",
    "            if row['contributing_factors']:\n",
    "                factors_str = ', '.join(row['contributing_factors'][:3])\n",
    "                print(f\"    Factors: {factors_str}\")\n",
    "            print(f\"    Trend: {row['escalation_trend']}, Intervention: {row['frustration_intervention_needed']}\")\n",
    "            print(f\"    Confidence: {row['frustration_confidence']:.2f}\")\n",
    "    \n",
    "    # Moderate frustration examples\n",
    "    moderate_examples = df_frustration[df_frustration['frustration_level'] == 'moderate'].head(2)\n",
    "    if len(moderate_examples) > 0:\n",
    "        print(f\"\\nüò§ MODERATE FRUSTRATION:\")\n",
    "        for idx, row in moderate_examples.iterrows():\n",
    "            print(f\"  Example {row['conversation_id']}.{row['turn_number']} (Score: {row['frustration_score']:.1f}):\")\n",
    "            print(f\"    Query: {row['customer_query'][:100]}...\")\n",
    "            if row['contributing_factors']:\n",
    "                factors_str = ', '.join(row['contributing_factors'][:3])\n",
    "                print(f\"    Factors: {factors_str}\")\n",
    "            print(f\"    Trend: {row['escalation_trend']}, Intervention: {row['frustration_intervention_needed']}\")\n",
    "            print(f\"    Confidence: {row['frustration_confidence']:.2f}\")\n",
    "    \n",
    "    # Low frustration examples for comparison\n",
    "    low_examples = df_frustration[df_frustration['frustration_level'].isin(['low', 'minimal'])].head(2)\n",
    "    if len(low_examples) > 0:\n",
    "        print(f\"\\nüòä LOW/MINIMAL FRUSTRATION:\")\n",
    "        for idx, row in low_examples.iterrows():\n",
    "            print(f\"  Example {row['conversation_id']}.{row['turn_number']} (Score: {row['frustration_score']:.1f}):\")\n",
    "            print(f\"    Query: {row['customer_query'][:100]}...\")\n",
    "            print(f\"    Level: {row['frustration_level']}, Confidence: {row['frustration_confidence']:.2f}\")\n",
    "    \n",
    "    # Employee Wellbeing Impact Analysis\n",
    "    print(f\"\\nüë• EMPLOYEE WELLBEING IMPACT ANALYSIS\")\n",
    "    critical_high_count = len(df_frustration[df_frustration['frustration_level'].isin(['critical', 'high'])])\n",
    "    escalating_count = len(df_frustration[df_frustration['escalation_trend'] == 'escalating'])\n",
    "    \n",
    "    print(f\"  High-stress customer interactions: {critical_high_count} ({critical_high_count/len(df_frustration)*100:.1f}%)\")\n",
    "    print(f\"  Escalating frustration patterns: {escalating_count} ({escalating_count/len(df_frustration)*100:.1f}%)\")\n",
    "    print(f\"  Recommended for experienced agents: {intervention_needed}\")\n",
    "    \n",
    "    if critical_high_count > 0:\n",
    "        print(f\"\\nüí° Employee Protection Recommendations:\")\n",
    "        print(f\"  ‚Ä¢ Rotate high-frustration customers among multiple agents\")\n",
    "        print(f\"  ‚Ä¢ Provide emotional support for agents handling {critical_high_count} difficult cases\")\n",
    "        print(f\"  ‚Ä¢ Consider priority routing for {escalating_count} escalating situations\")\n",
    "        print(f\"  ‚Ä¢ Monitor agent stress levels during peak frustration periods\")\n",
    "        print(f\"  ‚Ä¢ Implement cooldown periods after handling critical frustration cases\")\n",
    "        print(f\"  ‚Ä¢ Provide specialized training for {intervention_needed} intervention-required cases\")\n",
    "    \n",
    "    # Frustration Progression Analysis\n",
    "    print(f\"\\nüìä FRUSTRATION PROGRESSION ANALYSIS\")\n",
    "    multi_turn_convs = df_frustration[df_frustration.groupby('conversation_id')['conversation_id'].transform('count') > 1]\n",
    "    if len(multi_turn_convs) > 0:\n",
    "        print(f\"  Multi-turn conversations: {multi_turn_convs['conversation_id'].nunique()}\")\n",
    "        \n",
    "        # Analyze progression patterns\n",
    "        escalating_convs = multi_turn_convs[multi_turn_convs['escalation_trend'] == 'escalating']['conversation_id'].nunique()\n",
    "        stable_convs = multi_turn_convs[multi_turn_convs['escalation_trend'] == 'stable']['conversation_id'].nunique()\n",
    "        improving_convs = multi_turn_convs[multi_turn_convs['escalation_trend'] == 'improving']['conversation_id'].nunique()\n",
    "        \n",
    "        total_multi = multi_turn_convs['conversation_id'].nunique()\n",
    "        print(f\"  Escalating patterns: {escalating_convs} ({escalating_convs/total_multi*100:.1f}%)\")\n",
    "        print(f\"  Stable patterns: {stable_convs} ({stable_convs/total_multi*100:.1f}%)\")\n",
    "        print(f\"  Improving patterns: {improving_convs} ({improving_convs/total_multi*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"  All conversations are single-turn\")\n",
    "    \n",
    "    # Show summary table with enhanced columns\n",
    "    print(f\"\\nüìä FRUSTRATION ANALYSIS SUMMARY TABLE\")\n",
    "    summary_df = df_frustration[['conversation_id', 'turn_number', 'customer_type', 'complexity', \n",
    "                               'frustration_score', 'frustration_level', 'frustration_confidence', \n",
    "                               'frustration_intervention_needed', 'escalation_trend', \n",
    "                               'current_query_score', 'pattern_score']].copy()\n",
    "    summary_df['frustration_score'] = summary_df['frustration_score'].round(1)\n",
    "    summary_df['frustration_confidence'] = summary_df['frustration_confidence'].round(2)\n",
    "    summary_df['current_query_score'] = summary_df['current_query_score'].round(1)\n",
    "    summary_df['pattern_score'] = summary_df['pattern_score'].round(1)\n",
    "    \n",
    "    display(summary_df.head(10))\n",
    "    \n",
    "    if len(summary_df) > 10:\n",
    "        print(f\"... showing first 10 of {len(summary_df)} analyzed turns\")\n",
    "    \n",
    "    # Advanced Analytics Summary\n",
    "    print(f\"\\nüìà ADVANCED ANALYTICS SUMMARY\")\n",
    "    avg_conf = df_frustration['frustration_confidence'].mean()\n",
    "    high_confidence_rate = len(df_frustration[df_frustration['frustration_confidence'] >= 0.8]) / len(df_frustration) * 100\n",
    "    consistent_analysis = len(df_frustration[abs(df_frustration['current_query_score'] - df_frustration['pattern_score']) <= 2.0]) / len(df_frustration) * 100\n",
    "    \n",
    "    print(f\"  Average confidence: {avg_conf:.2f}\")\n",
    "    print(f\"  High confidence detections (‚â•0.8): {high_confidence_rate:.1f}%\")\n",
    "    print(f\"  Consistent pattern-query analysis (‚â§2.0 difference): {consistent_analysis:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚úÖ Comprehensive frustration analysis complete! Use Step 7 to export detailed results.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No frustration analysis results to review. Please run frustration analysis in Step 5 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 7: Export Frustration Analysis Results\n",
    "\n",
    "Save the enhanced conversation data with frustration metrics and employee wellbeing recommendations to files with timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Exporting Frustration Analysis Results and Configuration\n",
      "============================================================\n",
      "‚úÖ Frustration analysis results exported to: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_analysis_results.json\n",
      "‚úÖ Configuration settings exported to: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_agent_config.json\n",
      "‚úÖ Summary CSV exported to: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_summary.csv\n",
      "‚úÖ Frustration analysis report exported to: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_report.txt\n",
      "\n",
      "üìÅ All files exported successfully!\n",
      "\n",
      "üìã Export Summary:\n",
      "  Results JSON: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_analysis_results.json\n",
      "  Configuration: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_agent_config.json\n",
      "  Summary CSV: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_summary.csv\n",
      "  Frustration Report: /workspace/notebooks/agent_testers/outputs/frustration_evals/20250725_165950/frustration_report.txt\n",
      "\n",
      "üí° File Usage:\n",
      "  ‚Ä¢ Results JSON: Complete data for further analysis or integration\n",
      "  ‚Ä¢ Configuration: Settings used for frustration detection\n",
      "  ‚Ä¢ Summary CSV: Import into Excel, Google Sheets, or data analysis tools\n",
      "  ‚Ä¢ Frustration Report: Human-readable summary for management review\n",
      "\n",
      "üîÑ Next Steps:\n",
      "  ‚Ä¢ Use results to fine-tune frustration detection thresholds\n",
      "  ‚Ä¢ Analyze patterns to improve customer experience\n",
      "  ‚Ä¢ Implement employee wellbeing protection measures\n",
      "  ‚Ä¢ Compare frustration trends across different configurations\n",
      "  ‚Ä¢ Share analysis with customer service management\n"
     ]
    }
   ],
   "source": [
    "# Export frustration analysis results and settings to files with timestamps\n",
    "def export_frustration_results():\n",
    "    \"\"\"Export frustration analysis results and configuration to JSON files\"\"\"\n",
    "    if not frustration_results:\n",
    "        print(\"‚ùå No frustration analysis results to export.\")\n",
    "        return\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    output_dir = Path(f'/workspace/notebooks/agent_testers/outputs/frustration_evals/{timestamp}')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    # Prepare export data\n",
    "    export_data = {\n",
    "        'metadata': {\n",
    "            'export_timestamp': datetime.now().isoformat(),\n",
    "            'frustration_agent_version': frustration_agent.agent_config.version if frustration_agent.agent_config else '1.0.0',\n",
    "            'total_turns_analyzed': len(frustration_results),\n",
    "            'average_frustration_score': sum(r['frustration_score'] for r in frustration_results) / len(frustration_results),\n",
    "            'analysis_model': frustration_agent.llm_provider.model_name if frustration_agent.llm_provider else 'unknown',\n",
    "            'frustration_thresholds': frustration_agent.agent_config.settings.get('frustration_thresholds', {}) if frustration_agent.agent_config else {},\n",
    "            'intervention_threshold': frustration_agent.agent_config.settings.get('intervention_threshold', 'high') if frustration_agent.agent_config else 'high'\n",
    "        },\n",
    "        'frustration_analyses': frustration_results,\n",
    "        'summary_statistics': {\n",
    "            'level_distribution': dict(pd.DataFrame(frustration_results)['frustration_level'].value_counts()),\n",
    "            'escalation_trends': dict(pd.DataFrame(frustration_results)['escalation_trend'].value_counts()),\n",
    "            'intervention_statistics': {\n",
    "                'total_interventions_recommended': sum(1 for r in frustration_results if r['frustration_intervention_needed']),\n",
    "                'intervention_rate': sum(1 for r in frustration_results if r['frustration_intervention_needed']) / len(frustration_results),\n",
    "            },\n",
    "            'score_statistics': {\n",
    "                'mean': sum(r['frustration_score'] for r in frustration_results) / len(frustration_results),\n",
    "                'median': sorted([r['frustration_score'] for r in frustration_results])[len(frustration_results)//2],\n",
    "                'min': min(r['frustration_score'] for r in frustration_results),\n",
    "                'max': max(r['frustration_score'] for r in frustration_results)\n",
    "            },\n",
    "            'customer_type_analysis': {},\n",
    "            'complexity_analysis': {},\n",
    "            'employee_wellbeing_impact': {}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add customer type analysis\n",
    "    df_frustration = pd.DataFrame(frustration_results)\n",
    "    for customer_type in df_frustration['customer_type'].unique():\n",
    "        type_data = df_frustration[df_frustration['customer_type'] == customer_type]\n",
    "        export_data['summary_statistics']['customer_type_analysis'][customer_type] = {\n",
    "            'count': len(type_data),\n",
    "            'average_frustration_score': type_data['frustration_score'].mean(),\n",
    "            'intervention_rate': type_data['frustration_intervention_needed'].sum() / len(type_data),\n",
    "            'high_frustration_rate': len(type_data[type_data['frustration_level'].isin(['high', 'critical'])]) / len(type_data)\n",
    "        }\n",
    "    \n",
    "    # Add complexity analysis\n",
    "    for complexity in df_frustration['complexity'].unique():\n",
    "        complexity_data = df_frustration[df_frustration['complexity'] == complexity]\n",
    "        export_data['summary_statistics']['complexity_analysis'][complexity] = {\n",
    "            'count': len(complexity_data),\n",
    "            'average_frustration_score': complexity_data['frustration_score'].mean(),\n",
    "            'intervention_rate': complexity_data['frustration_intervention_needed'].sum() / len(complexity_data)\n",
    "        }\n",
    "    \n",
    "    # Add employee wellbeing analysis\n",
    "    critical_high_count = len(df_frustration[df_frustration['frustration_level'].isin(['critical', 'high'])])\n",
    "    escalating_count = len(df_frustration[df_frustration['escalation_trend'] == 'escalating'])\n",
    "    \n",
    "    export_data['summary_statistics']['employee_wellbeing_impact'] = {\n",
    "        'high_stress_interactions': critical_high_count,\n",
    "        'high_stress_rate': critical_high_count / len(df_frustration),\n",
    "        'escalating_patterns': escalating_count,\n",
    "        'escalating_rate': escalating_count / len(df_frustration),\n",
    "        'recommendations': [\n",
    "            'Rotate high-frustration customers among multiple agents',\n",
    "            'Provide emotional support for agents handling difficult cases',\n",
    "            'Monitor agent stress levels during peak frustration periods',\n",
    "            'Consider priority routing for escalating situations'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Export main results\n",
    "    results_filename = f'frustration_analysis_results.json'\n",
    "    results_path = output_dir / results_filename\n",
    "    \n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Frustration analysis results exported to: {results_path}\")\n",
    "    \n",
    "    # Export configuration used\n",
    "    config_export = {\n",
    "        'export_timestamp': datetime.now().isoformat(),\n",
    "        'agent_config': {},\n",
    "        'prompts_config': {},\n",
    "        'models_config': {}\n",
    "    }\n",
    "    \n",
    "    # Read current config contents\n",
    "    try:\n",
    "        with open(temp_file_paths['agent_config'], 'r') as f:\n",
    "            yaml = YAML()\n",
    "            config_export['agent_config'] = yaml.load(f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        with open(temp_file_paths['prompts_config'], 'r') as f:\n",
    "            yaml = YAML()\n",
    "            config_export['prompts_config'] = yaml.load(f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        with open(temp_file_paths['models_config'], 'r') as f:\n",
    "            yaml = YAML()\n",
    "            config_export['models_config'] = yaml.load(f)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    config_filename = f'frustration_agent_config.json'\n",
    "    config_path = output_dir / config_filename\n",
    "    \n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config_export, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Configuration settings exported to: {config_path}\")\n",
    "    \n",
    "    # Export summary CSV for easy analysis\n",
    "    summary_df = pd.DataFrame(frustration_results)\n",
    "    csv_filename = f'frustration_summary.csv'\n",
    "    csv_path = output_dir / csv_filename\n",
    "    \n",
    "    # Select key columns for CSV\n",
    "    csv_columns = ['conversation_id', 'turn_number', 'customer_type', 'complexity',\n",
    "                   'frustration_score', 'frustration_level', 'frustration_confidence', \n",
    "                   'frustration_intervention_needed', 'escalation_trend', 'contributing_factors',\n",
    "                   'current_query_score', 'pattern_score', 'customer_query']\n",
    "    \n",
    "    summary_csv = summary_df[csv_columns].copy()\n",
    "    # Convert list columns to strings for CSV\n",
    "    summary_csv['contributing_factors'] = summary_csv['contributing_factors'].apply(lambda x: '; '.join(x) if x else '')\n",
    "    summary_csv.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Summary CSV exported to: {csv_path}\")\n",
    "    \n",
    "    # Generate frustration analysis report\n",
    "    report_filename = f'frustration_report.txt'\n",
    "    report_path = output_dir / report_filename\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"FRUSTRATION ANALYSIS REPORT\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(f\"Export Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Total Turns Analyzed: {len(frustration_results)}\\n\")\n",
    "        f.write(f\"Average Frustration Score: {export_data['metadata']['average_frustration_score']:.2f}/10.0\\n\")\n",
    "        f.write(f\"Analysis Model: {export_data['metadata']['analysis_model']}\\n\")\n",
    "        f.write(f\"Intervention Threshold: {export_data['metadata']['intervention_threshold']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"FRUSTRATION LEVEL DISTRIBUTION:\\n\")\n",
    "        for level, count in export_data['summary_statistics']['level_distribution'].items():\n",
    "            percentage = count / len(frustration_results) * 100\n",
    "            f.write(f\"  {level.replace('_', ' ').title()}: {count} ({percentage:.1f}%)\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"INTERVENTION ANALYSIS:\\n\")\n",
    "        intervention_stats = export_data['summary_statistics']['intervention_statistics']\n",
    "        f.write(f\"  Interventions Recommended: {intervention_stats['total_interventions_recommended']}\\n\")\n",
    "        f.write(f\"  Intervention Rate: {intervention_stats['intervention_rate']*100:.1f}%\\n\\n\")\n",
    "        \n",
    "        f.write(\"ESCALATION TRENDS:\\n\")\n",
    "        for trend, count in export_data['summary_statistics']['escalation_trends'].items():\n",
    "            percentage = count / len(frustration_results) * 100\n",
    "            f.write(f\"  {trend.replace('_', ' ').title()}: {count} ({percentage:.1f}%)\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"CUSTOMER TYPE ANALYSIS:\\n\")\n",
    "        for customer_type, stats in export_data['summary_statistics']['customer_type_analysis'].items():\n",
    "            f.write(f\"  {customer_type.title()}:\\n\")\n",
    "            f.write(f\"    Sample Size: {stats['count']}\\n\")\n",
    "            f.write(f\"    Average Frustration: {stats['average_frustration_score']:.2f}/10.0\\n\")\n",
    "            f.write(f\"    Intervention Rate: {stats['intervention_rate']*100:.1f}%\\n\")\n",
    "            f.write(f\"    High Frustration Rate: {stats['high_frustration_rate']*100:.1f}%\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"EMPLOYEE WELLBEING IMPACT:\\n\")\n",
    "        wellbeing = export_data['summary_statistics']['employee_wellbeing_impact']\n",
    "        f.write(f\"  High-Stress Interactions: {wellbeing['high_stress_interactions']} ({wellbeing['high_stress_rate']*100:.1f}%)\\n\")\n",
    "        f.write(f\"  Escalating Patterns: {wellbeing['escalating_patterns']} ({wellbeing['escalating_rate']*100:.1f}%)\\n\")\n",
    "        f.write(\"\\n  Recommendations:\\n\")\n",
    "        for rec in wellbeing['recommendations']:\n",
    "            f.write(f\"    ‚Ä¢ {rec}\\n\")\n",
    "    \n",
    "    print(f\"‚úÖ Frustration analysis report exported to: {report_path}\")\n",
    "    \n",
    "    return {\n",
    "        'results_file': str(results_path),\n",
    "        'config_file': str(config_path),\n",
    "        'csv_file': str(csv_path),\n",
    "        'report_file': str(report_path)\n",
    "    }\n",
    "\n",
    "# Export results if available\n",
    "if frustration_results:\n",
    "    print(\"üíæ Exporting Frustration Analysis Results and Configuration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    export_files = export_frustration_results()\n",
    "    \n",
    "    if export_files:\n",
    "        print(f\"\\nüìÅ All files exported successfully!\")\n",
    "        print(f\"\\nüìã Export Summary:\")\n",
    "        print(f\"  Results JSON: {export_files['results_file']}\")\n",
    "        print(f\"  Configuration: {export_files['config_file']}\")\n",
    "        print(f\"  Summary CSV: {export_files['csv_file']}\")\n",
    "        print(f\"  Frustration Report: {export_files['report_file']}\")\n",
    "        \n",
    "        print(f\"\\nüí° File Usage:\")\n",
    "        print(f\"  ‚Ä¢ Results JSON: Complete data for further analysis or integration\")\n",
    "        print(f\"  ‚Ä¢ Configuration: Settings used for frustration detection\")\n",
    "        print(f\"  ‚Ä¢ Summary CSV: Import into Excel, Google Sheets, or data analysis tools\")\n",
    "        print(f\"  ‚Ä¢ Frustration Report: Human-readable summary for management review\")\n",
    "        \n",
    "        print(f\"\\nüîÑ Next Steps:\")\n",
    "        print(f\"  ‚Ä¢ Use results to fine-tune frustration detection thresholds\")\n",
    "        print(f\"  ‚Ä¢ Analyze patterns to improve customer experience\")\n",
    "        print(f\"  ‚Ä¢ Implement employee wellbeing protection measures\")\n",
    "        print(f\"  ‚Ä¢ Compare frustration trends across different configurations\")\n",
    "        print(f\"  ‚Ä¢ Share analysis with customer service management\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Export failed. Please check for errors above.\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No frustration analysis results to export. Please run frustration analysis in Step 5 first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
