{
  "experiment_info": {
    "timestamp": "20250725_1332",
    "agent_type": "chatbot_agent",
    "experiment_type": "full_conversation_simulation",
    "total_questions": 20,
    "completed_conversations": 20,
    "input_file": "test_questions_20250718_1744.json"
  },
  "model_settings": {
    "preferred_model": "deepinfra_general_budget",
    "fallback_models": [],
    "temperature": 0.7,
    "max_tokens": 2000,
    "timeout": 30
  },
  "behavior_settings": {
    "context_integration": true,
    "response_style": "clear_and_professional",
    "personalization": true
  },
  "escalation_settings": {
    "confidence_threshold": 0.7,
    "enable_auto_escalation": true,
    "escalation_triggers": [
      "low_confidence",
      "user_dissatisfaction",
      "repeat_query"
    ]
  },
  "conversation_settings": {
    "max_conversation_turns": 8,
    "customer_ai_enabled": true,
    "realistic_simulation": true
  },
  "configuration_files": {
    "agent_config": {
      "agent": {
        "name": "chatbot_agent",
        "version": "1.0.0",
        "description": "Primary response generation agent that provides direct answers to user queries",
        "type": "llm_agent",
        "created": "2025-01-17",
        "last_modified": "2025-01-17"
      },
      "settings": {
        "temperature": 0.7,
        "max_tokens": 2000,
        "timeout": 30,
        "response_time_limit": 30,
        "max_retries": 3
      },
      "behavior": {
        "context_integration": true,
        "response_style": "clear_and_professional",
        "personalization": true
      },
      "escalation": {
        "confidence_threshold": 0.7,
        "enable_auto_escalation": true,
        "escalation_triggers": [
          "low_confidence",
          "user_dissatisfaction",
          "repeat_query"
        ]
      }
    },
    "models_config": {
      "primary_model": "deepinfra_general_budget",
      "model_overrides": {
        "temperature": 0.7,
        "max_tokens": 2000,
        "per_model": {
          "codellama-7b": {
            "max_tokens": 3000
          }
        }
      }
    }
  }
}